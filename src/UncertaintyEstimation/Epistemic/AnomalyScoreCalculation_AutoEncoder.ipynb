{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.lof import LOF\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.auto_encoder import AutoEncoder\n",
    "from pyod.utils.data import evaluate_print\n",
    "\n",
    "from combo.models.score_comb import majority_vote, maximization, average\n",
    "\n",
    "# suppress warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# temporary solution for relative imports in case combo is not installed\n",
    "# if combo is installed, no need to use the following line\n",
    "sys.path.append(\n",
    "    os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), '..')))\n",
    "\n",
    "from suod.models.base import SUOD\n",
    "from suod.utils.utility import get_estimators_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### separate pet/ct positive/negative models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../Cli3/UTSW_Cli_224P_OrderFea_10_SMOTE_CV_it_2_10_1.mat', '../PrePost/PET_MOO/HN_MR_1_PPD_SMOTE_CV5_fea50_it_50_1.mat', '../PrePost/CT_MOO/HN_MR_1_PPD_SMOTE_CV5_fea50_val_it_50_1.mat']\n",
      "\n",
      "... Processing ../PrePost/PET_MOO/HN_MR_1_PPD_SMOTE_CV5_fea50_it_50_1 ...\n",
      "PET_feature shape is (179, 50)\n",
      "\n",
      "... Processing ../PrePost/CT_MOO/HN_MR_1_PPD_SMOTE_CV5_fea50_val_it_50_1 ...\n",
      "CT_feature shape is (179, 50)\n",
      "\n",
      "Feature shape is (179, 50)\n",
      "\n",
      "Label shape is (179, 1)\n",
      "\n",
      "Feature test shape is (45, 50)\n",
      "\n",
      "Label test shape is (45, 1)\n",
      "\n",
      "After SMOTE feature shape is (266, 50)\n",
      "Model: \"sequential_201\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1401 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1201 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1402 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1202 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1403 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1203 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1404 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1204 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1405 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1205 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1406 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1206 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1407 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1207 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1408 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1208 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1409 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 141s 1s/step - loss: 194.8675 - val_loss: 80.8551\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 160.6296 - val_loss: 69.1080\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 135.3522 - val_loss: 60.5066\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 120.3443 - val_loss: 54.0082\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 106.3564 - val_loss: 48.9938\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 96.2507 - val_loss: 45.0144\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 87.5586 - val_loss: 41.8446\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 81.2879 - val_loss: 39.1854\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 76.7574 - val_loss: 36.8764\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 71.7681 - val_loss: 34.8682\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 68.0354 - val_loss: 33.0925\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 64.7096 - val_loss: 31.4986\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 61.1494 - val_loss: 30.0981\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 58.8198 - val_loss: 28.7282\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 56.0426 - val_loss: 27.5109\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 53.4546 - val_loss: 26.3435\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 51.2179 - val_loss: 25.2720\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 48.8883 - val_loss: 24.2496\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 46.9626 - val_loss: 23.2412\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 44.9777 - val_loss: 22.2379\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 43.0243 - val_loss: 21.2713\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 41.3950 - val_loss: 20.3519\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 39.1350 - val_loss: 19.4538\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 37.5173 - val_loss: 18.5808\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 36.0639 - val_loss: 17.7165\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 34.1470 - val_loss: 16.8684\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 32.5510 - val_loss: 16.0531\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 30.7755 - val_loss: 15.2703\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 29.5851 - val_loss: 14.5267\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 27.8137 - val_loss: 13.8435\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 26.7536 - val_loss: 13.2009\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 25.3204 - val_loss: 12.6190\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 24.4740 - val_loss: 12.1003\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 23.0173 - val_loss: 11.6426\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 22.6896 - val_loss: 11.1985\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 21.5141 - val_loss: 10.8105\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 21.0672 - val_loss: 10.4591\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 20.3009 - val_loss: 10.1419\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 19.5343 - val_loss: 9.8618\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 19.0194 - val_loss: 9.5929\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 18.6637 - val_loss: 9.3380\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 18.1010 - val_loss: 9.0992\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 17.5447 - val_loss: 8.8718\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 17.2109 - val_loss: 8.6634\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.6938 - val_loss: 8.4651\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.2997 - val_loss: 8.2787\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.7849 - val_loss: 8.0986\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.5608 - val_loss: 7.9298\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 14.9958 - val_loss: 7.7641\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.6563 - val_loss: 7.6067\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.4769 - val_loss: 7.4514\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.1571 - val_loss: 7.2991\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.8297 - val_loss: 7.1575\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.5818 - val_loss: 7.0142\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.2379 - val_loss: 6.8817\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.9330 - val_loss: 6.7530\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.6248 - val_loss: 6.6230\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.4721 - val_loss: 6.5044\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.0392 - val_loss: 6.3908\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.7894 - val_loss: 6.2854\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.7669 - val_loss: 6.1818\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.7550 - val_loss: 6.0760\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.3874 - val_loss: 5.9779\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.1664 - val_loss: 5.8832\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.8027 - val_loss: 5.7954\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.8129 - val_loss: 5.7099\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.4274 - val_loss: 5.6282\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.3965 - val_loss: 5.5548\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.1172 - val_loss: 5.4803\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.9747 - val_loss: 5.4039\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.8466 - val_loss: 5.3330\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.8565 - val_loss: 5.2641\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.6271 - val_loss: 5.1984\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.5478 - val_loss: 5.1353\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.4268 - val_loss: 5.0748\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.1716 - val_loss: 5.0177\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.0284 - val_loss: 4.9601\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.7651 - val_loss: 4.9049\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.9334 - val_loss: 4.8541\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.6416 - val_loss: 4.8031\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.5002 - val_loss: 4.7538\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.4468 - val_loss: 4.7047\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.3273 - val_loss: 4.6587\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 8.3832 - val_loss: 4.6144\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.1356 - val_loss: 4.5697\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.9813 - val_loss: 4.5287\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.1075 - val_loss: 4.4881\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.9555 - val_loss: 4.4464\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.9152 - val_loss: 4.4073\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.7047 - val_loss: 4.3684\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.6906 - val_loss: 4.3311\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.5394 - val_loss: 4.2967\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.3944 - val_loss: 4.2609\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.5704 - val_loss: 4.2271\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.4245 - val_loss: 4.1970\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.2937 - val_loss: 4.1642\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.3529 - val_loss: 4.1330\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.2698 - val_loss: 4.1010\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.1184 - val_loss: 4.0713\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.1034 - val_loss: 4.0417\n",
      "Model: \"sequential_202\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1410 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1209 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1411 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1210 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1412 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1211 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1413 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1212 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1414 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1213 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1415 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1214 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1416 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1215 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1417 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1216 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1418 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 136s 1s/step - loss: 171.8558 - val_loss: 57.8829\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 148.4029 - val_loss: 50.9417\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 129.0034 - val_loss: 45.8003\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 113.1423 - val_loss: 41.9017\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 105.6239 - val_loss: 38.7985\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 93.8420 - val_loss: 36.3951\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 86.4578 - val_loss: 34.4278\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 80.5685 - val_loss: 32.7821\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 78.2540 - val_loss: 31.3974\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 73.2961 - val_loss: 30.2100\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 70.3571 - val_loss: 29.1653\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 67.7853 - val_loss: 28.1967\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 64.6935 - val_loss: 27.3186\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 61.3480 - val_loss: 26.4967\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 60.3333 - val_loss: 25.7037\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 57.2463 - val_loss: 24.9407\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 55.8567 - val_loss: 24.2233\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 53.7264 - val_loss: 23.4934\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 52.1072 - val_loss: 22.7648\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 49.0840 - val_loss: 22.0488\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 48.5238 - val_loss: 21.3208\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 46.7336 - val_loss: 20.5825\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 44.8686 - val_loss: 19.8606\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 43.2591 - val_loss: 19.1351\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 41.4005 - val_loss: 18.4068\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 39.6660 - val_loss: 17.6663\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 38.4827 - val_loss: 16.9485\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 36.8447 - val_loss: 16.2706\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 35.0626 - val_loss: 15.5891\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 32.8129 - val_loss: 14.9266\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 31.9477 - val_loss: 14.2985\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 30.2774 - val_loss: 13.6940\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 29.1732 - val_loss: 13.1197\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 26.9389 - val_loss: 12.5768\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 26.7408 - val_loss: 12.0814\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 25.7382 - val_loss: 11.6341\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 25.1927 - val_loss: 11.2226\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 23.7255 - val_loss: 10.8459\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 22.7205 - val_loss: 10.5015\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 21.9025 - val_loss: 10.2024\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 21.2882 - val_loss: 9.9228\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 21.0049 - val_loss: 9.6544\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 20.3990 - val_loss: 9.4104\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 20.1959 - val_loss: 9.1807\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 18.9369 - val_loss: 8.9732\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 18.9237 - val_loss: 8.7736\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 18.0236 - val_loss: 8.5780\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 17.5621 - val_loss: 8.4018\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 17.2574 - val_loss: 8.2399\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.7358 - val_loss: 8.0782\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.6346 - val_loss: 7.9239\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.2065 - val_loss: 7.7727\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.8409 - val_loss: 7.6270\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.7397 - val_loss: 7.4888\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.2392 - val_loss: 7.3564\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.0324 - val_loss: 7.2317\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.3492 - val_loss: 7.1113\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.2504 - val_loss: 7.0027\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.0206 - val_loss: 6.8902\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.5423 - val_loss: 6.7819\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.3431 - val_loss: 6.6821\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.4558 - val_loss: 6.5802\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.3071 - val_loss: 6.4812\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.8510 - val_loss: 6.3897\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.5176 - val_loss: 6.2980\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.2213 - val_loss: 6.2102\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.3366 - val_loss: 6.1320\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.9492 - val_loss: 6.0536\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.0044 - val_loss: 5.9757\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.7325 - val_loss: 5.8977\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.3587 - val_loss: 5.8264\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.3794 - val_loss: 5.7568\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.0208 - val_loss: 5.6897\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.8930 - val_loss: 5.6191\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.5432 - val_loss: 5.5557\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.5267 - val_loss: 5.4912\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.5718 - val_loss: 5.4304\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.4649 - val_loss: 5.3708\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.0293 - val_loss: 5.3115\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.0326 - val_loss: 5.2548\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.0188 - val_loss: 5.1989\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 9.8443 - val_loss: 5.1439\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.5052 - val_loss: 5.0957\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.5574 - val_loss: 5.0453\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.4596 - val_loss: 4.9957\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.4042 - val_loss: 4.9454\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.0724 - val_loss: 4.8989\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.2050 - val_loss: 4.8536\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.0439 - val_loss: 4.8111\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.7015 - val_loss: 4.7669\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.6824 - val_loss: 4.7237\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.5310 - val_loss: 4.6844\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.4919 - val_loss: 4.6461\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.6205 - val_loss: 4.6090\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.4204 - val_loss: 4.5708\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.1039 - val_loss: 4.5292\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.2318 - val_loss: 4.4915\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.2754 - val_loss: 4.4561\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.0338 - val_loss: 4.4194\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.9645 - val_loss: 4.3847\n",
      "\n",
      "Feature shape is (179, 50)\n",
      "\n",
      "Feature test shape is (45, 50)\n",
      "\n",
      "After SMOTE feature shape is (266, 50)\n",
      "Model: \"sequential_203\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1419 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1217 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1420 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1218 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1421 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1219 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1422 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1220 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1423 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1221 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1424 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1222 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1425 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1223 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1426 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1224 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1427 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 144s 1s/step - loss: 267.8993 - val_loss: 81.9575\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 209.2825 - val_loss: 70.7014\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 168.6397 - val_loss: 62.2273\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 146.4556 - val_loss: 55.6219\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 126.8651 - val_loss: 50.2906\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 113.3617 - val_loss: 46.0007\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 100.4192 - val_loss: 42.4613\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 89.4427 - val_loss: 39.5429\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 85.2493 - val_loss: 37.0757\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 78.3094 - val_loss: 34.9766\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 73.1121 - val_loss: 33.2213\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 67.9851 - val_loss: 31.6648\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 65.4019 - val_loss: 30.3001\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 62.6031 - val_loss: 29.0949\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 59.6265 - val_loss: 28.0250\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 57.2469 - val_loss: 27.0318\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 54.9466 - val_loss: 26.1132\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 52.8370 - val_loss: 25.2442\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 51.1965 - val_loss: 24.4155\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 49.7816 - val_loss: 23.6157\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 47.4288 - val_loss: 22.8571\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 46.0481 - val_loss: 22.1198\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 44.6882 - val_loss: 21.3848\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 42.6592 - val_loss: 20.6666\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 41.2562 - val_loss: 19.9534\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 39.9230 - val_loss: 19.2473\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 38.5268 - val_loss: 18.5674\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 37.4510 - val_loss: 17.8951\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 35.4892 - val_loss: 17.2252\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 34.1787 - val_loss: 16.5743\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 33.0486 - val_loss: 15.9429\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 31.7783 - val_loss: 15.3411\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 30.8595 - val_loss: 14.7624\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 29.1635 - val_loss: 14.2150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 27.8200 - val_loss: 13.6951\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 27.1306 - val_loss: 13.2103\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 26.3637 - val_loss: 12.7617\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 25.0898 - val_loss: 12.3587\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 24.5380 - val_loss: 11.9676\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 23.6553 - val_loss: 11.6151\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 23.2312 - val_loss: 11.2964\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 22.8006 - val_loss: 11.0055\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 21.7754 - val_loss: 10.7419\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 21.5477 - val_loss: 10.4864\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 21.0999 - val_loss: 10.2504\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 20.2805 - val_loss: 10.0303\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 20.0371 - val_loss: 9.8145\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 19.6809 - val_loss: 9.6170\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 18.8282 - val_loss: 9.4348\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 18.9707 - val_loss: 9.2534\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 18.3502 - val_loss: 9.0795\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 18.0470 - val_loss: 8.9112\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 17.6275 - val_loss: 8.7583\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 17.2125 - val_loss: 8.6032\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 17.0840 - val_loss: 8.4606\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.6806 - val_loss: 8.3221\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.3515 - val_loss: 8.1850\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.6205 - val_loss: 8.0536\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.2973 - val_loss: 7.9283\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.4982 - val_loss: 7.8106\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.2712 - val_loss: 7.6973\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.1493 - val_loss: 7.5775\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.6513 - val_loss: 7.4662\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.7832 - val_loss: 7.3528\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.5701 - val_loss: 7.2523\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.3406 - val_loss: 7.1517\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.0481 - val_loss: 7.0577\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.9648 - val_loss: 6.9613\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.6315 - val_loss: 6.8694\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.3424 - val_loss: 6.7789\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.3009 - val_loss: 6.6903\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.9000 - val_loss: 6.6084\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.8714 - val_loss: 6.5258\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.5369 - val_loss: 6.4500\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.5638 - val_loss: 6.3723\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.4679 - val_loss: 6.3007\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.4148 - val_loss: 6.2289\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.1495 - val_loss: 6.1512\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.0654 - val_loss: 6.0864\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.7707 - val_loss: 6.0178\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.5654 - val_loss: 5.9499\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.5336 - val_loss: 5.8868\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.4313 - val_loss: 5.8263\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.2209 - val_loss: 5.7695\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.0085 - val_loss: 5.7111\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.0701 - val_loss: 5.6527\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.7591 - val_loss: 5.5946\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.6978 - val_loss: 5.5374\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.4607 - val_loss: 5.4842\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.5885 - val_loss: 5.4329\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.4701 - val_loss: 5.3825\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.2247 - val_loss: 5.3305\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.0347 - val_loss: 5.2808\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.9677 - val_loss: 5.2336\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.9643 - val_loss: 5.1886\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.9329 - val_loss: 5.1439\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.0455 - val_loss: 5.1015\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.7921 - val_loss: 5.0576\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.6823 - val_loss: 5.0122\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.4801 - val_loss: 4.9698\n",
      "Model: \"sequential_204\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1428 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1225 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1429 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1226 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1430 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1227 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1431 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1228 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1432 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1229 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1433 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1230 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1434 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1231 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1435 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1232 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1436 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 141s 1s/step - loss: 208.6458 - val_loss: 61.9621\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 171.6245 - val_loss: 54.1623\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 144.8616 - val_loss: 48.6527\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 127.4976 - val_loss: 44.4373\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 116.4942 - val_loss: 41.0757\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 105.2558 - val_loss: 38.3619\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 96.9714 - val_loss: 36.1598\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 88.4082 - val_loss: 34.2628\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 85.0798 - val_loss: 32.5966\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 79.5706 - val_loss: 31.1680\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 76.3559 - val_loss: 29.8817\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 72.5595 - val_loss: 28.6833\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 68.6594 - val_loss: 27.5860\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 65.1099 - val_loss: 26.5473\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 61.3886 - val_loss: 25.5746\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 59.2899 - val_loss: 24.6201\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 57.2169 - val_loss: 23.6939\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 53.7456 - val_loss: 22.8020\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 52.7960 - val_loss: 21.8824\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 50.0202 - val_loss: 20.9794\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 47.4436 - val_loss: 20.0902\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 45.1789 - val_loss: 19.2130\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 43.1724 - val_loss: 18.3677\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 40.3643 - val_loss: 17.5500\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 39.3515 - val_loss: 16.7664\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 37.3701 - val_loss: 16.0237\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 35.3927 - val_loss: 15.3286\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 33.3572 - val_loss: 14.7037\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 32.1749 - val_loss: 14.1379\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 30.8107 - val_loss: 13.6108\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 29.7329 - val_loss: 13.1479\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 28.7488 - val_loss: 12.7345\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 27.5323 - val_loss: 12.3527\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 26.9884 - val_loss: 12.0021\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 25.9538 - val_loss: 11.6685\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 25.2073 - val_loss: 11.3509\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 24.1739 - val_loss: 11.0600\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 23.6011 - val_loss: 10.7903\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 22.8441 - val_loss: 10.5356\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 22.1260 - val_loss: 10.2947\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 21.7908 - val_loss: 10.0671\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 20.9161 - val_loss: 9.8430\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 20.6750 - val_loss: 9.6312\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 19.8870 - val_loss: 9.4316\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 19.4784 - val_loss: 9.2483\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 18.8589 - val_loss: 9.0721\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 18.5227 - val_loss: 8.8939\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 18.3707 - val_loss: 8.7277\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 17.9271 - val_loss: 8.5718\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 17.4720 - val_loss: 8.4205\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.9729 - val_loss: 8.2762\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.6428 - val_loss: 8.1374\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.3198 - val_loss: 8.0009\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.9628 - val_loss: 7.8707\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.7474 - val_loss: 7.7475\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.3541 - val_loss: 7.6304\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.1044 - val_loss: 7.5110\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.7659 - val_loss: 7.3995\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.5562 - val_loss: 7.2853\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.4097 - val_loss: 7.1773\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.9073 - val_loss: 7.0738\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.5967 - val_loss: 6.9712\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.5993 - val_loss: 6.8733\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.2718 - val_loss: 6.7761\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.1280 - val_loss: 6.6820\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.6368 - val_loss: 6.5887\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.8253 - val_loss: 6.5022\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.6783 - val_loss: 6.4180\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.2574 - val_loss: 6.3341\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.9570 - val_loss: 6.2557\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.6268 - val_loss: 6.1803\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.6136 - val_loss: 6.1048\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.5698 - val_loss: 6.0303\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.3601 - val_loss: 5.9597\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.1759 - val_loss: 5.8889\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.1074 - val_loss: 5.8223\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.8045 - val_loss: 5.7579\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.8670 - val_loss: 5.6955\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.4802 - val_loss: 5.6333\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.5705 - val_loss: 5.5761\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.2941 - val_loss: 5.5172\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.0873 - val_loss: 5.4594\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.9790 - val_loss: 5.4021\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.8737 - val_loss: 5.3469\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.0699 - val_loss: 5.2936\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.5563 - val_loss: 5.2421\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.6685 - val_loss: 5.1918\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.3075 - val_loss: 5.1423\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.2219 - val_loss: 5.0951\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.2053 - val_loss: 5.0471\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.2490 - val_loss: 5.0013\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.9123 - val_loss: 4.9584\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.0381 - val_loss: 4.9167\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.7176 - val_loss: 4.8720\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.6062 - val_loss: 4.8291\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.5263 - val_loss: 4.7885\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.5024 - val_loss: 4.7486\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.5110 - val_loss: 4.7104\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.3341 - val_loss: 4.6725\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.3598 - val_loss: 4.6340\n",
      "['../Cli3/UTSW_Cli_224P_OrderFea_10_SMOTE_CV_it_2_10_2.mat', '../PrePost/PET_MOO/HN_MR_1_PPD_SMOTE_CV5_fea50_it_50_2.mat', '../PrePost/CT_MOO/HN_MR_1_PPD_SMOTE_CV5_fea50_val_it_50_2.mat']\n",
      "\n",
      "... Processing ../PrePost/PET_MOO/HN_MR_1_PPD_SMOTE_CV5_fea50_it_50_2 ...\n",
      "PET_feature shape is (180, 50)\n",
      "\n",
      "... Processing ../PrePost/CT_MOO/HN_MR_1_PPD_SMOTE_CV5_fea50_val_it_50_2 ...\n",
      "CT_feature shape is (180, 50)\n",
      "\n",
      "Feature shape is (180, 50)\n",
      "\n",
      "Label shape is (180, 1)\n",
      "\n",
      "Feature test shape is (44, 50)\n",
      "\n",
      "Label test shape is (44, 1)\n",
      "\n",
      "After SMOTE feature shape is (268, 50)\n",
      "Model: \"sequential_205\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1437 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1233 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1438 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1234 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1439 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1235 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1440 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1236 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1441 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1237 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1442 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1238 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1443 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1239 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1444 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1240 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1445 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 144s 1s/step - loss: 175.9185 - val_loss: 67.8539\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 145.7092 - val_loss: 57.7405\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 125.9506 - val_loss: 50.1898\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 109.6209 - val_loss: 44.6046\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - ETA: 0s - loss: 103.504 - 0s 2ms/step - loss: 96.0936 - val_loss: 40.4242\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 87.2896 - val_loss: 37.0953\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 79.9166 - val_loss: 34.4745\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 74.7506 - val_loss: 32.2991\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 71.1129 - val_loss: 30.4495\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 65.8322 - val_loss: 28.8823\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 62.7745 - val_loss: 27.4908\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 59.8034 - val_loss: 26.2427\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 56.8334 - val_loss: 25.1142\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 54.4988 - val_loss: 24.0770\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 52.1930 - val_loss: 23.0987\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 50.0046 - val_loss: 22.1834\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 47.7425 - val_loss: 21.3013\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 45.8904 - val_loss: 20.4418\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 43.8401 - val_loss: 19.6098\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 42.2113 - val_loss: 18.7935\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 40.2708 - val_loss: 17.9870\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 38.5468 - val_loss: 17.1885\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 36.4275 - val_loss: 16.3930\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 35.5026 - val_loss: 15.6322\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 33.7080 - val_loss: 14.9065\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 31.9861 - val_loss: 14.2238\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 2ms/step - loss: 30.2952 - val_loss: 13.5860\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 29.1536 - val_loss: 13.0100\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 28.4054 - val_loss: 12.4924\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 26.8159 - val_loss: 12.0201\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 25.8830 - val_loss: 11.5948\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 25.1987 - val_loss: 11.2065\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 24.0296 - val_loss: 10.8499\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 23.6275 - val_loss: 10.5173\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22.6468 - val_loss: 10.2111\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21.6810 - val_loss: 9.9224\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21.2967 - val_loss: 9.6546\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20.7752 - val_loss: 9.4039\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 19.6990 - val_loss: 9.1662\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 19.8290 - val_loss: 8.9399\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.8011 - val_loss: 8.7242\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.5065 - val_loss: 8.5228\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.8789 - val_loss: 8.3351\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.7100 - val_loss: 8.1615\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.9886 - val_loss: 7.9965\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.8522 - val_loss: 7.8430\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.3900 - val_loss: 7.6945\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.0376 - val_loss: 7.5508\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.7064 - val_loss: 7.4190\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.2555 - val_loss: 7.2922\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.1439 - val_loss: 7.1708\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.8583 - val_loss: 7.0549\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.8024 - val_loss: 6.9444\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.2457 - val_loss: 6.8396\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.8036 - val_loss: 6.7352\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.6290 - val_loss: 6.6383\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.3602 - val_loss: 6.5440\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.1408 - val_loss: 6.4500\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.9221 - val_loss: 6.3603\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.7891 - val_loss: 6.2708\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.4947 - val_loss: 6.1826\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.2210 - val_loss: 6.0994\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.1280 - val_loss: 6.0169\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.7175 - val_loss: 5.9384\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.6455 - val_loss: 5.8648\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.5719 - val_loss: 5.7931\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.2831 - val_loss: 5.7197\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.1175 - val_loss: 5.6476\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.9575 - val_loss: 5.5778\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.6947 - val_loss: 5.5108\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.7268 - val_loss: 5.4425\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.4053 - val_loss: 5.3757\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.3358 - val_loss: 5.3120\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.9236 - val_loss: 5.2504\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.9217 - val_loss: 5.1919\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.7203 - val_loss: 5.1326\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.6988 - val_loss: 5.0760\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.4241 - val_loss: 5.0216\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.3381 - val_loss: 4.9674\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.1516 - val_loss: 4.9154\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.2164 - val_loss: 4.8638\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.8419 - val_loss: 4.8152\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.8683 - val_loss: 4.7675\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.9348 - val_loss: 4.7218\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.8117 - val_loss: 4.6764\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.6370 - val_loss: 4.6316\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.3026 - val_loss: 4.5874\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.4624 - val_loss: 4.5438\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.2213 - val_loss: 4.5024\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.1709 - val_loss: 4.4604\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.0844 - val_loss: 4.4194\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.9396 - val_loss: 4.3789\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.0483 - val_loss: 4.3418\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.8034 - val_loss: 4.3048\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.7926 - val_loss: 4.2681\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.7377 - val_loss: 4.2321\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.6219 - val_loss: 4.1958\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.3133 - val_loss: 4.1602\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.3969 - val_loss: 4.1267\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.0947 - val_loss: 4.0939\n",
      "Model: \"sequential_206\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1446 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1241 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1447 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1242 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1448 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1243 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1449 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1244 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1450 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1245 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1451 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1246 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1452 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1247 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1453 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1248 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1454 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 142s 1s/step - loss: 203.7651 - val_loss: 86.1112\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 165.7077 - val_loss: 77.4207\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 137.0024 - val_loss: 70.8759\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 126.0573 - val_loss: 65.6808\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 115.5906 - val_loss: 61.3368\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 104.5520 - val_loss: 57.9402\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 102.2742 - val_loss: 55.0636\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 90.3661 - val_loss: 52.6081\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 86.4518 - val_loss: 50.4394\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 81.6074 - val_loss: 48.6419\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 78.2400 - val_loss: 46.8970\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 71.7850 - val_loss: 45.4071\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 71.9562 - val_loss: 44.0510\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 69.2332 - val_loss: 42.8024\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 65.5346 - val_loss: 41.7222\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 63.4664 - val_loss: 40.6009\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 60.9279 - val_loss: 39.5259\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 58.3945 - val_loss: 38.4873\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 55.7926 - val_loss: 37.4880\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 52.4228 - val_loss: 36.5417\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 50.8529 - val_loss: 35.5835\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 48.5394 - val_loss: 34.6563\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 45.9737 - val_loss: 33.7154\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 44.7549 - val_loss: 32.7959\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 42.6053 - val_loss: 31.9129\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 40.8616 - val_loss: 31.0288\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 38.6575 - val_loss: 30.2014\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 37.0721 - val_loss: 29.3403\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 35.4471 - val_loss: 28.5894\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 33.6463 - val_loss: 27.8817\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 32.2700 - val_loss: 27.2306\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 30.4926 - val_loss: 26.6119\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 29.1201 - val_loss: 26.0086\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 28.0896 - val_loss: 25.5112\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 26.2357 - val_loss: 25.0549\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 26.2215 - val_loss: 24.5905\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 24.7218 - val_loss: 24.1923\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 23.8793 - val_loss: 23.8043\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 23.3034 - val_loss: 23.4193\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22.6229 - val_loss: 23.1479\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22.2909 - val_loss: 22.9017\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21.4445 - val_loss: 22.6952\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20.4082 - val_loss: 22.4992\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20.3763 - val_loss: 22.3137\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 19.6362 - val_loss: 22.1143\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.4747 - val_loss: 21.9523\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.6920 - val_loss: 21.7572\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.2648 - val_loss: 21.5604\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.3894 - val_loss: 21.3646\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.0988 - val_loss: 21.1374\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.9380 - val_loss: 20.9484\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.4633 - val_loss: 20.7800\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.1090 - val_loss: 20.6563\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.6576 - val_loss: 20.5550\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.1970 - val_loss: 20.4694\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.2470 - val_loss: 20.3297\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.7226 - val_loss: 20.1969\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.2961 - val_loss: 20.0515\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.0215 - val_loss: 19.8888\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.0321 - val_loss: 19.7532\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.7266 - val_loss: 19.6308\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.5571 - val_loss: 19.5062\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.1690 - val_loss: 19.3806\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.0213 - val_loss: 19.2762\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.5234 - val_loss: 19.1622\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.6262 - val_loss: 19.0198\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.2160 - val_loss: 18.8611\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.1535 - val_loss: 18.7432\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.8950 - val_loss: 18.6646\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.6836 - val_loss: 18.5702\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.6687 - val_loss: 18.4865\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.4846 - val_loss: 18.4233\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.2630 - val_loss: 18.3491\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.0529 - val_loss: 18.2638\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.8743 - val_loss: 18.1781\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.6731 - val_loss: 18.0758\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.5312 - val_loss: 17.9845\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.4154 - val_loss: 17.8867\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.2538 - val_loss: 17.7929\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - ETA: 0s - loss: 10.91 - 0s 2ms/step - loss: 10.3463 - val_loss: 17.7312\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.9363 - val_loss: 17.6810\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.9300 - val_loss: 17.6425\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.6760 - val_loss: 17.5929\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.5020 - val_loss: 17.5557\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.4872 - val_loss: 17.4703\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.4634 - val_loss: 17.3948\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.2107 - val_loss: 17.3092\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.9882 - val_loss: 17.2354\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.2895 - val_loss: 17.1903\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.9668 - val_loss: 17.1591\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.9007 - val_loss: 17.1098\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.6381 - val_loss: 17.0488\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.6878 - val_loss: 16.9920\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.6541 - val_loss: 16.9493\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.6415 - val_loss: 16.8911\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.3675 - val_loss: 16.8619\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.1595 - val_loss: 16.8464\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.1718 - val_loss: 16.7862\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.1469 - val_loss: 16.7553\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.0342 - val_loss: 16.7203\n",
      "\n",
      "Feature shape is (180, 50)\n",
      "\n",
      "Feature test shape is (44, 50)\n",
      "\n",
      "After SMOTE feature shape is (268, 50)\n",
      "Model: \"sequential_207\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1455 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1249 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1456 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1250 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1457 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1251 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1458 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1252 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1459 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1253 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1460 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1254 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1461 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1255 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1462 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1256 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1463 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 150s 1s/step - loss: 216.6793 - val_loss: 70.6427\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 173.9791 - val_loss: 61.1426\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 146.4587 - val_loss: 54.2910\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 127.0250 - val_loss: 49.0138\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 111.4346 - val_loss: 44.9233\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 99.7556 - val_loss: 41.7065\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 91.2479 - val_loss: 39.0697\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 84.6691 - val_loss: 36.8725\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 77.9032 - val_loss: 34.9537\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 73.8172 - val_loss: 33.2684\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 69.3241 - val_loss: 31.7831\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 65.0041 - val_loss: 30.4279\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 61.9579 - val_loss: 29.1922\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 59.0592 - val_loss: 28.0180\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 56.4234 - val_loss: 26.8925\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 54.1243 - val_loss: 25.7769\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 51.5422 - val_loss: 24.7209\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 49.0347 - val_loss: 23.6716\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 46.6638 - val_loss: 22.6355\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 44.5116 - val_loss: 21.6030\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 42.0963 - val_loss: 20.5804\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 39.9180 - val_loss: 19.5828\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 37.8441 - val_loss: 18.6078\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 35.3337 - val_loss: 17.6586\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 33.7931 - val_loss: 16.7705\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 31.8957 - val_loss: 15.9429\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 30.1122 - val_loss: 15.1827\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 28.4491 - val_loss: 14.4904\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 26.8413 - val_loss: 13.8893\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 25.7201 - val_loss: 13.3688\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 2ms/step - loss: 24.8215 - val_loss: 12.9060\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 23.8528 - val_loss: 12.4986\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 23.1495 - val_loss: 12.1270\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22.0630 - val_loss: 11.7764\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21.6588 - val_loss: 11.4487\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20.8356 - val_loss: 11.1457\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20.3285 - val_loss: 10.8628\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 19.5034 - val_loss: 10.5952\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 19.0071 - val_loss: 10.3467\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.4371 - val_loss: 10.1146\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.8007 - val_loss: 9.8961\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.6160 - val_loss: 9.6768\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.0931 - val_loss: 9.4769\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.7265 - val_loss: 9.2863\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.2383 - val_loss: 9.1011\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.8722 - val_loss: 8.9183\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.5662 - val_loss: 8.7503\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.2788 - val_loss: 8.5904\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.7709 - val_loss: 8.4335\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.3488 - val_loss: 8.2890\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.2324 - val_loss: 8.1482\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.7659 - val_loss: 8.0136\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.7592 - val_loss: 7.8778\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.3825 - val_loss: 7.7490\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.1135 - val_loss: 7.6307\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.7772 - val_loss: 7.5129\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.6551 - val_loss: 7.3965\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.5278 - val_loss: 7.2887\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.2041 - val_loss: 7.1821\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.0121 - val_loss: 7.0789\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.8467 - val_loss: 6.9827\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.8562 - val_loss: 6.8881\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.5722 - val_loss: 6.7982\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.3321 - val_loss: 6.7068\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.0243 - val_loss: 6.6188\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.8335 - val_loss: 6.5351\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.7670 - val_loss: 6.4495\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.5197 - val_loss: 6.3653\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.4158 - val_loss: 6.2864\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.4671 - val_loss: 6.2106\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.1284 - val_loss: 6.1363\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.9770 - val_loss: 6.0634\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.9171 - val_loss: 5.9952\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - ETA: 0s - loss: 10.52 - 0s 2ms/step - loss: 9.8799 - val_loss: 5.9287\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.6071 - val_loss: 5.8586\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.5207 - val_loss: 5.7938\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.3643 - val_loss: 5.7299\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.2368 - val_loss: 5.6674\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.1185 - val_loss: 5.6095\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.1355 - val_loss: 5.5501\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.8924 - val_loss: 5.4925\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.7578 - val_loss: 5.4371\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.6324 - val_loss: 5.3819\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.4993 - val_loss: 5.3319\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.4817 - val_loss: 5.2811\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.4988 - val_loss: 5.2312\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.3971 - val_loss: 5.1814\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.3056 - val_loss: 5.1335\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.2040 - val_loss: 5.0860\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.1922 - val_loss: 5.0420\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.0438 - val_loss: 4.9981\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.9612 - val_loss: 4.9555\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.7970 - val_loss: 4.9137\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.7655 - val_loss: 4.8702\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.6255 - val_loss: 4.8295\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.6323 - val_loss: 4.7904\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.3465 - val_loss: 4.7500\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.4999 - val_loss: 4.7129\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.4498 - val_loss: 4.6775\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.3881 - val_loss: 4.6426\n",
      "Model: \"sequential_208\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1464 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1257 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1465 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1258 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1466 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1259 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1467 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1260 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1468 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1261 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1469 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1262 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1470 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1263 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1471 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1264 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1472 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 154s 1s/step - loss: 183.9793 - val_loss: 65.6881\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 160.8335 - val_loss: 59.4320\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 137.7807 - val_loss: 54.5728\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 124.8475 - val_loss: 50.6457\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 114.0584 - val_loss: 47.3891\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 103.8290 - val_loss: 44.6605\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 98.6282 - val_loss: 42.3943\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 92.5985 - val_loss: 40.4011\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 86.5597 - val_loss: 38.6769\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 82.1564 - val_loss: 37.0931\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 77.0257 - val_loss: 35.6687\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 72.9150 - val_loss: 34.3933\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 70.4282 - val_loss: 33.1478\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 66.9187 - val_loss: 31.9551\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 63.9470 - val_loss: 30.8410\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 60.8728 - val_loss: 29.7573\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 57.9038 - val_loss: 28.6380\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 55.1393 - val_loss: 27.5150\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 52.3834 - val_loss: 26.3785\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 50.0615 - val_loss: 25.2625\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 47.5459 - val_loss: 24.1551\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 44.4567 - val_loss: 23.1073\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 42.5511 - val_loss: 22.0932\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 40.3099 - val_loss: 21.1913\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 38.5037 - val_loss: 20.3568\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 36.2623 - val_loss: 19.6109\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 34.8368 - val_loss: 18.9655\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 33.2511 - val_loss: 18.3580\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 31.6824 - val_loss: 17.7351\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 30.2993 - val_loss: 17.2042\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 29.2029 - val_loss: 16.6848\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 27.9180 - val_loss: 16.2037\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 27.0189 - val_loss: 15.7688\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 26.2215 - val_loss: 15.3507\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 24.7759 - val_loss: 14.9583\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 24.5725 - val_loss: 14.5782\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 23.2662 - val_loss: 14.2273\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22.8319 - val_loss: 13.8987\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22.0789 - val_loss: 13.5521\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21.6106 - val_loss: 13.2377\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20.8238 - val_loss: 12.9421\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20.0416 - val_loss: 12.6779\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 19.7035 - val_loss: 12.4140\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 19.1548 - val_loss: 12.1443\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.6398 - val_loss: 11.8966\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.2484 - val_loss: 11.6493\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.6702 - val_loss: 11.4338\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.3038 - val_loss: 11.2335\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.8851 - val_loss: 11.0256\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.5294 - val_loss: 10.8056\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.9481 - val_loss: 10.6055\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.9212 - val_loss: 10.4118\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.5054 - val_loss: 10.2272\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.0924 - val_loss: 10.0577\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.9870 - val_loss: 9.8950\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.5230 - val_loss: 9.7140\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.3339 - val_loss: 9.5557\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.0024 - val_loss: 9.3958\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.7392 - val_loss: 9.2422\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.3386 - val_loss: 9.0884\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.3522 - val_loss: 8.9375\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.0906 - val_loss: 8.8014\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.8566 - val_loss: 8.6648\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.4361 - val_loss: 8.5447\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.4583 - val_loss: 8.4223\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.9651 - val_loss: 8.2991\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.8293 - val_loss: 8.1854\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.6472 - val_loss: 8.0622\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.5292 - val_loss: 7.9494\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.1025 - val_loss: 7.8475\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.3034 - val_loss: 7.7476\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.0870 - val_loss: 7.6367\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.7922 - val_loss: 7.5376\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.6326 - val_loss: 7.4424\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.4463 - val_loss: 7.3427\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.2984 - val_loss: 7.2446\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.0883 - val_loss: 7.1593\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.1743 - val_loss: 7.0716\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.9091 - val_loss: 6.9801\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.7622 - val_loss: 6.8981\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - ETA: 0s - loss: 10.18 - 0s 2ms/step - loss: 9.7892 - val_loss: 6.8136\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.5536 - val_loss: 6.7318\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.4017 - val_loss: 6.6655\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.1711 - val_loss: 6.5966\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.0338 - val_loss: 6.5264\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.2498 - val_loss: 6.4565\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.9108 - val_loss: 6.3907\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.7864 - val_loss: 6.3217\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.7582 - val_loss: 6.2562\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.5995 - val_loss: 6.1917\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.5800 - val_loss: 6.1274\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.4122 - val_loss: 6.0734\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.3132 - val_loss: 6.0183\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.2074 - val_loss: 5.9614\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.1762 - val_loss: 5.9052\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.2251 - val_loss: 5.8504\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.1198 - val_loss: 5.7969\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.9693 - val_loss: 5.7436\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.7766 - val_loss: 5.6967\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.8460 - val_loss: 5.6428\n",
      "['../Cli3/UTSW_Cli_224P_OrderFea_10_SMOTE_CV_it_2_10_3.mat', '../PrePost/PET_MOO/HN_MR_1_PPD_SMOTE_CV5_fea50_it_50_3.mat', '../PrePost/CT_MOO/HN_MR_1_PPD_SMOTE_CV5_fea50_val_it_50_3.mat']\n",
      "\n",
      "... Processing ../PrePost/PET_MOO/HN_MR_1_PPD_SMOTE_CV5_fea50_it_50_3 ...\n",
      "PET_feature shape is (179, 50)\n",
      "\n",
      "... Processing ../PrePost/CT_MOO/HN_MR_1_PPD_SMOTE_CV5_fea50_val_it_50_3 ...\n",
      "CT_feature shape is (179, 50)\n",
      "\n",
      "Feature shape is (179, 50)\n",
      "\n",
      "Label shape is (179, 1)\n",
      "\n",
      "Feature test shape is (45, 50)\n",
      "\n",
      "Label test shape is (45, 1)\n",
      "\n",
      "After SMOTE feature shape is (268, 50)\n",
      "Model: \"sequential_209\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1473 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1265 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1474 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1266 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1475 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1267 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1476 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1268 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1477 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1269 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1478 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1270 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1479 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1271 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1480 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1272 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1481 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 154s 1s/step - loss: 170.3939 - val_loss: 52.3782\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 141.9044 - val_loss: 46.3308\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 123.6801 - val_loss: 41.5760\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 111.1674 - val_loss: 37.9406\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 102.5632 - val_loss: 35.0338\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 87.7013 - val_loss: 32.7215\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 82.7427 - val_loss: 30.7858\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 78.1350 - val_loss: 29.1533\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 71.2844 - val_loss: 27.7589\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 67.6444 - val_loss: 26.5109\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 64.1124 - val_loss: 25.4147\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 60.5512 - val_loss: 24.4067\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 57.1917 - val_loss: 23.4710\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 54.8087 - val_loss: 22.5825\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 52.2582 - val_loss: 21.7184\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 49.7068 - val_loss: 20.8749\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 47.5109 - val_loss: 20.0227\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 44.2283 - val_loss: 19.1853\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 43.0848 - val_loss: 18.3354\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 41.4184 - val_loss: 17.4725\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 38.9689 - val_loss: 16.6095\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 35.8946 - val_loss: 15.7533\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 34.9785 - val_loss: 14.9177\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 32.9703 - val_loss: 14.1063\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 30.8120 - val_loss: 13.3301\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 29.2861 - val_loss: 12.5972\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 2ms/step - loss: 27.3233 - val_loss: 11.9297\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 26.3235 - val_loss: 11.3388\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 24.8909 - val_loss: 10.8177\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 23.6999 - val_loss: 10.3812\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22.5115 - val_loss: 10.0075\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21.9055 - val_loss: 9.6745\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21.1437 - val_loss: 9.3719\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20.1623 - val_loss: 9.0953\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 19.5137 - val_loss: 8.8398\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 19.0632 - val_loss: 8.6056\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.6365 - val_loss: 8.3833\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.8010 - val_loss: 8.1704\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.1653 - val_loss: 7.9711\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.7370 - val_loss: 7.7790\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.9823 - val_loss: 7.5954\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.0015 - val_loss: 7.4349\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.1974 - val_loss: 7.2819\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.9710 - val_loss: 7.1323\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.6758 - val_loss: 6.9970\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.2988 - val_loss: 6.8638\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.0950 - val_loss: 6.7305\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.8071 - val_loss: 6.6071\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.5251 - val_loss: 6.4866\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.1456 - val_loss: 6.3722\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.8526 - val_loss: 6.2654\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.5168 - val_loss: 6.1616\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.5036 - val_loss: 6.0656\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.1866 - val_loss: 5.9716\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.6579 - val_loss: 5.8810\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.5374 - val_loss: 5.7951\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.3302 - val_loss: 5.7105\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.4441 - val_loss: 5.6258\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.9540 - val_loss: 5.5480\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.9088 - val_loss: 5.4724\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.7167 - val_loss: 5.3961\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.4186 - val_loss: 5.3213\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.2014 - val_loss: 5.2511\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.2643 - val_loss: 5.1864\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.0294 - val_loss: 5.1248\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.9657 - val_loss: 5.0628\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.7458 - val_loss: 5.0019\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.5502 - val_loss: 4.9434\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.4420 - val_loss: 4.8848\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.2761 - val_loss: 4.8301\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.1742 - val_loss: 4.7767\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.1177 - val_loss: 4.7259\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.9542 - val_loss: 4.6753\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.7571 - val_loss: 4.6247\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.6958 - val_loss: 4.5771\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.5996 - val_loss: 4.5301\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.4960 - val_loss: 4.4861\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.4608 - val_loss: 4.4417\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.3372 - val_loss: 4.3995\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.3516 - val_loss: 4.3591\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.1839 - val_loss: 4.3166\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.0669 - val_loss: 4.2780\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.9869 - val_loss: 4.2413\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.7766 - val_loss: 4.2037\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.7752 - val_loss: 4.1668\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.7571 - val_loss: 4.1296\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.6541 - val_loss: 4.0949\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.5683 - val_loss: 4.0609\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.5174 - val_loss: 4.0288\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.4775 - val_loss: 3.9964\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.2376 - val_loss: 3.9648\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.4220 - val_loss: 3.9338\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.2469 - val_loss: 3.9033\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.2001 - val_loss: 3.8749\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.1183 - val_loss: 3.8459\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6.9659 - val_loss: 3.8178\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6.9842 - val_loss: 3.7891\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6.8971 - val_loss: 3.7631\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6.8658 - val_loss: 3.7371\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6.8065 - val_loss: 3.7124\n",
      "Model: \"sequential_210\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1482 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1273 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1483 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1274 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1484 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1275 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1485 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1276 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1486 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1277 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1487 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1278 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1488 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1279 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1489 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1280 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1490 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 146s 1s/step - loss: 202.0601 - val_loss: 78.2941\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 165.6220 - val_loss: 69.6649\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 151.2701 - val_loss: 62.9058\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 129.9020 - val_loss: 57.6281\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 120.3449 - val_loss: 53.1856\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 106.2174 - val_loss: 49.6064\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 99.5692 - val_loss: 46.6383\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 92.2629 - val_loss: 44.1386\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 86.1286 - val_loss: 41.9680\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 82.2421 - val_loss: 40.0858\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 75.7334 - val_loss: 38.4419\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 74.7781 - val_loss: 36.9162\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 71.5887 - val_loss: 35.5218\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 68.1906 - val_loss: 34.1910\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 65.6743 - val_loss: 32.9451\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 61.9450 - val_loss: 31.7688\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 59.9130 - val_loss: 30.6443\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 57.2806 - val_loss: 29.5580\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 54.0448 - val_loss: 28.5141\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 52.0250 - val_loss: 27.4722\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 50.4522 - val_loss: 26.4365\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 48.3110 - val_loss: 25.4120\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 46.8394 - val_loss: 24.3969\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 44.4604 - val_loss: 23.4142\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 42.2881 - val_loss: 22.4765\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 39.5745 - val_loss: 21.5465\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 38.0896 - val_loss: 20.6367\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 36.2349 - val_loss: 19.7694\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 34.5120 - val_loss: 18.9473\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 33.0035 - val_loss: 18.1845\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 31.4300 - val_loss: 17.4856\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 29.9937 - val_loss: 16.8465\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 28.8432 - val_loss: 16.2785\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 27.6037 - val_loss: 15.7681\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 26.6192 - val_loss: 15.2851\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 25.9581 - val_loss: 14.8411\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 24.7631 - val_loss: 14.4403\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 24.1617 - val_loss: 14.0542\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 23.1594 - val_loss: 13.7102\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22.9257 - val_loss: 13.3674\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21.9736 - val_loss: 13.0479\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21.3186 - val_loss: 12.7599\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20.8031 - val_loss: 12.4732\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20.5628 - val_loss: 12.2128\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 19.4821 - val_loss: 11.9620\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 19.1611 - val_loss: 11.7123\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.8777 - val_loss: 11.4837\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.4127 - val_loss: 11.2641\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.8004 - val_loss: 11.0597\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.3981 - val_loss: 10.8629\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.5739 - val_loss: 10.6780\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.2868 - val_loss: 10.4965\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.0693 - val_loss: 10.3267\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.8163 - val_loss: 10.1660\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.4222 - val_loss: 9.9992\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.1319 - val_loss: 9.8328\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.6194 - val_loss: 9.6858\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.2231 - val_loss: 9.5377\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.1436 - val_loss: 9.3895\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.9827 - val_loss: 9.2461\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.5566 - val_loss: 9.1145\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.3960 - val_loss: 8.9949\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.1720 - val_loss: 8.8678\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.9064 - val_loss: 8.7446\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.5804 - val_loss: 8.6235\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.3985 - val_loss: 8.5166\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.0885 - val_loss: 8.4109\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.7960 - val_loss: 8.3062\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.6957 - val_loss: 8.2015\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.4410 - val_loss: 8.1056\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.4520 - val_loss: 8.0028\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.1757 - val_loss: 7.9158\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.8669 - val_loss: 7.8274\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.8341 - val_loss: 7.7393\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.5146 - val_loss: 7.6516\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.6471 - val_loss: 7.5634\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.3442 - val_loss: 7.4837\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.1729 - val_loss: 7.4097\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.9657 - val_loss: 7.3356\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.0060 - val_loss: 7.2675\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.6820 - val_loss: 7.1992\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.6026 - val_loss: 7.1326\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.3603 - val_loss: 7.0694\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.3864 - val_loss: 7.0106\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.2664 - val_loss: 6.9452\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.2009 - val_loss: 6.8762\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.1643 - val_loss: 6.8098\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.8211 - val_loss: 6.7520\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.7049 - val_loss: 6.6923\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.6691 - val_loss: 6.6377\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.6004 - val_loss: 6.5829\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.5825 - val_loss: 6.5323\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.3727 - val_loss: 6.4833\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.2452 - val_loss: 6.4359\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.1832 - val_loss: 6.3887\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.0882 - val_loss: 6.3340\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.9203 - val_loss: 6.2905\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.9818 - val_loss: 6.2487\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.7811 - val_loss: 6.2051\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.7998 - val_loss: 6.1595\n",
      "\n",
      "Feature shape is (179, 50)\n",
      "\n",
      "Feature test shape is (45, 50)\n",
      "\n",
      "After SMOTE feature shape is (268, 50)\n",
      "Model: \"sequential_211\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1491 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1281 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1492 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1282 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1493 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1283 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1494 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1284 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1495 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1285 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1496 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1286 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1497 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1287 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1498 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1288 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1499 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 152s 1s/step - loss: 202.6171 - val_loss: 99.7902\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 168.2854 - val_loss: 86.2564\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 142.8878 - val_loss: 75.7969\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 123.8309 - val_loss: 67.8349\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 109.8646 - val_loss: 61.6454\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 99.1621 - val_loss: 56.7890\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 89.9949 - val_loss: 52.8200\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 82.6975 - val_loss: 49.5941\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 77.4136 - val_loss: 46.9365\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 73.1191 - val_loss: 44.6821\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 69.4887 - val_loss: 42.7137\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 65.4748 - val_loss: 40.9753\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 62.6835 - val_loss: 39.4399\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 59.8199 - val_loss: 38.0773\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 57.5614 - val_loss: 36.7806\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 55.6408 - val_loss: 35.5642\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 53.4551 - val_loss: 34.4495\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 50.8136 - val_loss: 33.4061\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 48.7394 - val_loss: 32.3876\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 47.0348 - val_loss: 31.3719\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 45.4015 - val_loss: 30.3821\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 43.5758 - val_loss: 29.4290\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 42.1517 - val_loss: 28.4576\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 40.0510 - val_loss: 27.5126\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 38.2618 - val_loss: 26.5883\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 36.9957 - val_loss: 25.6495\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 35.2844 - val_loss: 24.7369\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 33.3922 - val_loss: 23.8755\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 31.4048 - val_loss: 23.0696\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 30.5144 - val_loss: 22.2985\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 29.1435 - val_loss: 21.5778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 28.3683 - val_loss: 20.9306\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 26.4880 - val_loss: 20.3408\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 25.5540 - val_loss: 19.7831\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 24.9238 - val_loss: 19.2742\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 24.1074 - val_loss: 18.8135\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 23.4746 - val_loss: 18.3881\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22.3992 - val_loss: 18.0091\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21.7220 - val_loss: 17.6535\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21.3609 - val_loss: 17.2958\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20.7626 - val_loss: 16.9722\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20.5870 - val_loss: 16.6541\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 19.6755 - val_loss: 16.3655\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.9195 - val_loss: 16.0943\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.4754 - val_loss: 15.8215\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.3964 - val_loss: 15.5679\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.1656 - val_loss: 15.3101\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.6163 - val_loss: 15.0750\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.9956 - val_loss: 14.8528\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.3517 - val_loss: 14.6147\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.4007 - val_loss: 14.3976\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.3740 - val_loss: 14.1960\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.7271 - val_loss: 13.9807\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.5970 - val_loss: 13.7651\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.2983 - val_loss: 13.5787\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.6440 - val_loss: 13.3950\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.5701 - val_loss: 13.2076\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.3199 - val_loss: 13.0267\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.1558 - val_loss: 12.8473\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.7997 - val_loss: 12.6870\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.5884 - val_loss: 12.5156\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.5878 - val_loss: 12.3591\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.0806 - val_loss: 12.2008\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.9207 - val_loss: 12.0496\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.8487 - val_loss: 11.9045\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.9226 - val_loss: 11.7597\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.4392 - val_loss: 11.6145\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.2348 - val_loss: 11.4693\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.0589 - val_loss: 11.3357\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.8719 - val_loss: 11.2061\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.7406 - val_loss: 11.0926\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.6483 - val_loss: 10.9638\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.2134 - val_loss: 10.8340\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.4133 - val_loss: 10.7010\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.2092 - val_loss: 10.5950\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.0333 - val_loss: 10.4895\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.0270 - val_loss: 10.3723\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.7400 - val_loss: 10.2706\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.7867 - val_loss: 10.1702\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.2452 - val_loss: 10.0581\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.2451 - val_loss: 9.9508\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.3120 - val_loss: 9.8547\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.0738 - val_loss: 9.7416\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.8323 - val_loss: 9.6374\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.6222 - val_loss: 9.5497\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.6888 - val_loss: 9.4604\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.7302 - val_loss: 9.3756\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.4588 - val_loss: 9.2913\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.3435 - val_loss: 9.2089\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.2394 - val_loss: 9.1149\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.1048 - val_loss: 9.0414\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.1145 - val_loss: 8.9603\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.8674 - val_loss: 8.8855\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.7561 - val_loss: 8.7995\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.6758 - val_loss: 8.7242\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.6709 - val_loss: 8.6494\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.7328 - val_loss: 8.5711\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.6116 - val_loss: 8.5049\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.4335 - val_loss: 8.4385\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.5856 - val_loss: 8.3657\n",
      "Model: \"sequential_212\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1500 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1289 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1501 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1290 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1502 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1291 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1503 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1292 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1504 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1293 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1505 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1294 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1506 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1295 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1507 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1296 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1508 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 154s 1s/step - loss: 193.7415 - val_loss: 77.7454\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 167.0991 - val_loss: 69.9352\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 142.6715 - val_loss: 63.9712\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 130.1976 - val_loss: 59.0946\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 115.4127 - val_loss: 55.1133\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 109.6380 - val_loss: 51.8305\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 99.0987 - val_loss: 48.9991\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 92.5336 - val_loss: 46.6265\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 84.4306 - val_loss: 44.5797\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 81.7063 - val_loss: 42.7802\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 77.6022 - val_loss: 41.2300\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 73.3231 - val_loss: 39.8105\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 71.3850 - val_loss: 38.4885\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 68.3481 - val_loss: 37.2601\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 64.7269 - val_loss: 36.1050\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 61.4953 - val_loss: 34.9070\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 59.9699 - val_loss: 33.7800\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 56.5409 - val_loss: 32.7439\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 54.6236 - val_loss: 31.6678\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 51.6821 - val_loss: 30.5541\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 50.1523 - val_loss: 29.4221\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 47.7066 - val_loss: 28.3124\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 45.0966 - val_loss: 27.2900\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 42.9954 - val_loss: 26.2762\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 40.9724 - val_loss: 25.2343\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 38.8885 - val_loss: 24.2529\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 37.0494 - val_loss: 23.2738\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 35.0893 - val_loss: 22.4136\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 33.4104 - val_loss: 21.6278\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 32.0083 - val_loss: 20.8952\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 30.1912 - val_loss: 20.2334\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 28.8323 - val_loss: 19.6188\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 27.9501 - val_loss: 19.1190\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 26.7349 - val_loss: 18.6550\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 26.7781 - val_loss: 18.1867\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 25.3325 - val_loss: 17.8001\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 24.3851 - val_loss: 17.3734\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 23.3380 - val_loss: 16.9548\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22.8956 - val_loss: 16.6086\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22.4460 - val_loss: 16.2513\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21.6053 - val_loss: 15.9291\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20.9277 - val_loss: 15.6320\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20.3231 - val_loss: 15.3539\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 19.8498 - val_loss: 15.0353\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 19.3750 - val_loss: 14.7440\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.8847 - val_loss: 14.4914\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.1672 - val_loss: 14.2268\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.7464 - val_loss: 13.9552\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.3604 - val_loss: 13.6930\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.0753 - val_loss: 13.4506\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.6637 - val_loss: 13.2155\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.9218 - val_loss: 12.9861\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.1089 - val_loss: 12.7589\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.5534 - val_loss: 12.5591\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.2700 - val_loss: 12.3828\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.9333 - val_loss: 12.2314\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.7153 - val_loss: 12.0437\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.3555 - val_loss: 11.8632\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.1477 - val_loss: 11.6762\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.8712 - val_loss: 11.4983\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.4434 - val_loss: 11.3616\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.4478 - val_loss: 11.1746\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.0743 - val_loss: 11.0294\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.5703 - val_loss: 10.8620\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.6319 - val_loss: 10.7254\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.3864 - val_loss: 10.5856\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.1628 - val_loss: 10.4387\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.8446 - val_loss: 10.3024\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.6662 - val_loss: 10.1745\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.5457 - val_loss: 10.0496\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.2051 - val_loss: 9.9341\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.1137 - val_loss: 9.8139\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.0493 - val_loss: 9.7144\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.9214 - val_loss: 9.5932\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.7413 - val_loss: 9.4970\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.3760 - val_loss: 9.3955\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.2817 - val_loss: 9.2892\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.1769 - val_loss: 9.1995\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.1067 - val_loss: 9.1019\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.8127 - val_loss: 9.0187\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.6352 - val_loss: 8.9103\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.6199 - val_loss: 8.8128\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.3958 - val_loss: 8.7208\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.4212 - val_loss: 8.6346\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.3660 - val_loss: 8.5519\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.2235 - val_loss: 8.4744\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.1477 - val_loss: 8.3913\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.0555 - val_loss: 8.3176\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.8645 - val_loss: 8.2434\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.7940 - val_loss: 8.1837\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.5569 - val_loss: 8.1208\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.4785 - val_loss: 8.0529\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.4460 - val_loss: 7.9647\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.4726 - val_loss: 7.9018\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.4237 - val_loss: 7.8354\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.1186 - val_loss: 7.7657\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.9559 - val_loss: 7.7018\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.0570 - val_loss: 7.6509\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.9153 - val_loss: 7.5898\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.8250 - val_loss: 7.5275\n",
      "['../Cli3/UTSW_Cli_224P_OrderFea_10_SMOTE_CV_it_2_10_4.mat', '../PrePost/PET_MOO/HN_MR_1_PPD_SMOTE_CV5_fea50_it_50_4.mat', '../PrePost/CT_MOO/HN_MR_1_PPD_SMOTE_CV5_fea50_val_it_50_4.mat']\n",
      "\n",
      "... Processing ../PrePost/PET_MOO/HN_MR_1_PPD_SMOTE_CV5_fea50_it_50_4 ...\n",
      "PET_feature shape is (180, 50)\n",
      "\n",
      "... Processing ../PrePost/CT_MOO/HN_MR_1_PPD_SMOTE_CV5_fea50_val_it_50_4 ...\n",
      "CT_feature shape is (180, 50)\n",
      "\n",
      "Feature shape is (180, 50)\n",
      "\n",
      "Label shape is (180, 1)\n",
      "\n",
      "Feature test shape is (44, 50)\n",
      "\n",
      "Label test shape is (44, 1)\n",
      "\n",
      "After SMOTE feature shape is (268, 50)\n",
      "Model: \"sequential_213\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1509 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1297 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1510 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1298 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1511 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1299 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1512 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1300 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1513 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1301 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1514 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1302 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1515 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1303 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1516 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1304 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1517 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 160s 1s/step - loss: 173.2529 - val_loss: 81.0861\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 146.0018 - val_loss: 70.2231\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 123.7734 - val_loss: 61.7750\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 110.7313 - val_loss: 54.7778\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 98.2455 - val_loss: 49.3487\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 88.4941 - val_loss: 44.9085\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 81.3145 - val_loss: 41.1748\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 75.1199 - val_loss: 38.2220\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 69.4850 - val_loss: 35.6034\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 65.0299 - val_loss: 33.3664\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 61.2344 - val_loss: 31.4469\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 57.9542 - val_loss: 29.6910\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 54.6974 - val_loss: 28.1155\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 52.0266 - val_loss: 26.6528\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 49.2507 - val_loss: 25.2961\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 46.8698 - val_loss: 23.9787\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 44.4440 - val_loss: 22.6790\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 41.5044 - val_loss: 21.4990\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 39.3676 - val_loss: 20.3092\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 37.1455 - val_loss: 19.2273\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 35.1221 - val_loss: 18.1828\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 33.0105 - val_loss: 17.2265\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 30.7418 - val_loss: 16.3544\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 29.4524 - val_loss: 15.5858\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 28.0287 - val_loss: 14.8975\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 26.5579 - val_loss: 14.3085\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 2ms/step - loss: 25.8116 - val_loss: 13.7709\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 24.2699 - val_loss: 13.2955\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 23.3837 - val_loss: 12.8556\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22.3710 - val_loss: 12.4521\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21.5487 - val_loss: 12.0750\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20.9116 - val_loss: 11.7379\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20.2519 - val_loss: 11.4410\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 19.4037 - val_loss: 11.1521\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.9825 - val_loss: 10.8916\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.2095 - val_loss: 10.6317\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.8906 - val_loss: 10.3994\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.3173 - val_loss: 10.1755\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.9502 - val_loss: 9.9697\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.7139 - val_loss: 9.7654\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.0326 - val_loss: 9.5813\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.5890 - val_loss: 9.4041\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.1747 - val_loss: 9.2353\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.0401 - val_loss: 9.0699\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.4264 - val_loss: 8.9143\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.2283 - val_loss: 8.7679\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.0097 - val_loss: 8.6311\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.8291 - val_loss: 8.4975\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.2660 - val_loss: 8.3676\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.1842 - val_loss: 8.2430\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.0006 - val_loss: 8.1244\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.5932 - val_loss: 8.0088\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.2319 - val_loss: 7.8955\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.2588 - val_loss: 7.7921\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.7815 - val_loss: 7.6921\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.7518 - val_loss: 7.5875\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.5010 - val_loss: 7.4908\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.3173 - val_loss: 7.4007\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.0468 - val_loss: 7.3120\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.2785 - val_loss: 7.2229\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.8829 - val_loss: 7.1416\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.6872 - val_loss: 7.0544\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.3821 - val_loss: 6.9714\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.4259 - val_loss: 6.8919\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.1538 - val_loss: 6.8144\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.9191 - val_loss: 6.7449\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.9272 - val_loss: 6.6744\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.7573 - val_loss: 6.6055\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.6075 - val_loss: 6.5428\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.4271 - val_loss: 6.4785\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.2986 - val_loss: 6.4136\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.2130 - val_loss: 6.3519\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.0766 - val_loss: 6.2888\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.9457 - val_loss: 6.2316\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.7339 - val_loss: 6.1742\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.8768 - val_loss: 6.1155\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.5948 - val_loss: 6.0609\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.5358 - val_loss: 6.0068\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.4693 - val_loss: 5.9558\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.3124 - val_loss: 5.9028\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.1551 - val_loss: 5.8532\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.1885 - val_loss: 5.8047\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.0393 - val_loss: 5.7578\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.0532 - val_loss: 5.7083\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.8428 - val_loss: 5.6641\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.6660 - val_loss: 5.6211\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.7467 - val_loss: 5.5787\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.5956 - val_loss: 5.5382\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.6579 - val_loss: 5.4953\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.4300 - val_loss: 5.4536\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.6294 - val_loss: 5.4130\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.2720 - val_loss: 5.3752\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.3162 - val_loss: 5.3381\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.2440 - val_loss: 5.3014\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.1130 - val_loss: 5.2656\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.2019 - val_loss: 5.2315\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.0467 - val_loss: 5.1965\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6.8942 - val_loss: 5.1622\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6.8700 - val_loss: 5.1285\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6.7110 - val_loss: 5.0982\n",
      "Model: \"sequential_214\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1518 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1305 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1519 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1306 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1520 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1307 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1521 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1308 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1522 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1309 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1523 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1310 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1524 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1311 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1525 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1312 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1526 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 157s 1s/step - loss: 174.0925 - val_loss: 59.0966\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 148.4356 - val_loss: 52.5834\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 127.1890 - val_loss: 47.5395\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 115.3764 - val_loss: 43.6925\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 104.3417 - val_loss: 40.5674\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 96.1466 - val_loss: 37.9990\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 89.1143 - val_loss: 35.8648\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 83.5827 - val_loss: 34.0360\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 78.1272 - val_loss: 32.4012\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 73.3359 - val_loss: 30.9764\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 69.2254 - val_loss: 29.6792\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 65.5931 - val_loss: 28.4584\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 63.0276 - val_loss: 27.3060\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 60.0171 - val_loss: 26.1915\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 57.1807 - val_loss: 25.1010\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 54.5215 - val_loss: 24.0341\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 52.5205 - val_loss: 22.9617\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 49.6090 - val_loss: 21.9243\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 46.8089 - val_loss: 20.9023\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 44.6137 - val_loss: 19.9211\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 42.1691 - val_loss: 18.9845\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 40.1464 - val_loss: 18.0981\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 38.2961 - val_loss: 17.2827\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 36.0144 - val_loss: 16.5389\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 34.5199 - val_loss: 15.8631\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 33.0717 - val_loss: 15.2498\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 31.7541 - val_loss: 14.6921\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 29.8993 - val_loss: 14.1864\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 29.4622 - val_loss: 13.7137\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 28.4396 - val_loss: 13.2776\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 27.2392 - val_loss: 12.8675\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 26.2764 - val_loss: 12.4928\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 25.3891 - val_loss: 12.1443\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 24.5284 - val_loss: 11.8190\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 23.7272 - val_loss: 11.5085\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22.8042 - val_loss: 11.2146\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22.3931 - val_loss: 10.9380\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21.4862 - val_loss: 10.6706\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21.0189 - val_loss: 10.4168\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20.3495 - val_loss: 10.1799\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 19.5506 - val_loss: 9.9608\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 19.4582 - val_loss: 9.7504\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.8103 - val_loss: 9.5487\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.3170 - val_loss: 9.3556\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.7903 - val_loss: 9.1594\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.4503 - val_loss: 8.9774\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.8154 - val_loss: 8.7990\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.4867 - val_loss: 8.6268\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.1516 - val_loss: 8.4762\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.9529 - val_loss: 8.3217\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.6355 - val_loss: 8.1688\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.1870 - val_loss: 8.0283\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.8923 - val_loss: 7.8838\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.4815 - val_loss: 7.7531\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.2082 - val_loss: 7.6218\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.9177 - val_loss: 7.5020\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.7031 - val_loss: 7.3797\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.4711 - val_loss: 7.2632\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.0964 - val_loss: 7.1513\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.0034 - val_loss: 7.0426\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.7019 - val_loss: 6.9342\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.3921 - val_loss: 6.8261\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.1811 - val_loss: 6.7248\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.0837 - val_loss: 6.6222\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.6622 - val_loss: 6.5234\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.7530 - val_loss: 6.4281\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.4386 - val_loss: 6.3397\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.3002 - val_loss: 6.2522\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.0008 - val_loss: 6.1715\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.9445 - val_loss: 6.0911\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.6801 - val_loss: 6.0133\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.5106 - val_loss: 5.9359\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.3296 - val_loss: 5.8623\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.2205 - val_loss: 5.7948\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.9221 - val_loss: 5.7299\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.8806 - val_loss: 5.6594\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.7015 - val_loss: 5.5944\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.6964 - val_loss: 5.5296\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.5976 - val_loss: 5.4664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.4872 - val_loss: 5.4042\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.2321 - val_loss: 5.3451\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.1589 - val_loss: 5.2858\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.0491 - val_loss: 5.2327\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.9367 - val_loss: 5.1808\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.8622 - val_loss: 5.1288\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.6888 - val_loss: 5.0826\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.6478 - val_loss: 5.0336\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.4645 - val_loss: 4.9859\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.3595 - val_loss: 4.9366\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.3881 - val_loss: 4.8923\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.2921 - val_loss: 4.8468\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.1308 - val_loss: 4.8026\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.0448 - val_loss: 4.7605\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.9498 - val_loss: 4.7206\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.9325 - val_loss: 4.6790\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.8398 - val_loss: 4.6390\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.6566 - val_loss: 4.6022\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.6815 - val_loss: 4.5660\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.6421 - val_loss: 4.5308\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.4405 - val_loss: 4.4956\n",
      "\n",
      "Feature shape is (180, 50)\n",
      "\n",
      "Feature test shape is (44, 50)\n",
      "\n",
      "After SMOTE feature shape is (268, 50)\n",
      "Model: \"sequential_215\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1527 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1313 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1528 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1314 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1529 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1315 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1530 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1316 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1531 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1317 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1532 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1318 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1533 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1319 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1534 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1320 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1535 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 157s 1s/step - loss: 161.5696 - val_loss: 52.0485\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 128.8383 - val_loss: 44.4525\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 111.4091 - val_loss: 39.0685\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 96.2901 - val_loss: 35.1144\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 86.7509 - val_loss: 32.2689\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 78.6300 - val_loss: 30.1259\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 71.1881 - val_loss: 28.3956\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 68.1317 - val_loss: 27.0262\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 64.2074 - val_loss: 25.9141\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 61.6219 - val_loss: 24.8846\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 58.4893 - val_loss: 23.9311\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 55.4535 - val_loss: 23.0526\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 53.4278 - val_loss: 22.1571\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 50.9340 - val_loss: 21.3099\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 49.1142 - val_loss: 20.4781\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 46.9765 - val_loss: 19.7039\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 44.9969 - val_loss: 18.9211\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 43.3227 - val_loss: 18.1589\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 41.1055 - val_loss: 17.3335\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 39.2309 - val_loss: 16.5471\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 37.3030 - val_loss: 15.7367\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 35.6470 - val_loss: 14.9366\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 33.8398 - val_loss: 14.1592\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 31.8722 - val_loss: 13.4332\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 30.3613 - val_loss: 12.7727\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 28.6933 - val_loss: 12.1590\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 27.1978 - val_loss: 11.6122\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 26.4420 - val_loss: 11.1132\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 25.1307 - val_loss: 10.6597\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 24.1814 - val_loss: 10.2806\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 23.1112 - val_loss: 9.9200\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22.4703 - val_loss: 9.5840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22.1277 - val_loss: 9.3464\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20.9057 - val_loss: 9.0830\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20.2905 - val_loss: 8.8360\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 19.8187 - val_loss: 8.6327\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 19.0191 - val_loss: 8.4055\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.7026 - val_loss: 8.2046\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.2252 - val_loss: 8.0170\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.7265 - val_loss: 7.8416\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.3601 - val_loss: 7.6689\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.0275 - val_loss: 7.5149\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.5773 - val_loss: 7.3633\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.0410 - val_loss: 7.2349\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.7373 - val_loss: 7.0955\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.2649 - val_loss: 6.9612\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.1666 - val_loss: 6.8189\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.9086 - val_loss: 6.6845\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.5604 - val_loss: 6.5775\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.3154 - val_loss: 6.4617\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.0799 - val_loss: 6.3601\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.4557 - val_loss: 6.2614\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.4149 - val_loss: 6.1595\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.2459 - val_loss: 6.0724\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.8377 - val_loss: 5.9846\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.8305 - val_loss: 5.8995\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.6028 - val_loss: 5.8169\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.1611 - val_loss: 5.7420\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.1911 - val_loss: 5.6525\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.9179 - val_loss: 5.5723\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.8594 - val_loss: 5.4991\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.4254 - val_loss: 5.4296\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.3784 - val_loss: 5.3602\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.3010 - val_loss: 5.2863\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.0126 - val_loss: 5.2298\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.8275 - val_loss: 5.1734\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.6938 - val_loss: 5.1136\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.5434 - val_loss: 5.0454\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.4755 - val_loss: 4.9746\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.1727 - val_loss: 4.9280\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.1243 - val_loss: 4.8646\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.9226 - val_loss: 4.8123\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.7448 - val_loss: 4.7570\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.6064 - val_loss: 4.7138\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.5895 - val_loss: 4.6622\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.4917 - val_loss: 4.6128\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.2227 - val_loss: 4.5680\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.2541 - val_loss: 4.5232\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.1581 - val_loss: 4.4877\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.0352 - val_loss: 4.4463\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.8101 - val_loss: 4.4086\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.8469 - val_loss: 4.3687\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.5539 - val_loss: 4.3258\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.7163 - val_loss: 4.2851\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.5172 - val_loss: 4.2446\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.5269 - val_loss: 4.2067\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.3980 - val_loss: 4.1700\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.3315 - val_loss: 4.1298\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.1863 - val_loss: 4.0969\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.0613 - val_loss: 4.0628\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.0458 - val_loss: 4.0325\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.7511 - val_loss: 4.0012\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.8684 - val_loss: 3.9680\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.7816 - val_loss: 3.9397\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.7209 - val_loss: 3.9074\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.7272 - val_loss: 3.8767\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.5427 - val_loss: 3.8461\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.6056 - val_loss: 3.8136\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.3633 - val_loss: 3.7838\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.4625 - val_loss: 3.7623\n",
      "Model: \"sequential_216\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1536 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1321 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1537 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1322 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1538 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1323 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1539 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1324 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1540 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1325 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1541 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1326 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1542 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1327 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1543 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1328 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1544 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 163s 1s/step - loss: 191.6687 - val_loss: 68.7881\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 165.9885 - val_loss: 61.2454\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 142.1096 - val_loss: 55.2948\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 124.5969 - val_loss: 50.9410\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 115.1747 - val_loss: 47.3545\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 106.6653 - val_loss: 44.4041\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 98.1409 - val_loss: 41.9555\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 90.0467 - val_loss: 39.8472\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 85.8710 - val_loss: 38.0545\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 81.7258 - val_loss: 36.4488\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 77.9927 - val_loss: 35.0488\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 74.5097 - val_loss: 33.8115\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 70.5897 - val_loss: 32.6646\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 67.6812 - val_loss: 31.6072\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 64.4086 - val_loss: 30.6442\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 62.4552 - val_loss: 29.7261\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 59.6235 - val_loss: 28.8561\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 57.8124 - val_loss: 27.9897\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 55.9858 - val_loss: 27.1188\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 53.7023 - val_loss: 26.2744\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 51.0212 - val_loss: 25.4607\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 49.5658 - val_loss: 24.6362\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 47.3746 - val_loss: 23.7874\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 45.9329 - val_loss: 22.9644\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 43.5062 - val_loss: 22.1083\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 41.9882 - val_loss: 21.2805\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 40.1157 - val_loss: 20.4583\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 38.1629 - val_loss: 19.6529\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 35.8463 - val_loss: 18.8693\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 34.7652 - val_loss: 18.0893\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 32.9089 - val_loss: 17.3576\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 31.6894 - val_loss: 16.6475\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 30.2945 - val_loss: 15.9821\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 28.7122 - val_loss: 15.3710\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 27.3123 - val_loss: 14.8189\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 26.2579 - val_loss: 14.3000\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 24.9921 - val_loss: 13.8429\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 24.5839 - val_loss: 13.4188\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 23.4260 - val_loss: 13.0547\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22.6148 - val_loss: 12.7087\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22.2451 - val_loss: 12.3889\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21.0575 - val_loss: 12.0813\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20.7298 - val_loss: 11.8065\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 19.6949 - val_loss: 11.5281\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 19.7971 - val_loss: 11.2559\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 19.0664 - val_loss: 11.0114\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.3225 - val_loss: 10.7856\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.9635 - val_loss: 10.5594\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.6099 - val_loss: 10.3341\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.0473 - val_loss: 10.1235\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.9126 - val_loss: 9.9322\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.5206 - val_loss: 9.7324\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.1106 - val_loss: 9.5523\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.5773 - val_loss: 9.3755\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.9293 - val_loss: 9.2039\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.0102 - val_loss: 9.0388\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.7503 - val_loss: 8.8896\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.3436 - val_loss: 8.7409\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.8926 - val_loss: 8.5944\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.7755 - val_loss: 8.4433\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.5090 - val_loss: 8.3073\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.1381 - val_loss: 8.1819\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.8702 - val_loss: 8.0600\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.6771 - val_loss: 7.9462\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.3164 - val_loss: 7.8295\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.3193 - val_loss: 7.7205\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.1423 - val_loss: 7.6080\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.8863 - val_loss: 7.5056\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.8725 - val_loss: 7.4043\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.5338 - val_loss: 7.3003\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.4265 - val_loss: 7.2031\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.0226 - val_loss: 7.1014\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.0464 - val_loss: 7.0057\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.8637 - val_loss: 6.9218\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.5055 - val_loss: 6.8388\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.4388 - val_loss: 6.7518\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.3040 - val_loss: 6.6775\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.9802 - val_loss: 6.5894\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.9888 - val_loss: 6.5066\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.7800 - val_loss: 6.4349\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.6174 - val_loss: 6.3611\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.5836 - val_loss: 6.2872\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.4676 - val_loss: 6.2208\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.2675 - val_loss: 6.1523\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.3584 - val_loss: 6.0866\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.0523 - val_loss: 6.0235\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.0962 - val_loss: 5.9583\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.8379 - val_loss: 5.8958\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.7599 - val_loss: 5.8374\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.7373 - val_loss: 5.7769\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.4749 - val_loss: 5.7199\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.4143 - val_loss: 5.6657\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.2688 - val_loss: 5.6123\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.1998 - val_loss: 5.5576\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.1899 - val_loss: 5.5056\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.2693 - val_loss: 5.4604\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.0297 - val_loss: 5.4056\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.0010 - val_loss: 5.3583\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.8087 - val_loss: 5.3101\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.7647 - val_loss: 5.2672\n",
      "['../Cli3/UTSW_Cli_224P_OrderFea_10_SMOTE_CV_it_2_10_5.mat', '../PrePost/PET_MOO/HN_MR_1_PPD_SMOTE_CV5_fea50_it_50_5.mat', '../PrePost/CT_MOO/HN_MR_1_PPD_SMOTE_CV5_fea50_val_it_50_5.mat']\n",
      "\n",
      "... Processing ../PrePost/PET_MOO/HN_MR_1_PPD_SMOTE_CV5_fea50_it_50_5 ...\n",
      "PET_feature shape is (178, 50)\n",
      "\n",
      "... Processing ../PrePost/CT_MOO/HN_MR_1_PPD_SMOTE_CV5_fea50_val_it_50_5 ...\n",
      "CT_feature shape is (178, 50)\n",
      "\n",
      "Feature shape is (178, 50)\n",
      "\n",
      "Label shape is (178, 1)\n",
      "\n",
      "Feature test shape is (46, 50)\n",
      "\n",
      "Label test shape is (46, 1)\n",
      "\n",
      "After SMOTE feature shape is (266, 50)\n",
      "Model: \"sequential_217\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1545 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1329 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1546 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1330 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1547 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1331 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1548 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1332 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1549 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1333 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1550 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1334 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1551 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1335 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1552 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1336 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1553 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 163s 1s/step - loss: 186.9258 - val_loss: 97.9904\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 154.3643 - val_loss: 81.3722\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 129.1334 - val_loss: 69.9363\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 112.5390 - val_loss: 61.1198\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 99.3455 - val_loss: 54.5396\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 88.7500 - val_loss: 49.4370\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 81.3650 - val_loss: 45.2482\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 74.8496 - val_loss: 41.8797\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 69.9738 - val_loss: 39.0893\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 65.1410 - val_loss: 36.7794\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 62.0521 - val_loss: 34.7013\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 59.2208 - val_loss: 32.8715\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 56.5679 - val_loss: 31.2159\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 53.8840 - val_loss: 29.7376\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 51.6248 - val_loss: 28.3662\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 49.4155 - val_loss: 27.0598\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 47.4224 - val_loss: 25.8754\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 45.7108 - val_loss: 24.8003\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 43.3622 - val_loss: 23.7641\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 41.5685 - val_loss: 22.7648\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 39.7825 - val_loss: 21.8017\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 38.0465 - val_loss: 20.8693\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 36.6116 - val_loss: 19.9565\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 34.6494 - val_loss: 19.0671\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 33.0806 - val_loss: 18.2062\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 31.5105 - val_loss: 17.3939\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 29.7000 - val_loss: 16.6076\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 28.7255 - val_loss: 15.8804\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 27.1474 - val_loss: 15.2266\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 26.1291 - val_loss: 14.6047\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 24.8022 - val_loss: 14.0365\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 24.0465 - val_loss: 13.5366\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 22.8217 - val_loss: 13.0780\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 22.0213 - val_loss: 12.6679\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 21.0068 - val_loss: 12.2949\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 20.4744 - val_loss: 11.9387\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 19.9303 - val_loss: 11.6179\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 19.5613 - val_loss: 11.3114\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 18.6129 - val_loss: 11.0167\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 18.2601 - val_loss: 10.7414\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 17.3694 - val_loss: 10.4734\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 17.1826 - val_loss: 10.2395\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.5229 - val_loss: 10.0061\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.4896 - val_loss: 9.7811\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.8627 - val_loss: 9.5843\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.3151 - val_loss: 9.3852\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.9168 - val_loss: 9.2045\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.7634 - val_loss: 9.0237\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.3695 - val_loss: 8.8547\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.9664 - val_loss: 8.6966\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.6264 - val_loss: 8.5435\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.5086 - val_loss: 8.3998\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.2441 - val_loss: 8.2606\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.9820 - val_loss: 8.1200\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.6783 - val_loss: 7.9944\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.3091 - val_loss: 7.8654\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.0024 - val_loss: 7.7447\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.9650 - val_loss: 7.6274\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.6150 - val_loss: 7.5164\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.4788 - val_loss: 7.4111\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.2671 - val_loss: 7.3066\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.0370 - val_loss: 7.2027\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.9298 - val_loss: 7.1054\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.6823 - val_loss: 7.0092\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.4624 - val_loss: 6.9209\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.2507 - val_loss: 6.8330\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.0262 - val_loss: 6.7495\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.8523 - val_loss: 6.6715\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.9547 - val_loss: 6.5928\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.8018 - val_loss: 6.5172\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.5474 - val_loss: 6.4485\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.3626 - val_loss: 6.3761\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.4352 - val_loss: 6.3093\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.1330 - val_loss: 6.2422\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.9184 - val_loss: 6.1808\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.8796 - val_loss: 6.1203\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.8410 - val_loss: 6.0631\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.6712 - val_loss: 6.0091\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.6372 - val_loss: 5.9546\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.4775 - val_loss: 5.9014\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.3207 - val_loss: 5.8484\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.2588 - val_loss: 5.8007\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.1844 - val_loss: 5.7528\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.0563 - val_loss: 5.7103\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.0141 - val_loss: 5.6637\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.0279 - val_loss: 5.6215\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.8075 - val_loss: 5.5779\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.8396 - val_loss: 5.5364\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.7331 - val_loss: 5.4983\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.6197 - val_loss: 5.4557\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.4925 - val_loss: 5.4167\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.5217 - val_loss: 5.3774\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.2109 - val_loss: 5.3437\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.3218 - val_loss: 5.3048\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.2092 - val_loss: 5.2693\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.1023 - val_loss: 5.2376\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.0156 - val_loss: 5.2040\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.1660 - val_loss: 5.1724\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.0702 - val_loss: 5.1419\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6.8939 - val_loss: 5.1100\n",
      "Model: \"sequential_218\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1554 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1337 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1555 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1338 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1556 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1339 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1557 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1340 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1558 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1341 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1559 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1342 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1560 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1343 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1561 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1344 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1562 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 161s 1s/step - loss: 162.1480 - val_loss: 77.8116\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 139.3469 - val_loss: 70.5032\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 121.8305 - val_loss: 65.1023\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 112.2640 - val_loss: 60.8038\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 101.1724 - val_loss: 57.3058\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 94.7394 - val_loss: 54.3745\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 86.3139 - val_loss: 51.8751\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 81.5112 - val_loss: 49.6973\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 78.1903 - val_loss: 47.7939\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 72.8330 - val_loss: 46.1072\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 69.7897 - val_loss: 44.6711\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 66.5913 - val_loss: 43.3174\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 63.6487 - val_loss: 42.0772\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 61.6986 - val_loss: 40.8666\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 59.3625 - val_loss: 39.7479\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 56.5973 - val_loss: 38.6473\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 54.4854 - val_loss: 37.5647\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 53.0088 - val_loss: 36.4923\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 50.1665 - val_loss: 35.3992\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 48.1879 - val_loss: 34.3279\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 45.9047 - val_loss: 33.2537\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 44.3742 - val_loss: 32.1672\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 41.9201 - val_loss: 31.1390\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 40.5454 - val_loss: 30.1365\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 38.7730 - val_loss: 29.1823\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 36.3403 - val_loss: 28.2900\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 34.3735 - val_loss: 27.4778\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 32.8074 - val_loss: 26.7343\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 31.6366 - val_loss: 26.0081\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 30.2318 - val_loss: 25.3601\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 29.0826 - val_loss: 24.7609\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 27.8162 - val_loss: 24.2225\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 26.9952 - val_loss: 23.7517\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 25.5943 - val_loss: 23.3171\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 24.5676 - val_loss: 22.9219\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 24.2416 - val_loss: 22.5343\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 23.5276 - val_loss: 22.1650\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 22.4753 - val_loss: 21.8254\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 22.1129 - val_loss: 21.5250\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 21.1811 - val_loss: 21.2211\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 20.6957 - val_loss: 20.9378\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 19.8563 - val_loss: 20.6535\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 19.0954 - val_loss: 20.3966\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 18.8322 - val_loss: 20.1570\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 18.5837 - val_loss: 19.9561\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 17.9363 - val_loss: 19.7443\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 17.6540 - val_loss: 19.5460\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 17.1028 - val_loss: 19.3473\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.4186 - val_loss: 19.1762\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.3339 - val_loss: 19.0085\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.0471 - val_loss: 18.8494\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.6107 - val_loss: 18.6854\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.1643 - val_loss: 18.5453\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.7729 - val_loss: 18.4156\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.5468 - val_loss: 18.2809\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.3649 - val_loss: 18.1498\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.1930 - val_loss: 18.0195\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.6700 - val_loss: 17.8880\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.5788 - val_loss: 17.7658\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.1957 - val_loss: 17.6467\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.8911 - val_loss: 17.5387\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.5628 - val_loss: 17.4385\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.6246 - val_loss: 17.3421\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.1096 - val_loss: 17.2480\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.3038 - val_loss: 17.1554\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.8821 - val_loss: 17.0636\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.9017 - val_loss: 16.9755\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.3731 - val_loss: 16.8964\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.3119 - val_loss: 16.8312\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.2997 - val_loss: 16.7663\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.8814 - val_loss: 16.6888\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.8637 - val_loss: 16.6104\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.8170 - val_loss: 16.5378\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.6833 - val_loss: 16.4664\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.4961 - val_loss: 16.3817\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.2923 - val_loss: 16.3028\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.0222 - val_loss: 16.2351\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.7863 - val_loss: 16.1631\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.9050 - val_loss: 16.0824\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.7463 - val_loss: 16.0163\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.6967 - val_loss: 15.9632\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.3943 - val_loss: 15.8980\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.3262 - val_loss: 15.8371\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.3200 - val_loss: 15.7744\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.1942 - val_loss: 15.7176\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.0894 - val_loss: 15.6650\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.0070 - val_loss: 15.6030\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.9477 - val_loss: 15.5267\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.5952 - val_loss: 15.4598\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.5170 - val_loss: 15.4106\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.4880 - val_loss: 15.3542\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.4259 - val_loss: 15.2915\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.3072 - val_loss: 15.2371\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.2820 - val_loss: 15.1837\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.2470 - val_loss: 15.1149\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.1526 - val_loss: 15.0745\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.8532 - val_loss: 15.0248\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.9719 - val_loss: 14.9702\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.9019 - val_loss: 14.9115\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.7221 - val_loss: 14.8711\n",
      "\n",
      "Feature shape is (178, 50)\n",
      "\n",
      "Feature test shape is (46, 50)\n",
      "\n",
      "After SMOTE feature shape is (266, 50)\n",
      "Model: \"sequential_219\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1563 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1345 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1564 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1346 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1565 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1347 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1566 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1348 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1567 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1349 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1568 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1350 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1569 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1351 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1570 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1352 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1571 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 170s 1s/step - loss: 153.4518 - val_loss: 132.7105\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 134.2390 - val_loss: 113.2630\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 115.1306 - val_loss: 98.4449\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 101.1495 - val_loss: 87.1978\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 92.5206 - val_loss: 78.9171\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 82.3801 - val_loss: 72.2480\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 78.1972 - val_loss: 66.6749\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 73.6748 - val_loss: 61.6692\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 68.8821 - val_loss: 57.7598\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 65.5588 - val_loss: 54.1096\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 62.0718 - val_loss: 51.0981\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 58.8761 - val_loss: 48.5690\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 56.7689 - val_loss: 46.5443\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 53.5554 - val_loss: 44.8360\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 51.7691 - val_loss: 43.2830\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 49.3913 - val_loss: 42.0511\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 47.7438 - val_loss: 40.7828\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 45.3342 - val_loss: 39.6320\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 44.2831 - val_loss: 38.4989\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 42.1582 - val_loss: 37.4702\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 40.2712 - val_loss: 36.5866\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 38.4979 - val_loss: 35.7344\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 37.1560 - val_loss: 34.9491\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 35.4081 - val_loss: 34.1727\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 32.9637 - val_loss: 33.4952\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 31.8514 - val_loss: 32.7034\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 30.7697 - val_loss: 31.9690\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 29.3473 - val_loss: 31.1229\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 27.4627 - val_loss: 30.4409\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 26.5609 - val_loss: 29.8746\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 25.2553 - val_loss: 29.3699\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 24.1713 - val_loss: 28.8163\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 23.2605 - val_loss: 28.4227\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 22.0858 - val_loss: 27.9562\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 21.8690 - val_loss: 27.5533\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 21.0357 - val_loss: 27.2738\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 20.5007 - val_loss: 26.8607\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 19.7131 - val_loss: 26.5513\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 19.4432 - val_loss: 26.2378\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 18.6106 - val_loss: 25.9941\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 18.1802 - val_loss: 25.6538\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 17.6273 - val_loss: 25.3053\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 17.3709 - val_loss: 24.9261\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.5111 - val_loss: 24.6092\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.3505 - val_loss: 24.3093\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.9546 - val_loss: 23.9213\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.5931 - val_loss: 23.6745\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.3179 - val_loss: 23.4392\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.9381 - val_loss: 23.1606\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.6131 - val_loss: 22.9662\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.2071 - val_loss: 22.7714\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.8581 - val_loss: 22.5612\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.7383 - val_loss: 22.3525\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.4032 - val_loss: 22.1814\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.9136 - val_loss: 22.0158\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.7397 - val_loss: 21.7873\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.7489 - val_loss: 21.6197\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.5565 - val_loss: 21.3882\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.1743 - val_loss: 21.1512\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.6993 - val_loss: 21.0114\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.7494 - val_loss: 20.8484\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.5305 - val_loss: 20.6756\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.1912 - val_loss: 20.5811\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.0434 - val_loss: 20.4955\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.8911 - val_loss: 20.3088\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.7678 - val_loss: 20.1228\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.4161 - val_loss: 19.9802\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.4646 - val_loss: 19.8409\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.1897 - val_loss: 19.7358\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.1451 - val_loss: 19.5991\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.8976 - val_loss: 19.4607\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.7528 - val_loss: 19.3071\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.7876 - val_loss: 19.1892\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.5928 - val_loss: 18.9793\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.4601 - val_loss: 18.8900\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.3775 - val_loss: 18.7396\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.2065 - val_loss: 18.6296\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.0670 - val_loss: 18.5105\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.0153 - val_loss: 18.4598\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.0092 - val_loss: 18.3464\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.7900 - val_loss: 18.3094\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.6588 - val_loss: 18.1693\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.5415 - val_loss: 18.0564\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.5730 - val_loss: 17.9997\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.3368 - val_loss: 17.8979\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.2347 - val_loss: 17.7888\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.0385 - val_loss: 17.6771\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.9565 - val_loss: 17.5882\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.8405 - val_loss: 17.5028\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.0542 - val_loss: 17.4457\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.8534 - val_loss: 17.3833\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.8679 - val_loss: 17.2777\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.5322 - val_loss: 17.2334\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.6449 - val_loss: 17.1828\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.5321 - val_loss: 17.0724\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.3222 - val_loss: 17.0232\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.4639 - val_loss: 16.9855\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.4452 - val_loss: 16.9216\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.2387 - val_loss: 16.8487\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.0342 - val_loss: 16.7834\n",
      "Model: \"sequential_220\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1572 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1353 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1573 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1354 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1574 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1355 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1575 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1356 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1576 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1357 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1577 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1358 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1578 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1359 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1579 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1360 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1580 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 165s 1s/step - loss: 211.9231 - val_loss: 65.4751\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 172.1576 - val_loss: 57.7743\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 149.4760 - val_loss: 52.0827\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 130.5173 - val_loss: 47.5911\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 117.7944 - val_loss: 44.1225\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 108.9070 - val_loss: 41.2201\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 99.4423 - val_loss: 38.8198\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 92.0550 - val_loss: 36.8143\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 85.7447 - val_loss: 35.0824\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 81.6192 - val_loss: 33.5902\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 76.8177 - val_loss: 32.2486\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 72.9825 - val_loss: 31.0369\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 69.6879 - val_loss: 29.9152\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 67.0818 - val_loss: 28.8726\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 64.6017 - val_loss: 27.8445\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 61.0899 - val_loss: 26.8524\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 58.4596 - val_loss: 25.8866\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 55.8601 - val_loss: 24.9577\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 53.6230 - val_loss: 24.0518\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 51.0245 - val_loss: 23.1471\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 49.2056 - val_loss: 22.2654\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 46.6232 - val_loss: 21.3703\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 45.0553 - val_loss: 20.4554\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 42.1373 - val_loss: 19.5770\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 40.5319 - val_loss: 18.7590\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 38.4467 - val_loss: 17.9538\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 37.1400 - val_loss: 17.1888\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 34.4061 - val_loss: 16.4703\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 32.8350 - val_loss: 15.8175\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 31.7972 - val_loss: 15.2259\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 30.2744 - val_loss: 14.7077\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 29.2655 - val_loss: 14.2278\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 27.8789 - val_loss: 13.8096\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 26.8793 - val_loss: 13.4294\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 25.9611 - val_loss: 13.0707\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 24.9623 - val_loss: 12.7306\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 24.3361 - val_loss: 12.4304\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 23.7812 - val_loss: 12.1286\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 22.8066 - val_loss: 11.8501\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 22.0408 - val_loss: 11.5876\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 21.8474 - val_loss: 11.3367\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 20.9073 - val_loss: 11.0969\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 20.4137 - val_loss: 10.8647\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 20.2950 - val_loss: 10.6398\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 19.3724 - val_loss: 10.4346\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 19.1135 - val_loss: 10.2383\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 18.6188 - val_loss: 10.0521\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 18.1485 - val_loss: 9.8692\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 17.7711 - val_loss: 9.7005\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 17.3166 - val_loss: 9.5209\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 17.1503 - val_loss: 9.3648\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.4877 - val_loss: 9.2069\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.0679 - val_loss: 9.0555\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.7139 - val_loss: 8.9157\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.4627 - val_loss: 8.7834\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.4176 - val_loss: 8.6430\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.9358 - val_loss: 8.5155\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.3652 - val_loss: 8.3912\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.1427 - val_loss: 8.2745\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.0068 - val_loss: 8.1567\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.6828 - val_loss: 8.0458\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.4377 - val_loss: 7.9310\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.3728 - val_loss: 7.8316\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.0429 - val_loss: 7.7288\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.6548 - val_loss: 7.6329\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.5510 - val_loss: 7.5370\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.2889 - val_loss: 7.4456\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.2919 - val_loss: 7.3482\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.0795 - val_loss: 7.2512\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.9355 - val_loss: 7.1663\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.6342 - val_loss: 7.0767\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.3095 - val_loss: 6.9940\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.2115 - val_loss: 6.9141\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.0410 - val_loss: 6.8327\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.9299 - val_loss: 6.7472\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.5871 - val_loss: 6.6741\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.3699 - val_loss: 6.6061\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.5047 - val_loss: 6.5265\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.1041 - val_loss: 6.4586\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.9969 - val_loss: 6.3943\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.9639 - val_loss: 6.3282\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.0219 - val_loss: 6.2570\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.5239 - val_loss: 6.1914\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.6220 - val_loss: 6.1306\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.3263 - val_loss: 6.0712\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.1935 - val_loss: 6.0168\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.2224 - val_loss: 5.9639\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.0777 - val_loss: 5.9109\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.9662 - val_loss: 5.8487\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.7937 - val_loss: 5.7914\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.7227 - val_loss: 5.7372\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.6101 - val_loss: 5.6830\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.4662 - val_loss: 5.6337\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.3652 - val_loss: 5.5848\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.3618 - val_loss: 5.5356\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.1614 - val_loss: 5.4857\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.2691 - val_loss: 5.4418\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.9819 - val_loss: 5.3970\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.8999 - val_loss: 5.3518\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.9002 - val_loss: 5.3085\n",
      "['../Cli3/UTSW_Cli_224P_OrderFea_20_SMOTE_CV_it_2_10_1.mat', '../PrePost/PET_MOO/HN_MR_2_PPD_SMOTE_CV5_fea50_it_50_1.mat', '../PrePost/CT_MOO/HN_MR_2_PPD_SMOTE_CV5_fea50_val_it_50_1.mat']\n",
      "\n",
      "... Processing ../PrePost/PET_MOO/HN_MR_2_PPD_SMOTE_CV5_fea50_it_50_1 ...\n",
      "PET_feature shape is (179, 50)\n",
      "\n",
      "... Processing ../PrePost/CT_MOO/HN_MR_2_PPD_SMOTE_CV5_fea50_val_it_50_1 ...\n",
      "CT_feature shape is (179, 50)\n",
      "\n",
      "Feature shape is (179, 50)\n",
      "\n",
      "Label shape is (179, 1)\n",
      "\n",
      "Feature test shape is (45, 50)\n",
      "\n",
      "Label test shape is (45, 1)\n",
      "\n",
      "After SMOTE feature shape is (266, 50)\n",
      "Model: \"sequential_221\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1581 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1361 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1582 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1362 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1583 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1363 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1584 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1364 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1585 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1365 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1586 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1366 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1587 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1367 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1588 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1368 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1589 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 171s 1s/step - loss: 187.1881 - val_loss: 66.8797\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 153.2813 - val_loss: 57.5985\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 131.5256 - val_loss: 50.6930\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 113.6542 - val_loss: 45.5330\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 101.9948 - val_loss: 41.4649\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 90.6695 - val_loss: 38.2980\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 83.6968 - val_loss: 35.6939\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 77.9990 - val_loss: 33.5418\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 71.3672 - val_loss: 31.7067\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 67.3450 - val_loss: 30.1207\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 63.0104 - val_loss: 28.7548\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 60.0185 - val_loss: 27.5167\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 57.2079 - val_loss: 26.3393\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 53.6322 - val_loss: 25.2549\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 51.6792 - val_loss: 24.2254\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 48.9182 - val_loss: 23.2344\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 46.2273 - val_loss: 22.2466\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 44.2899 - val_loss: 21.2812\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 41.8766 - val_loss: 20.3341\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 39.9255 - val_loss: 19.4018\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 37.4185 - val_loss: 18.4842\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 35.0896 - val_loss: 17.5848\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 33.2070 - val_loss: 16.7209\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 30.8052 - val_loss: 15.9278\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 29.6252 - val_loss: 15.2105\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 28.2857 - val_loss: 14.5838\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 26.8656 - val_loss: 14.0366\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 25.6527 - val_loss: 13.5600\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 24.4072 - val_loss: 13.1362\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 23.6616 - val_loss: 12.7632\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 22.8825 - val_loss: 12.4205\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 21.5550 - val_loss: 12.1047\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 20.8701 - val_loss: 11.8124\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 20.5118 - val_loss: 11.5470\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 19.6165 - val_loss: 11.2937\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 18.9361 - val_loss: 11.0597\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 18.7465 - val_loss: 10.8366\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 18.3509 - val_loss: 10.6217\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 17.4638 - val_loss: 10.4242\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 17.2060 - val_loss: 10.2313\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.7745 - val_loss: 10.0604\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.1023 - val_loss: 9.8904\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.7401 - val_loss: 9.7358\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.5795 - val_loss: 9.5809\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.1316 - val_loss: 9.4358\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.8932 - val_loss: 9.2962\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.6112 - val_loss: 9.1597\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.2996 - val_loss: 9.0321\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.9041 - val_loss: 8.9096\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.5582 - val_loss: 8.7825\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.2907 - val_loss: 8.6646\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.3202 - val_loss: 8.5480\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.9537 - val_loss: 8.4408\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.7835 - val_loss: 8.3390\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.4191 - val_loss: 8.2401\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.2659 - val_loss: 8.1458\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.9652 - val_loss: 8.0514\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.7539 - val_loss: 7.9540\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.6781 - val_loss: 7.8654\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.3913 - val_loss: 7.7778\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.3655 - val_loss: 7.6934\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.1422 - val_loss: 7.6157\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.9356 - val_loss: 7.5376\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.8150 - val_loss: 7.4645\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.7000 - val_loss: 7.3913\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.3394 - val_loss: 7.3226\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.0573 - val_loss: 7.2565\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.0916 - val_loss: 7.1900\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.8141 - val_loss: 7.1193\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.8136 - val_loss: 7.0541\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.5873 - val_loss: 6.9971\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.6377 - val_loss: 6.9414\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.4798 - val_loss: 6.8841\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.4181 - val_loss: 6.8251\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.1743 - val_loss: 6.7710\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.1433 - val_loss: 6.7190\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.9495 - val_loss: 6.6694\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.0074 - val_loss: 6.6175\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.8575 - val_loss: 6.5699\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.7382 - val_loss: 6.5221\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.6673 - val_loss: 6.4812\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.6082 - val_loss: 6.4367\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.4425 - val_loss: 6.3941\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.4822 - val_loss: 6.3537\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.3857 - val_loss: 6.3149\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.1915 - val_loss: 6.2704\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.0777 - val_loss: 6.2346\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.8411 - val_loss: 6.1958\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.8813 - val_loss: 6.1547\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.9821 - val_loss: 6.1147\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.7462 - val_loss: 6.0804\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.6936 - val_loss: 6.0428\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.6226 - val_loss: 6.0071\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.6113 - val_loss: 5.9716\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.4818 - val_loss: 5.9374\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.3534 - val_loss: 5.9040\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.2879 - val_loss: 5.8726\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.1271 - val_loss: 5.8385\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.1562 - val_loss: 5.8093\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.0485 - val_loss: 5.7774\n",
      "Model: \"sequential_222\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1590 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1369 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1591 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1370 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1592 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1371 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1593 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1372 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1594 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1373 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1595 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1374 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1596 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1375 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1597 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1376 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1598 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 167s 1s/step - loss: 200.7285 - val_loss: 145.5047\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 167.3011 - val_loss: 129.0903\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 140.3309 - val_loss: 117.4497\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 124.3420 - val_loss: 108.8575\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 109.5889 - val_loss: 102.3294\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 98.6485 - val_loss: 97.2847\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 91.5845 - val_loss: 93.1694\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 84.5231 - val_loss: 90.0002\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 79.1405 - val_loss: 87.2673\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 75.6644 - val_loss: 85.1418\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 72.2491 - val_loss: 83.2213\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 68.1477 - val_loss: 81.5905\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 65.3178 - val_loss: 80.1954\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 62.0720 - val_loss: 78.8786\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 59.5762 - val_loss: 77.5846\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 57.4154 - val_loss: 76.3588\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 55.2985 - val_loss: 75.2299\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 52.6081 - val_loss: 74.1260\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 50.7886 - val_loss: 73.0707\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 48.1797 - val_loss: 72.0056\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 45.9986 - val_loss: 70.8840\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 43.6827 - val_loss: 69.7030\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 41.5197 - val_loss: 68.5262\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 39.3079 - val_loss: 67.4422\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 37.1513 - val_loss: 66.3795\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 34.9996 - val_loss: 65.4032\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 33.6519 - val_loss: 64.5193\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 32.0114 - val_loss: 63.6618\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 30.7421 - val_loss: 62.8799\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 29.1984 - val_loss: 62.2355\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 28.2871 - val_loss: 61.5454\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 27.1454 - val_loss: 60.9388\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 25.7492 - val_loss: 60.3953\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 25.1556 - val_loss: 59.7978\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 23.9900 - val_loss: 59.2934\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 23.1523 - val_loss: 58.7943\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 22.5274 - val_loss: 58.4424\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 21.5446 - val_loss: 57.9319\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 20.7128 - val_loss: 57.5471\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 20.3573 - val_loss: 57.1591\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 19.2951 - val_loss: 56.7679\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 19.0384 - val_loss: 56.4368\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 18.5619 - val_loss: 56.0866\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 18.1688 - val_loss: 55.6983\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 17.4754 - val_loss: 55.3359\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 17.0584 - val_loss: 55.0152\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.6899 - val_loss: 54.6673\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.0605 - val_loss: 54.3420\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.8534 - val_loss: 54.0172\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.2846 - val_loss: 53.6978\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.1508 - val_loss: 53.3823\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.7105 - val_loss: 53.1523\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.5628 - val_loss: 52.8701\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.1859 - val_loss: 52.5699\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.0212 - val_loss: 52.2790\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.5590 - val_loss: 51.9478\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.2100 - val_loss: 51.6670\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.9332 - val_loss: 51.3943\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.8684 - val_loss: 51.0607\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.4646 - val_loss: 50.7904\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.1513 - val_loss: 50.5216\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.0742 - val_loss: 50.2394\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.8340 - val_loss: 49.9791\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.6590 - val_loss: 49.6828\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.4427 - val_loss: 49.4110\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.3581 - val_loss: 49.2082\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.3010 - val_loss: 48.9580\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.9325 - val_loss: 48.7299\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.0474 - val_loss: 48.4650\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.6053 - val_loss: 48.2986\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.4351 - val_loss: 48.0641\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.2447 - val_loss: 47.7883\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.0420 - val_loss: 47.5440\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.9919 - val_loss: 47.2805\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.6844 - val_loss: 47.0577\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.9008 - val_loss: 46.7972\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.6158 - val_loss: 46.6023\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.4157 - val_loss: 46.3991\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.3386 - val_loss: 46.1771\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.1667 - val_loss: 45.9254\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.0349 - val_loss: 45.7260\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.9549 - val_loss: 45.5272\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.8554 - val_loss: 45.3537\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.7424 - val_loss: 45.1529\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.6094 - val_loss: 44.9557\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.4975 - val_loss: 44.7275\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.4390 - val_loss: 44.5375\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.2628 - val_loss: 44.3338\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.2070 - val_loss: 44.1251\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.0987 - val_loss: 43.9578\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.1758 - val_loss: 43.8018\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.9951 - val_loss: 43.5915\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.8951 - val_loss: 43.4317\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.7192 - val_loss: 43.3038\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.6425 - val_loss: 43.1275\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.7414 - val_loss: 42.9434\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.5390 - val_loss: 42.7380\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.4830 - val_loss: 42.5744\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.4158 - val_loss: 42.3592\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.5044 - val_loss: 42.1712\n",
      "\n",
      "Feature shape is (179, 50)\n",
      "\n",
      "Feature test shape is (45, 50)\n",
      "\n",
      "After SMOTE feature shape is (266, 50)\n",
      "Model: \"sequential_223\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1599 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1377 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1600 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1378 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1601 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1379 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1602 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1380 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1603 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1381 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1604 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1382 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1605 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1383 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1606 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1384 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1607 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 169s 1s/step - loss: 182.1329 - val_loss: 72.7558\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 146.5468 - val_loss: 63.5421\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 124.1295 - val_loss: 56.9660\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 103.0315 - val_loss: 52.0488\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 92.1231 - val_loss: 48.1993\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 81.5372 - val_loss: 45.2031\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 74.8812 - val_loss: 42.7904\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 69.4002 - val_loss: 40.8348\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 64.8438 - val_loss: 39.2358\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 61.7697 - val_loss: 37.8626\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 59.0267 - val_loss: 36.6752\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 55.9062 - val_loss: 35.6022\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 53.3493 - val_loss: 34.5951\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 51.6326 - val_loss: 33.6318\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 49.6985 - val_loss: 32.7602\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 47.5664 - val_loss: 31.8561\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 45.9243 - val_loss: 31.0206\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 43.7583 - val_loss: 30.1919\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 42.4308 - val_loss: 29.4112\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 40.6281 - val_loss: 28.6739\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 38.6833 - val_loss: 27.9008\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 37.4507 - val_loss: 27.1413\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 36.2865 - val_loss: 26.3430\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 34.7121 - val_loss: 25.5837\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 32.8305 - val_loss: 24.8415\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 31.3554 - val_loss: 24.0919\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 30.0915 - val_loss: 23.3663\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 28.9742 - val_loss: 22.6671\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 27.0751 - val_loss: 21.9834\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 25.8685 - val_loss: 21.3632\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 24.9279 - val_loss: 20.7770\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 23.8587 - val_loss: 20.2292\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 22.7868 - val_loss: 19.7328\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 21.8650 - val_loss: 19.2830\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 20.9953 - val_loss: 18.8826\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 20.2420 - val_loss: 18.4813\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 19.7295 - val_loss: 18.1318\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 19.1000 - val_loss: 17.8270\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 18.9791 - val_loss: 17.5086\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 18.1157 - val_loss: 17.2431\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 17.9171 - val_loss: 16.9800\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 17.4949 - val_loss: 16.7117\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.4721 - val_loss: 16.4784\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.4854 - val_loss: 16.2514\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.2743 - val_loss: 16.0245\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.9467 - val_loss: 15.8076\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.5257 - val_loss: 15.5827\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.0906 - val_loss: 15.3536\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.7160 - val_loss: 15.1539\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.5342 - val_loss: 14.9501\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.1256 - val_loss: 14.7703\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.8824 - val_loss: 14.6065\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.6653 - val_loss: 14.4554\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.6602 - val_loss: 14.2905\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.0889 - val_loss: 14.1267\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.0307 - val_loss: 13.9564\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.7683 - val_loss: 13.8076\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.7154 - val_loss: 13.6447\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.3317 - val_loss: 13.5042\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.1893 - val_loss: 13.3635\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.8722 - val_loss: 13.2222\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.8095 - val_loss: 13.0827\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.6138 - val_loss: 12.9595\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.3623 - val_loss: 12.8272\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.2788 - val_loss: 12.6918\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.8000 - val_loss: 12.5663\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.7655 - val_loss: 12.4397\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.7781 - val_loss: 12.3165\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.6734 - val_loss: 12.1981\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.4084 - val_loss: 12.0934\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.2431 - val_loss: 11.9776\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.1869 - val_loss: 11.8590\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.0034 - val_loss: 11.7637\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.0081 - val_loss: 11.6709\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.7793 - val_loss: 11.5756\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.6596 - val_loss: 11.4788\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.5127 - val_loss: 11.3934\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.5841 - val_loss: 11.3030\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.4083 - val_loss: 11.1942\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.1238 - val_loss: 11.0886\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.1117 - val_loss: 11.0060\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.9382 - val_loss: 10.9237\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.9684 - val_loss: 10.8372\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.9238 - val_loss: 10.7571\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.8004 - val_loss: 10.6906\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.8701 - val_loss: 10.6086\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.4810 - val_loss: 10.5195\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.3843 - val_loss: 10.4463\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.5058 - val_loss: 10.3695\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.2898 - val_loss: 10.3002\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.1948 - val_loss: 10.2213\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.2293 - val_loss: 10.1397\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.1579 - val_loss: 10.0722\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.9521 - val_loss: 10.0104\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.0333 - val_loss: 9.9348\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.7748 - val_loss: 9.8661\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.7655 - val_loss: 9.7977\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.7603 - val_loss: 9.7347\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.4876 - val_loss: 9.6701\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.6211 - val_loss: 9.6148\n",
      "Model: \"sequential_224\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1608 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1385 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1609 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1386 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1610 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1387 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1611 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1388 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1612 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1389 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1613 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1390 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1614 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1391 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1615 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1392 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1616 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 174s 1s/step - loss: 186.7573 - val_loss: 94.9282\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 161.2797 - val_loss: 84.3316\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 141.2672 - val_loss: 75.9784\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 124.2349 - val_loss: 69.5448\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 113.6273 - val_loss: 64.4559\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 106.6558 - val_loss: 60.3210\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 98.3400 - val_loss: 56.9894\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 91.7350 - val_loss: 54.1113\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 86.0768 - val_loss: 51.7329\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 80.7351 - val_loss: 49.6137\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 77.5088 - val_loss: 47.7373\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 73.7540 - val_loss: 46.0082\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 69.7158 - val_loss: 44.4204\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 66.4417 - val_loss: 42.9386\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 63.9265 - val_loss: 41.4994\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 60.2834 - val_loss: 40.0688\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 58.3501 - val_loss: 38.7176\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 54.2763 - val_loss: 37.3675\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 52.1550 - val_loss: 36.0788\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 49.4704 - val_loss: 34.7691\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 46.9750 - val_loss: 33.5187\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 43.9421 - val_loss: 32.2980\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 41.9993 - val_loss: 31.1967\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 39.3114 - val_loss: 30.1900\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 37.9691 - val_loss: 29.2419\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 36.3180 - val_loss: 28.3930\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 34.3488 - val_loss: 27.5674\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 32.8768 - val_loss: 26.8370\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 31.9424 - val_loss: 26.1271\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 30.3204 - val_loss: 25.4627\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 29.1942 - val_loss: 24.8469\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 28.0843 - val_loss: 24.2605\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 27.1423 - val_loss: 23.7239\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 26.1239 - val_loss: 23.1760\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 25.1271 - val_loss: 22.6615\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 24.3569 - val_loss: 22.1696\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 23.5810 - val_loss: 21.6966\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 22.6729 - val_loss: 21.2547\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 21.9229 - val_loss: 20.8088\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 20.9444 - val_loss: 20.3777\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 20.6838 - val_loss: 19.9813\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 20.6375 - val_loss: 19.5789\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 19.7366 - val_loss: 19.2233\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 19.2812 - val_loss: 18.8460\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 18.7504 - val_loss: 18.4945\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 18.0485 - val_loss: 18.1660\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 17.7398 - val_loss: 17.8364\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 17.3702 - val_loss: 17.5183\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.8548 - val_loss: 17.2272\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.5329 - val_loss: 16.9338\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.9443 - val_loss: 16.6474\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.6920 - val_loss: 16.3593\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.3344 - val_loss: 16.0836\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.1337 - val_loss: 15.8257\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.8887 - val_loss: 15.5686\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.5335 - val_loss: 15.3282\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.0542 - val_loss: 15.0781\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.7852 - val_loss: 14.8343\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.4939 - val_loss: 14.5979\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.3615 - val_loss: 14.3704\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.1452 - val_loss: 14.1523\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.7359 - val_loss: 13.9527\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.5772 - val_loss: 13.7644\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.3781 - val_loss: 13.5558\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.0966 - val_loss: 13.3391\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.1241 - val_loss: 13.1498\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.9015 - val_loss: 12.9727\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.5212 - val_loss: 12.7854\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.3335 - val_loss: 12.6064\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.1168 - val_loss: 12.4523\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.8499 - val_loss: 12.2809\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.9596 - val_loss: 12.1165\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.7581 - val_loss: 11.9527\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.3206 - val_loss: 11.7924\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.3547 - val_loss: 11.6434\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.2317 - val_loss: 11.4839\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.3139 - val_loss: 11.3341\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.8408 - val_loss: 11.1842\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.8898 - val_loss: 11.0336\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.6833 - val_loss: 10.8969\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.7033 - val_loss: 10.7613\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.3606 - val_loss: 10.6371\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.2030 - val_loss: 10.5111\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.0901 - val_loss: 10.3988\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.0762 - val_loss: 10.2722\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.9590 - val_loss: 10.1564\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.7917 - val_loss: 10.0454\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.8636 - val_loss: 9.9267\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.6074 - val_loss: 9.8105\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.5480 - val_loss: 9.6986\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.4865 - val_loss: 9.5953\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.3806 - val_loss: 9.4918\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.3440 - val_loss: 9.3944\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.4254 - val_loss: 9.2889\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.0296 - val_loss: 9.1887\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.9891 - val_loss: 9.0962\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.9540 - val_loss: 9.0022\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.8771 - val_loss: 8.9124\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.7982 - val_loss: 8.8275\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.6712 - val_loss: 8.7497\n",
      "['../Cli3/UTSW_Cli_224P_OrderFea_20_SMOTE_CV_it_2_10_2.mat', '../PrePost/PET_MOO/HN_MR_2_PPD_SMOTE_CV5_fea50_it_50_2.mat', '../PrePost/CT_MOO/HN_MR_2_PPD_SMOTE_CV5_fea50_val_it_50_2.mat']\n",
      "\n",
      "... Processing ../PrePost/PET_MOO/HN_MR_2_PPD_SMOTE_CV5_fea50_it_50_2 ...\n",
      "PET_feature shape is (179, 50)\n",
      "\n",
      "... Processing ../PrePost/CT_MOO/HN_MR_2_PPD_SMOTE_CV5_fea50_val_it_50_2 ...\n",
      "CT_feature shape is (179, 50)\n",
      "\n",
      "Feature shape is (179, 50)\n",
      "\n",
      "Label shape is (179, 1)\n",
      "\n",
      "Feature test shape is (45, 50)\n",
      "\n",
      "Label test shape is (45, 1)\n",
      "\n",
      "After SMOTE feature shape is (266, 50)\n",
      "Model: \"sequential_225\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1617 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1393 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1618 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1394 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1619 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1395 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1620 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1396 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1621 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1397 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1622 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1398 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1623 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1399 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1624 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1400 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1625 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 178s 1s/step - loss: 214.3877 - val_loss: 78.6700\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 173.0116 - val_loss: 66.3941\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 145.3785 - val_loss: 57.6392\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 122.4735 - val_loss: 51.4429\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 110.6582 - val_loss: 46.7136\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 99.7561 - val_loss: 43.0479\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 91.3420 - val_loss: 40.0734\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 83.9205 - val_loss: 37.6434\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 78.4111 - val_loss: 35.5464\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 73.5262 - val_loss: 33.7535\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 69.1430 - val_loss: 32.1622\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 66.2032 - val_loss: 30.7335\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 62.8527 - val_loss: 29.4430\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 59.9719 - val_loss: 28.2417\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 57.3724 - val_loss: 27.1055\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 54.6521 - val_loss: 26.0613\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 52.4819 - val_loss: 25.0511\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 50.6961 - val_loss: 24.0743\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 48.2382 - val_loss: 23.1141\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 46.3881 - val_loss: 22.1789\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 44.4960 - val_loss: 21.2493\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 42.6298 - val_loss: 20.3312\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 40.5032 - val_loss: 19.4422\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 38.5752 - val_loss: 18.5599\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 36.7840 - val_loss: 17.6899\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 35.1657 - val_loss: 16.8431\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 33.6367 - val_loss: 16.0306\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 31.8223 - val_loss: 15.2405\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 30.3066 - val_loss: 14.4960\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 28.4430 - val_loss: 13.7930\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 26.8893 - val_loss: 13.1485\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 26.0408 - val_loss: 12.5576\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 24.7444 - val_loss: 12.0204\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 23.8854 - val_loss: 11.5480\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 23.2687 - val_loss: 11.1206\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 22.0974 - val_loss: 10.7324\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 21.1072 - val_loss: 10.3885\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 20.1342 - val_loss: 10.0724\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 19.8471 - val_loss: 9.7878\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 19.3709 - val_loss: 9.5219\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 18.9850 - val_loss: 9.2691\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 18.4195 - val_loss: 9.0381\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 17.4612 - val_loss: 8.8239\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 17.3391 - val_loss: 8.6193\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.7801 - val_loss: 8.4248\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.4141 - val_loss: 8.2422\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.9157 - val_loss: 8.0663\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.7011 - val_loss: 7.9011\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.6690 - val_loss: 7.7421\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.8637 - val_loss: 7.5915\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.9306 - val_loss: 7.4475\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.5644 - val_loss: 7.3062\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.9504 - val_loss: 7.1764\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.8704 - val_loss: 7.0516\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.5909 - val_loss: 6.9305\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.3663 - val_loss: 6.8124\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.9933 - val_loss: 6.6976\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.8284 - val_loss: 6.5915\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.6403 - val_loss: 6.4866\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.4006 - val_loss: 6.3871\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.1022 - val_loss: 6.2900\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.9031 - val_loss: 6.1994\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.8805 - val_loss: 6.1104\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.8681 - val_loss: 6.0221\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.5845 - val_loss: 5.9390\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.3072 - val_loss: 5.8573\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.0900 - val_loss: 5.7802\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.8625 - val_loss: 5.7044\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.9675 - val_loss: 5.6302\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.6853 - val_loss: 5.5607\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.5362 - val_loss: 5.4918\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.5163 - val_loss: 5.4246\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.2271 - val_loss: 5.3611\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.9917 - val_loss: 5.2988\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.9838 - val_loss: 5.2396\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.8554 - val_loss: 5.1817\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.6227 - val_loss: 5.1246\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.7512 - val_loss: 5.0698\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.5066 - val_loss: 5.0165\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.3885 - val_loss: 4.9653\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.2675 - val_loss: 4.9161\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.0607 - val_loss: 4.8671\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.8302 - val_loss: 4.8202\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.9332 - val_loss: 4.7745\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.9588 - val_loss: 4.7297\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.6253 - val_loss: 4.6860\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.5146 - val_loss: 4.6429\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.6061 - val_loss: 4.6012\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.3693 - val_loss: 4.5602\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.3167 - val_loss: 4.5204\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.3924 - val_loss: 4.4816\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.2496 - val_loss: 4.4444\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.2187 - val_loss: 4.4081\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.1314 - val_loss: 4.3719\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.0810 - val_loss: 4.3363\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.9902 - val_loss: 4.3024\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.8571 - val_loss: 4.2687\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.6715 - val_loss: 4.2361\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.9239 - val_loss: 4.2038\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.6037 - val_loss: 4.1726\n",
      "Model: \"sequential_226\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1626 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1401 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1627 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1402 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1628 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1403 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1629 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1404 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1630 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1405 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1631 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1406 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1632 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1407 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1633 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1408 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1634 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 180s 2s/step - loss: 221.8722 - val_loss: 65.1449\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 172.1496 - val_loss: 57.4124\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 157.9960 - val_loss: 51.4448\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 136.3070 - val_loss: 46.8778\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 125.1242 - val_loss: 43.2626\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 109.3887 - val_loss: 40.3416\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 103.4207 - val_loss: 37.8937\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 96.1988 - val_loss: 35.8441\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 88.1455 - val_loss: 34.0788\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 84.1694 - val_loss: 32.5435\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 78.9745 - val_loss: 31.1625\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 75.2762 - val_loss: 29.9096\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 71.6329 - val_loss: 28.7407\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 68.0942 - val_loss: 27.6245\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 65.1503 - val_loss: 26.5613\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 61.4801 - val_loss: 25.5088\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 58.8556 - val_loss: 24.4701\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 56.3067 - val_loss: 23.4519\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 53.5216 - val_loss: 22.4480\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 50.8622 - val_loss: 21.4522\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 47.7018 - val_loss: 20.4643\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 45.9388 - val_loss: 19.5010\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 43.2082 - val_loss: 18.5675\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 41.0685 - val_loss: 17.6797\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 38.8561 - val_loss: 16.8574\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 36.8668 - val_loss: 16.1077\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 35.6824 - val_loss: 15.4327\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 34.2057 - val_loss: 14.8241\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 32.8632 - val_loss: 14.2786\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 31.5128 - val_loss: 13.7758\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 30.3783 - val_loss: 13.3083\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 28.9327 - val_loss: 12.8762\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 28.0195 - val_loss: 12.4801\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 26.9154 - val_loss: 12.1133\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 25.8840 - val_loss: 11.7717\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 25.0905 - val_loss: 11.4498\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 24.4871 - val_loss: 11.1420\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 23.5609 - val_loss: 10.8528\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 23.0679 - val_loss: 10.5826\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 21.5689 - val_loss: 10.3267\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 21.5724 - val_loss: 10.0877\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 21.0633 - val_loss: 9.8540\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 20.2116 - val_loss: 9.6375\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 19.2367 - val_loss: 9.4280\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 19.2428 - val_loss: 9.2337\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 18.6017 - val_loss: 9.0466\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 18.3780 - val_loss: 8.8653\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 17.7327 - val_loss: 8.6970\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 17.4959 - val_loss: 8.5319\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 17.0863 - val_loss: 8.3718\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.3920 - val_loss: 8.2155\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.1795 - val_loss: 8.0681\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.6914 - val_loss: 7.9263\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.6054 - val_loss: 7.7875\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.1361 - val_loss: 7.6524\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.8061 - val_loss: 7.5266\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.5120 - val_loss: 7.3997\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.2384 - val_loss: 7.2828\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.8142 - val_loss: 7.1669\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.5683 - val_loss: 7.0526\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.5083 - val_loss: 6.9469\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.1183 - val_loss: 6.8421\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.8210 - val_loss: 6.7413\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.4435 - val_loss: 6.6452\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.3203 - val_loss: 6.5534\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.0476 - val_loss: 6.4634\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.8919 - val_loss: 6.3755\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.7053 - val_loss: 6.2884\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.5479 - val_loss: 6.2041\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.4330 - val_loss: 6.1244\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.0137 - val_loss: 6.0470\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.2387 - val_loss: 5.9730\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.7429 - val_loss: 5.9007\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.5892 - val_loss: 5.8281\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.5288 - val_loss: 5.7592\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.5205 - val_loss: 5.6923\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.2302 - val_loss: 5.6264\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.1390 - val_loss: 5.5615\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.7895 - val_loss: 5.5004\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.7980 - val_loss: 5.4371\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.6555 - val_loss: 5.3782\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.5831 - val_loss: 5.3208\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.5152 - val_loss: 5.2655\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.2512 - val_loss: 5.2098\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.2585 - val_loss: 5.1574\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.0309 - val_loss: 5.1038\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.8476 - val_loss: 5.0528\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.8804 - val_loss: 5.0022\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.6748 - val_loss: 4.9534\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.6160 - val_loss: 4.9058\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.5269 - val_loss: 4.8600\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.4075 - val_loss: 4.8154\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.2952 - val_loss: 4.7731\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.3423 - val_loss: 4.7294\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.1383 - val_loss: 4.6877\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.2260 - val_loss: 4.6469\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.9913 - val_loss: 4.6058\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.9697 - val_loss: 4.5667\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.9680 - val_loss: 4.5290\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.6692 - val_loss: 4.4911\n",
      "\n",
      "Feature shape is (179, 50)\n",
      "\n",
      "Feature test shape is (45, 50)\n",
      "\n",
      "After SMOTE feature shape is (266, 50)\n",
      "Model: \"sequential_227\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1635 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1409 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1636 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1410 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1637 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1411 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1638 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1412 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1639 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1413 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1640 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1414 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1641 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1415 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1642 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1416 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1643 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 185s 2s/step - loss: 166.4154 - val_loss: 51.6305\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 136.4326 - val_loss: 45.5727\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 115.8369 - val_loss: 40.8554\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 102.5731 - val_loss: 37.1634\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 92.4298 - val_loss: 34.3132\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 83.9597 - val_loss: 32.0990\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 77.8265 - val_loss: 30.2689\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 71.8063 - val_loss: 28.7833\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 68.1082 - val_loss: 27.5100\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 64.3197 - val_loss: 26.3745\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 61.1722 - val_loss: 25.3774\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 58.0247 - val_loss: 24.4671\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 55.5130 - val_loss: 23.5650\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 52.8305 - val_loss: 22.7083\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 50.7109 - val_loss: 21.8322\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 48.5333 - val_loss: 20.9409\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 46.2234 - val_loss: 20.0025\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 44.1111 - val_loss: 19.0601\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 42.0959 - val_loss: 18.0657\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 39.6700 - val_loss: 17.1112\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 37.2723 - val_loss: 16.2078\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 35.9404 - val_loss: 15.3343\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 33.7689 - val_loss: 14.5486\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 31.7720 - val_loss: 13.8391\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 30.3599 - val_loss: 13.1934\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 28.6491 - val_loss: 12.5994\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 27.4185 - val_loss: 12.0526\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 26.8140 - val_loss: 11.5633\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 25.2734 - val_loss: 11.1245\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 23.8017 - val_loss: 10.7260\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 23.0469 - val_loss: 10.3521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 22.3503 - val_loss: 10.0091\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 21.5234 - val_loss: 9.7013\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - ETA: 0s - loss: 22.39 - 0s 2ms/step - loss: 20.9450 - val_loss: 9.4057\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 20.1999 - val_loss: 9.1320\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 19.2895 - val_loss: 8.8761\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 18.8493 - val_loss: 8.6447\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 18.3936 - val_loss: 8.4257\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 17.6436 - val_loss: 8.2121\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 17.0675 - val_loss: 8.0206\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.6812 - val_loss: 7.8315\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.3477 - val_loss: 7.6561\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.7128 - val_loss: 7.4885\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.3667 - val_loss: 7.3217\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.9406 - val_loss: 7.1666\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.4820 - val_loss: 7.0281\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.5452 - val_loss: 6.8918\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.1426 - val_loss: 6.7598\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.7397 - val_loss: 6.6332\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.4625 - val_loss: 6.5139\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.1783 - val_loss: 6.3969\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.9816 - val_loss: 6.2925\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.7905 - val_loss: 6.1832\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.1657 - val_loss: 6.0899\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.2355 - val_loss: 6.0027\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.8792 - val_loss: 5.9130\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.4790 - val_loss: 5.8290\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.3897 - val_loss: 5.7433\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.2310 - val_loss: 5.6677\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.0645 - val_loss: 5.5843\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.8652 - val_loss: 5.5082\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.6206 - val_loss: 5.4402\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.3723 - val_loss: 5.3728\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.2380 - val_loss: 5.3075\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.1750 - val_loss: 5.2422\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.0904 - val_loss: 5.1817\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.8042 - val_loss: 5.1237\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.7997 - val_loss: 5.0651\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.7302 - val_loss: 5.0085\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.5752 - val_loss: 4.9549\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.4731 - val_loss: 4.90502\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.3980 - val_loss: 4.8574\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.3596 - val_loss: 4.8053\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.1168 - val_loss: 4.7553\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.9228 - val_loss: 4.7051\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.6922 - val_loss: 4.6609\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.7507 - val_loss: 4.6175\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.6901 - val_loss: 4.5746\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.5433 - val_loss: 4.5346\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.3778 - val_loss: 4.4938\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.3458 - val_loss: 4.4522\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.2939 - val_loss: 4.4134\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.3602 - val_loss: 4.3744\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.1400 - val_loss: 4.3409\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.0604 - val_loss: 4.3052\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.0059 - val_loss: 4.2696\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.0752 - val_loss: 4.2374\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.9424 - val_loss: 4.2056\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.7259 - val_loss: 4.1709\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.7340 - val_loss: 4.1426\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.6235 - val_loss: 4.1114\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.5716 - val_loss: 4.0840\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.4592 - val_loss: 4.0522\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.4363 - val_loss: 4.0238\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.3845 - val_loss: 3.9966\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.3237 - val_loss: 3.9686\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.2086 - val_loss: 3.9419\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.1680 - val_loss: 3.9143\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.0872 - val_loss: 3.8892\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.1475 - val_loss: 3.8642\n",
      "Model: \"sequential_228\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1644 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1417 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1645 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1418 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1646 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1419 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1647 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1420 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1648 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1421 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1649 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1422 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1650 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1423 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1651 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1424 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1652 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 183s 2s/step - loss: 169.4235 - val_loss: 53.9257\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 147.3660 - val_loss: 48.5181\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 129.4366 - val_loss: 44.4231\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 115.6734 - val_loss: 41.2045\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 106.3001 - val_loss: 38.6023\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 97.1566 - val_loss: 36.5002\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 90.9092 - val_loss: 34.6983\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 83.9890 - val_loss: 33.1774\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 80.7359 - val_loss: 31.8439\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 75.6868 - val_loss: 30.7013\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 73.0261 - val_loss: 29.6428\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 69.0961 - val_loss: 28.6884\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 66.3276 - val_loss: 27.7921\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 63.2426 - val_loss: 26.9226\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 60.5012 - val_loss: 26.1164\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 58.6111 - val_loss: 25.3307\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 56.5293 - val_loss: 24.5449\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 53.8536 - val_loss: 23.7510\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 52.4057 - val_loss: 22.9702\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 50.0237 - val_loss: 22.1973\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 47.7295 - val_loss: 21.4221\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 45.4430 - val_loss: 20.6508\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 44.0216 - val_loss: 19.8731\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 42.2840 - val_loss: 19.1086\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 40.0321 - val_loss: 18.3344\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 38.4970 - val_loss: 17.5828\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 36.3451 - val_loss: 16.8453\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 34.5959 - val_loss: 16.1507\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 33.3024 - val_loss: 15.4925\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 31.5887 - val_loss: 14.8659\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 30.1959 - val_loss: 14.2966\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 28.8945 - val_loss: 13.7676\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 27.6362 - val_loss: 13.2900\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 26.7492 - val_loss: 12.8568\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 25.4910 - val_loss: 12.4571\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 24.4237 - val_loss: 12.0970\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 24.0174 - val_loss: 11.7729\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 23.2043 - val_loss: 11.4713\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 22.5067 - val_loss: 11.1894\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 21.6541 - val_loss: 10.9269\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 21.1161 - val_loss: 10.6905\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 20.5658 - val_loss: 10.4605\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 19.9328 - val_loss: 10.2416\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 19.2847 - val_loss: 10.0341\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 19.0480 - val_loss: 9.8291\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 18.5070 - val_loss: 9.6306\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 18.0372 - val_loss: 9.4476\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 17.5260 - val_loss: 9.2713\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.9615 - val_loss: 9.1089\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.7702 - val_loss: 8.9427\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.2925 - val_loss: 8.7912\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.2310 - val_loss: 8.6382\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.6267 - val_loss: 8.4941\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.5486 - val_loss: 8.3517\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.0742 - val_loss: 8.2170\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.7229 - val_loss: 8.0831\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.5074 - val_loss: 7.9598\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.2040 - val_loss: 7.8365\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.7978 - val_loss: 7.7225\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.6592 - val_loss: 7.6067\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.3169 - val_loss: 7.5003\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.1225 - val_loss: 7.3866\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.9980 - val_loss: 7.2847\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.6588 - val_loss: 7.1836\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.3803 - val_loss: 7.0826\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.1836 - val_loss: 6.9846\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.3283 - val_loss: 6.8977\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.0556 - val_loss: 6.8095\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.6434 - val_loss: 6.7202\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.6602 - val_loss: 6.6350\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.3829 - val_loss: 6.5535\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.1589 - val_loss: 6.4705\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.8304 - val_loss: 6.3950\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.8454 - val_loss: 6.3158\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.6012 - val_loss: 6.2411\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.4471 - val_loss: 6.1680\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.2562 - val_loss: 6.0944\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.3861 - val_loss: 6.0222\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.2339 - val_loss: 5.9554\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.9052 - val_loss: 5.8898\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.8848 - val_loss: 5.8223\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.7093 - val_loss: 5.7570\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.5019 - val_loss: 5.6922\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.5208 - val_loss: 5.6328\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.3841 - val_loss: 5.5709\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.2317 - val_loss: 5.5147\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.1332 - val_loss: 5.4572\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.1061 - val_loss: 5.4023\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.0362 - val_loss: 5.3487\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.9966 - val_loss: 5.2937\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.8060 - val_loss: 5.2410\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.4918 - val_loss: 5.1881\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.7418 - val_loss: 5.1371\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.5971 - val_loss: 5.0878\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.3218 - val_loss: 5.0378\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.2533 - val_loss: 4.9916\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.0770 - val_loss: 4.9458\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.1626 - val_loss: 4.9014\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.0382 - val_loss: 4.8586\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.0041 - val_loss: 4.8155\n",
      "['../Cli3/UTSW_Cli_224P_OrderFea_20_SMOTE_CV_it_2_10_3.mat', '../PrePost/PET_MOO/HN_MR_2_PPD_SMOTE_CV5_fea50_it_50_3.mat', '../PrePost/CT_MOO/HN_MR_2_PPD_SMOTE_CV5_fea50_val_it_50_3.mat']\n",
      "\n",
      "... Processing ../PrePost/PET_MOO/HN_MR_2_PPD_SMOTE_CV5_fea50_it_50_3 ...\n",
      "PET_feature shape is (180, 50)\n",
      "\n",
      "... Processing ../PrePost/CT_MOO/HN_MR_2_PPD_SMOTE_CV5_fea50_val_it_50_3 ...\n",
      "CT_feature shape is (180, 50)\n",
      "\n",
      "Feature shape is (180, 50)\n",
      "\n",
      "Label shape is (180, 1)\n",
      "\n",
      "Feature test shape is (44, 50)\n",
      "\n",
      "Label test shape is (44, 1)\n",
      "\n",
      "After SMOTE feature shape is (268, 50)\n",
      "Model: \"sequential_229\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1653 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1425 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1654 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1426 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1655 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1427 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1656 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1428 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1657 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1429 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1658 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1430 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1659 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1431 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1660 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1432 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1661 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 190s 2s/step - loss: 156.9358 - val_loss: 59.1417\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 132.8777 - val_loss: 51.8310\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 113.7239 - val_loss: 46.4007\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 100.0288 - val_loss: 42.1214\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 91.0651 - val_loss: 38.6967\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 83.5015 - val_loss: 35.9121\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 76.0321 - val_loss: 33.5916\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 70.9843 - val_loss: 31.6313\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 67.0268 - val_loss: 29.9765\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 63.0179 - val_loss: 28.5558\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 59.8215 - val_loss: 27.2493\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 56.8536 - val_loss: 26.0126\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 54.1852 - val_loss: 24.8828\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 51.6585 - val_loss: 23.8518\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 49.4629 - val_loss: 22.8384\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 46.9222 - val_loss: 21.8652\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 44.7483 - val_loss: 20.9106\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 42.6034 - val_loss: 19.9455\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 40.6730 - val_loss: 18.9982\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 39.0792 - val_loss: 18.0812\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 36.9820 - val_loss: 17.1787\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 35.0950 - val_loss: 16.2994\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 33.1723 - val_loss: 15.4558\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 31.1991 - val_loss: 14.6502\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 29.6879 - val_loss: 13.8965\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 28.2473 - val_loss: 13.2007\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 2ms/step - loss: 26.9101 - val_loss: 12.5587\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 25.1473 - val_loss: 11.9941\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 24.5263 - val_loss: 11.4804\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 23.4877 - val_loss: 11.0198\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.5897 - val_loss: 10.5948\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21.4573 - val_loss: 10.2193\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.6284 - val_loss: 9.8732\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20.0930 - val_loss: 9.5554\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 19.2096 - val_loss: 9.2544\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.6448 - val_loss: 8.9719\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.1121 - val_loss: 8.7041\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.5085 - val_loss: 8.4620\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.9056 - val_loss: 8.2319\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.3329 - val_loss: 8.0175\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.2438 - val_loss: 7.8127\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.6708 - val_loss: 7.6181\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.0436 - val_loss: 7.4348\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.9026 - val_loss: 7.2603\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.3252 - val_loss: 7.1012\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.1512 - val_loss: 6.9482\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.6684 - val_loss: 6.8027\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.5717 - val_loss: 6.6584\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.9638 - val_loss: 6.5275\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.7760 - val_loss: 6.3991\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.5586 - val_loss: 6.2717\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.5062 - val_loss: 6.1504\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.0880 - val_loss: 6.0349\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.9995 - val_loss: 5.9228\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.7279 - val_loss: 5.8210\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.4461 - val_loss: 5.7213\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.1343 - val_loss: 5.6248\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.9791 - val_loss: 5.5324\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.6459 - val_loss: 5.4429\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.4779 - val_loss: 5.3550\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.3056 - val_loss: 5.2720\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.0601 - val_loss: 5.1930\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.0602 - val_loss: 5.1169\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.8679 - val_loss: 5.0455\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.6391 - val_loss: 4.9766\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.5895 - val_loss: 4.9076\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.3598 - val_loss: 4.8417\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.2526 - val_loss: 4.7779\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.0581 - val_loss: 4.7172\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.0336 - val_loss: 4.6581\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.8301 - val_loss: 4.6032\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.7032 - val_loss: 4.5482\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.5874 - val_loss: 4.4936\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.5924 - val_loss: 4.4425\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.4174 - val_loss: 4.3923\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.3014 - val_loss: 4.3454\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2417 - val_loss: 4.2983\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1747 - val_loss: 4.2534\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.0290 - val_loss: 4.2096\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.8749 - val_loss: 4.1676\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.8041 - val_loss: 4.1261\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.5780 - val_loss: 4.0867\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.6402 - val_loss: 4.0485\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.5868 - val_loss: 4.0097\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.4918 - val_loss: 3.9742\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.4479 - val_loss: 3.9390\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.3888 - val_loss: 3.9039\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.3238 - val_loss: 3.8695\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.2148 - val_loss: 3.8366\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.2952 - val_loss: 3.8044\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.2493 - val_loss: 3.7744\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.0254 - val_loss: 3.7438\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6.8552 - val_loss: 3.7152\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6.8188 - val_loss: 3.6862\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6.7909 - val_loss: 3.6576\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6.6980 - val_loss: 3.6302\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6.8329 - val_loss: 3.6036\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6.7352 - val_loss: 3.5768\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6.5738 - val_loss: 3.5521\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6.5426 - val_loss: 3.5264\n",
      "Model: \"sequential_230\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1662 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1433 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1663 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1434 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1664 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1435 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1665 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1436 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1666 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1437 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1667 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1438 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1668 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1439 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1669 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1440 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1670 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 179s 1s/step - loss: 187.0693 - val_loss: 63.2693\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 167.7557 - val_loss: 55.7514\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 145.6401 - val_loss: 50.0915\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 127.7148 - val_loss: 45.8268\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 117.7534 - val_loss: 42.3162\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 106.7453 - val_loss: 39.5615\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 99.7540 - val_loss: 37.3526\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 94.4304 - val_loss: 35.4530\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 88.5651 - val_loss: 33.8097\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 83.4474 - val_loss: 32.3909\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 78.6092 - val_loss: 31.1151\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 75.0627 - val_loss: 29.9771\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 71.0426 - val_loss: 28.9371\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 67.5244 - val_loss: 27.9650\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 65.9478 - val_loss: 27.0452\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 62.5276 - val_loss: 26.1701\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 60.8106 - val_loss: 25.2951\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 58.0451 - val_loss: 24.4282\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 54.8684 - val_loss: 23.5860\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 53.8624 - val_loss: 22.7250\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 51.3115 - val_loss: 21.8192\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 49.2818 - val_loss: 20.9142\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 47.5171 - val_loss: 20.0125\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 44.0547 - val_loss: 19.1109\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 42.1463 - val_loss: 18.2042\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 40.7128 - val_loss: 17.3088\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 38.5130 - val_loss: 16.4822\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 36.4162 - val_loss: 15.7009\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 34.5151 - val_loss: 15.0065\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 32.7095 - val_loss: 14.3746\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 31.3988 - val_loss: 13.8277\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 30.0625 - val_loss: 13.3395\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 28.9743 - val_loss: 12.9023\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 27.6586 - val_loss: 12.5001\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 26.9958 - val_loss: 12.1122\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 25.9090 - val_loss: 11.7733\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 25.1771 - val_loss: 11.4576\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 24.4285 - val_loss: 11.1343\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 23.3484 - val_loss: 10.8463\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22.5919 - val_loss: 10.5829\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22.0042 - val_loss: 10.3143\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21.6949 - val_loss: 10.0679\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20.9444 - val_loss: 9.8393\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20.1933 - val_loss: 9.6146\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 19.7422 - val_loss: 9.4104\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 19.0015 - val_loss: 9.1981\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.5701 - val_loss: 9.0136\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.0705 - val_loss: 8.8275\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.7858 - val_loss: 8.6446\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.0815 - val_loss: 8.4704\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.7558 - val_loss: 8.3065\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.3030 - val_loss: 8.1443\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.8335 - val_loss: 8.0023\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.7009 - val_loss: 7.8646\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.9555 - val_loss: 7.7297\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.0412 - val_loss: 7.6053\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.7212 - val_loss: 7.4798\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.5439 - val_loss: 7.3577\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.0280 - val_loss: 7.2408\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.6400 - val_loss: 7.1269\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.5756 - val_loss: 7.0209\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.0203 - val_loss: 6.9055\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.0733 - val_loss: 6.8045\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.5325 - val_loss: 6.6998\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.5357 - val_loss: 6.5955\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.1895 - val_loss: 6.5020\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.0272 - val_loss: 6.4156\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.8350 - val_loss: 6.3322\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.6760 - val_loss: 6.2467\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.4414 - val_loss: 6.1682\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.3724 - val_loss: 6.0831\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.0094 - val_loss: 6.0044\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.8054 - val_loss: 5.9284\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.8827 - val_loss: 5.8587\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.5201 - val_loss: 5.7925\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.3262 - val_loss: 5.7265\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.1611 - val_loss: 5.6554\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.0291 - val_loss: 5.5914\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.9541 - val_loss: 5.5223\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.8139 - val_loss: 5.4605\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.5091 - val_loss: 5.3976\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.5788 - val_loss: 5.3352\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.3685 - val_loss: 5.2831\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.3595 - val_loss: 5.2251\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.1717 - val_loss: 5.1752\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.0555 - val_loss: 5.1203\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.0293 - val_loss: 5.0654\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.8969 - val_loss: 5.0107\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.7679 - val_loss: 4.9634\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.6959 - val_loss: 4.9165\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.6554 - val_loss: 4.8683\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.5017 - val_loss: 4.8214\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.3731 - val_loss: 4.7765\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.3424 - val_loss: 4.7364\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1518 - val_loss: 4.6919\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.0094 - val_loss: 4.6485\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.9390 - val_loss: 4.6062\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.8722 - val_loss: 4.5690\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.8266 - val_loss: 4.5291\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.7012 - val_loss: 4.4964\n",
      "\n",
      "Feature shape is (180, 50)\n",
      "\n",
      "Feature test shape is (44, 50)\n",
      "\n",
      "After SMOTE feature shape is (268, 50)\n",
      "Model: \"sequential_231\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1671 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1441 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1672 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1442 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1673 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1443 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1674 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1444 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1675 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1445 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1676 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1446 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1677 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1447 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1678 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1448 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1679 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 182s 2s/step - loss: 146.1071 - val_loss: 82.2020\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 120.9871 - val_loss: 72.5887\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 106.1689 - val_loss: 65.5092\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 93.1919 - val_loss: 59.8764\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 84.3019 - val_loss: 55.3168\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 77.0618 - val_loss: 51.7886\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 72.6538 - val_loss: 48.8972\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 69.0018 - val_loss: 46.4306\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 64.9158 - val_loss: 44.3997\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 62.4976 - val_loss: 42.5569\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 58.9558 - val_loss: 40.9616\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 56.6990 - val_loss: 39.4660\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 54.5553 - val_loss: 38.1351\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 52.2062 - val_loss: 36.8523\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 49.9471 - val_loss: 35.5915\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 48.1068 - val_loss: 34.3572\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - ETA: 0s - loss: 49.02 - 0s 2ms/step - loss: 46.1461 - val_loss: 33.1431\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 44.5724 - val_loss: 31.9769\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 41.9672 - val_loss: 30.8783\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 39.2440 - val_loss: 29.7632\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 37.9321 - val_loss: 28.6637\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 35.7960 - val_loss: 27.6546\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 33.9030 - val_loss: 26.7192\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 32.1021 - val_loss: 25.8647\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 30.4871 - val_loss: 25.0646\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 29.6084 - val_loss: 24.3378\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 27.9878 - val_loss: 23.7005\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 26.9320 - val_loss: 23.1192\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 25.7891 - val_loss: 22.5891\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 24.3278 - val_loss: 22.1253\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 3ms/step - loss: 23.8932 - val_loss: 21.6654\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 23.0851 - val_loss: 21.2726\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22.2061 - val_loss: 20.8779\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21.2834 - val_loss: 20.4794\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20.8295 - val_loss: 20.1140\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20.0139 - val_loss: 19.7351\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 19.2786 - val_loss: 19.3942\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.7408 - val_loss: 19.0940\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.1483 - val_loss: 18.8065\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.7599 - val_loss: 18.5215\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.1999 - val_loss: 18.2466\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.9849 - val_loss: 17.9644\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.5080 - val_loss: 17.7052\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.9853 - val_loss: 17.4672\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.7424 - val_loss: 17.2289\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.3420 - val_loss: 17.0017\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.5692 - val_loss: 16.8154\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.4305 - val_loss: 16.6143\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.3187 - val_loss: 16.4128\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.0144 - val_loss: 16.2038\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.6928 - val_loss: 16.0183\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.1492 - val_loss: 15.8462\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.9169 - val_loss: 15.6735\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.9256 - val_loss: 15.5166\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.6129 - val_loss: 15.3688\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.2568 - val_loss: 15.2093\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.8875 - val_loss: 15.0501\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.9190 - val_loss: 14.8981\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.6238 - val_loss: 14.7519\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.5228 - val_loss: 14.6122\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.4868 - val_loss: 14.4828\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.9544 - val_loss: 14.3255\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.7359 - val_loss: 14.2007\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.7098 - val_loss: 14.0923\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.4056 - val_loss: 13.9846\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.2252 - val_loss: 13.8632\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.2489 - val_loss: 13.7278\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.9800 - val_loss: 13.5961\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.8436 - val_loss: 13.4904\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.6981 - val_loss: 13.3796\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.5310 - val_loss: 13.2581\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.4375 - val_loss: 13.1691\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.4446 - val_loss: 13.0614\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.1552 - val_loss: 12.9800\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.0560 - val_loss: 12.8930\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.0138 - val_loss: 12.7804\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.9581 - val_loss: 12.6948\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.8273 - val_loss: 12.5990\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.6245 - val_loss: 12.5148\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.5842 - val_loss: 12.4237\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.4344 - val_loss: 12.3380\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.4207 - val_loss: 12.2565\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.2969 - val_loss: 12.1904\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.1032 - val_loss: 12.1082\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.0330 - val_loss: 12.0348\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.8709 - val_loss: 11.9661\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.7282 - val_loss: 11.8857\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.8824 - val_loss: 11.8311\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.7043 - val_loss: 11.7570\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.6791 - val_loss: 11.6912\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.7117 - val_loss: 11.6159\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.4014 - val_loss: 11.5372\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.2580 - val_loss: 11.4812\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.3197 - val_loss: 11.4217\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.3218 - val_loss: 11.3572\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.2429 - val_loss: 11.3000\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.1881 - val_loss: 11.2440\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.0363 - val_loss: 11.1812\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.0132 - val_loss: 11.1203\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6.7359 - val_loss: 11.0611\n",
      "Model: \"sequential_232\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1680 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1449 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1681 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1450 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1682 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1451 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1683 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1452 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1684 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1453 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1685 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1454 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1686 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1455 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1687 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1456 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1688 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 194s 2s/step - loss: 188.8435 - val_loss: 89.2300\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 161.9341 - val_loss: 79.4701\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 142.5883 - val_loss: 72.2611\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 129.5287 - val_loss: 66.6877\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 119.0641 - val_loss: 62.0396\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 109.7527 - val_loss: 58.2614\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 101.7846 - val_loss: 55.0244\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 94.9322 - val_loss: 52.3205\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 90.8801 - val_loss: 49.8542\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 86.8572 - val_loss: 47.6212\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 82.3409 - val_loss: 45.4963\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 78.9581 - val_loss: 43.6485\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 75.7651 - val_loss: 41.8824\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 72.0756 - val_loss: 40.2180\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 69.1598 - val_loss: 38.6080\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 66.6807 - val_loss: 37.0531\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 63.2793 - val_loss: 35.6732\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 60.6515 - val_loss: 34.2639\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 57.3621 - val_loss: 32.8893\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 54.5739 - val_loss: 31.4914\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 52.8710 - val_loss: 30.1712\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 49.9713 - val_loss: 28.9058\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 47.4910 - val_loss: 27.7207\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 45.5031 - val_loss: 26.5071\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 43.1805 - val_loss: 25.3539\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 41.0296 - val_loss: 24.2875\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 39.3285 - val_loss: 23.2598\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 36.9832 - val_loss: 22.3295\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 35.8887 - val_loss: 21.4580\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 33.8311 - val_loss: 20.6522\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 32.4287 - val_loss: 19.9284\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 31.5533 - val_loss: 19.2652\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 30.0362 - val_loss: 18.6543\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 28.9028 - val_loss: 18.0891\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 28.3333 - val_loss: 17.5756\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 27.1905 - val_loss: 17.1072\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 26.1940 - val_loss: 16.6560\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 25.4617 - val_loss: 16.2380\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 24.7172 - val_loss: 15.8110\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.9633 - val_loss: 15.4089\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.1980 - val_loss: 15.0235\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.1316 - val_loss: 14.6959\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.4378 - val_loss: 14.3517\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21.0010 - val_loss: 13.9975\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.6337 - val_loss: 13.6568\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.0590 - val_loss: 13.3533\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.3011 - val_loss: 13.0611\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 19.0321 - val_loss: 12.7665\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.4196 - val_loss: 12.4851\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.9335 - val_loss: 12.2332\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.6209 - val_loss: 11.9946\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.2904 - val_loss: 11.7644\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.5370 - val_loss: 11.5286\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.3648 - val_loss: 11.3101\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.8494 - val_loss: 11.0851\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.3638 - val_loss: 10.8717\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.3547 - val_loss: 10.6932\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.9692 - val_loss: 10.5031\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.6313 - val_loss: 10.3081\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.2906 - val_loss: 10.1180\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.2096 - val_loss: 9.9588\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.6385 - val_loss: 9.8078\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.6698 - val_loss: 9.6377\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.2604 - val_loss: 9.4801\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.9341 - val_loss: 9.3375\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.6216 - val_loss: 9.2003\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.6172 - val_loss: 9.0633\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.1538 - val_loss: 8.9318\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.9988 - val_loss: 8.7998\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.8630 - val_loss: 8.6692\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.5632 - val_loss: 8.5511\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.3487 - val_loss: 8.4455\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.9853 - val_loss: 8.3283\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.1785 - val_loss: 8.2142\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.9813 - val_loss: 8.1131\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.6402 - val_loss: 8.0128\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.5164 - val_loss: 7.9102\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.3129 - val_loss: 7.8179\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.2477 - val_loss: 7.7131\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.1462 - val_loss: 7.6272\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.8800 - val_loss: 7.5356\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.7486 - val_loss: 7.4422\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.5975 - val_loss: 7.3603\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.5230 - val_loss: 7.2798\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.4228 - val_loss: 7.1867\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.3346 - val_loss: 7.1078\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.2686 - val_loss: 7.0244\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.1976 - val_loss: 6.9483\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.8613 - val_loss: 6.8660\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.0070 - val_loss: 6.7965\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.6315 - val_loss: 6.7193\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.6179 - val_loss: 6.6485\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.5818 - val_loss: 6.5852\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.4107 - val_loss: 6.5207\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.3077 - val_loss: 6.4585\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2570 - val_loss: 6.3985\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.3395 - val_loss: 6.3335\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1287 - val_loss: 6.2769\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.9748 - val_loss: 6.2143\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.9404 - val_loss: 6.1517\n",
      "['../Cli3/UTSW_Cli_224P_OrderFea_20_SMOTE_CV_it_2_10_4.mat', '../PrePost/PET_MOO/HN_MR_2_PPD_SMOTE_CV5_fea50_it_50_4.mat', '../PrePost/CT_MOO/HN_MR_2_PPD_SMOTE_CV5_fea50_val_it_50_4.mat']\n",
      "\n",
      "... Processing ../PrePost/PET_MOO/HN_MR_2_PPD_SMOTE_CV5_fea50_it_50_4 ...\n",
      "PET_feature shape is (179, 50)\n",
      "\n",
      "... Processing ../PrePost/CT_MOO/HN_MR_2_PPD_SMOTE_CV5_fea50_val_it_50_4 ...\n",
      "CT_feature shape is (179, 50)\n",
      "\n",
      "Feature shape is (179, 50)\n",
      "\n",
      "Label shape is (179, 1)\n",
      "\n",
      "Feature test shape is (45, 50)\n",
      "\n",
      "Label test shape is (45, 1)\n",
      "\n",
      "After SMOTE feature shape is (268, 50)\n",
      "Model: \"sequential_233\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1689 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1457 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1690 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1458 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1691 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1459 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1692 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1460 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1693 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1461 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1694 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1462 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1695 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1463 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1696 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1464 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1697 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 204s 2s/step - loss: 199.5539 - val_loss: 66.3253\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 162.4793 - val_loss: 57.2403\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 142.9548 - val_loss: 50.4762\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 116.9736 - val_loss: 45.4325\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 107.5541 - val_loss: 41.4260\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 96.5750 - val_loss: 38.2400\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 88.3597 - val_loss: 35.5898\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 81.7799 - val_loss: 33.3561\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 75.3683 - val_loss: 31.4724\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 71.1665 - val_loss: 29.7815\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 67.3429 - val_loss: 28.2618\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 63.0016 - val_loss: 26.8738\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 60.3611 - val_loss: 25.5797\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 56.5466 - val_loss: 24.3897\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 54.0328 - val_loss: 23.2551\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 51.6349 - val_loss: 22.1307\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 48.8823 - val_loss: 21.0427\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 46.3956 - val_loss: 19.9755\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 43.9347 - val_loss: 18.9276\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 40.9616 - val_loss: 17.9249\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 39.2418 - val_loss: 16.9764\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 37.6093 - val_loss: 16.0963\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 35.7815 - val_loss: 15.2880\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 33.6620 - val_loss: 14.5489\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 31.7307 - val_loss: 13.8769\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 30.5178 - val_loss: 13.2570\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 3ms/step - loss: 28.9389 - val_loss: 12.6990\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 27.2436 - val_loss: 12.1840\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 26.2213 - val_loss: 11.7058\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 25.1175 - val_loss: 11.2691\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 24.1074 - val_loss: 10.8639\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 23.1711 - val_loss: 10.4844\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22.2442 - val_loss: 10.1304\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21.5049 - val_loss: 9.7981\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20.8007 - val_loss: 9.4961\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.1200 - val_loss: 9.2124\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.4628 - val_loss: 8.9468\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.6010 - val_loss: 8.7003\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.2656 - val_loss: 8.4735\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.5838 - val_loss: 8.2620\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.1892 - val_loss: 8.0635\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.6212 - val_loss: 7.8780\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.2174 - val_loss: 7.7053\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.8948 - val_loss: 7.5383\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.4391 - val_loss: 7.3812\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.0904 - val_loss: 7.2318\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.8324 - val_loss: 7.0888\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.4801 - val_loss: 6.9514\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.2417 - val_loss: 6.8207\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.9371 - val_loss: 6.6942\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.4228 - val_loss: 6.5734\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.3582 - val_loss: 6.4609\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.1435 - val_loss: 6.3524\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.7787 - val_loss: 6.2500\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.6354 - val_loss: 6.1504\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.3258 - val_loss: 6.0555\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.9166 - val_loss: 5.9666\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.7830 - val_loss: 5.8786\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.4987 - val_loss: 5.7946\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.5595 - val_loss: 5.7155\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.2625 - val_loss: 5.6400\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.9982 - val_loss: 5.5625\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.1396 - val_loss: 5.4912\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.7237 - val_loss: 5.4200\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.6834 - val_loss: 5.3530\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.4632 - val_loss: 5.2885\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.2455 - val_loss: 5.2268\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.3553 - val_loss: 5.1687\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.9119 - val_loss: 5.1097\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.8839 - val_loss: 5.0540\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.9015 - val_loss: 4.9987\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.8179 - val_loss: 4.9450\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.4340 - val_loss: 4.8934\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.4097 - val_loss: 4.8443\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.3493 - val_loss: 4.7951\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.2249 - val_loss: 4.7493\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.0682 - val_loss: 4.7039\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.9688 - val_loss: 4.6579\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.0182 - val_loss: 4.6150\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.7210 - val_loss: 4.5729\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.7988 - val_loss: 4.5316\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.5733 - val_loss: 4.4911\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.5443 - val_loss: 4.4531\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.5334 - val_loss: 4.4148\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1979 - val_loss: 4.3776\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2878 - val_loss: 4.3416\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.3553 - val_loss: 4.3066\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2877 - val_loss: 4.2720\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0530 - val_loss: 4.2394\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.9441 - val_loss: 4.2073\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.9926 - val_loss: 4.1756\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.6414 - val_loss: 4.1446\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.8698 - val_loss: 4.1138\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.7642 - val_loss: 4.0843\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.4715 - val_loss: 4.0543\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.4762 - val_loss: 4.0255\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.4962 - val_loss: 3.9978\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.4256 - val_loss: 3.9709\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.3861 - val_loss: 3.9452\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.2885 - val_loss: 3.9190\n",
      "Model: \"sequential_234\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1698 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1465 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1699 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1466 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1700 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1467 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1701 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1468 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1702 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1469 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1703 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1470 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1704 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1471 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1705 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1472 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1706 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 202s 2s/step - loss: 212.5450 - val_loss: 77.2232\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 182.1219 - val_loss: 69.4266\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 153.4348 - val_loss: 63.7954\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 134.5502 - val_loss: 59.4929\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 119.8969 - val_loss: 56.1212\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 112.7320 - val_loss: 53.4582\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 103.0500 - val_loss: 51.3133\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 96.3815 - val_loss: 49.4891\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 90.1895 - val_loss: 47.9490\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 84.6877 - val_loss: 46.6330\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 81.0807 - val_loss: 45.4953\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 76.2294 - val_loss: 44.4597\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 72.8420 - val_loss: 43.5178\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 69.3105 - val_loss: 42.6650\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 65.8388 - val_loss: 41.8545\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 63.5284 - val_loss: 41.1068\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 60.8741 - val_loss: 40.3830\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 57.4922 - val_loss: 39.7141\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 55.4881 - val_loss: 39.0414\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 52.9634 - val_loss: 38.3572\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 50.7871 - val_loss: 37.6812\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 48.3887 - val_loss: 37.0262\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 45.7202 - val_loss: 36.3714\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 44.3996 - val_loss: 35.7580\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 42.0608 - val_loss: 35.1114\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 40.2568 - val_loss: 34.4745\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 38.0516 - val_loss: 33.8670\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 36.8802 - val_loss: 33.2186\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 34.3434 - val_loss: 32.6637\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 33.4725 - val_loss: 32.1288\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 31.9823 - val_loss: 31.6394\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 30.0720 - val_loss: 31.1989\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 28.5226 - val_loss: 30.7909\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 27.8935 - val_loss: 30.4243\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 26.5803 - val_loss: 30.1372\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 25.5701 - val_loss: 29.8410\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 24.5143 - val_loss: 29.5907\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.6726 - val_loss: 29.3611\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.0455 - val_loss: 29.1481\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.1535 - val_loss: 28.9825\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.5676 - val_loss: 28.8014\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.2965 - val_loss: 28.6542\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.6071 - val_loss: 28.4962\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.8222 - val_loss: 28.3633\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.1509 - val_loss: 28.2232\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.7188 - val_loss: 28.1035\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.4501 - val_loss: 27.9600\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.9950 - val_loss: 27.8154\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.3042 - val_loss: 27.6966\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.0355 - val_loss: 27.6052\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.4555 - val_loss: 27.4820\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.2035 - val_loss: 27.3778\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.7869 - val_loss: 27.2914\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.5307 - val_loss: 27.2064\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.2239 - val_loss: 27.1085\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.7431 - val_loss: 26.9902\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.5522 - val_loss: 26.8476\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.5277 - val_loss: 26.7242\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.8799 - val_loss: 26.6308\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.7143 - val_loss: 26.5442\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.4279 - val_loss: 26.4564\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.3528 - val_loss: 26.3612\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.9204 - val_loss: 26.2947\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.9502 - val_loss: 26.2199\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.4407 - val_loss: 26.1362\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.2662 - val_loss: 26.0636\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.1525 - val_loss: 25.9787\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.8927 - val_loss: 25.8955\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.4768 - val_loss: 25.8142\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.4743 - val_loss: 25.7552\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.4059 - val_loss: 25.7119\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.0489 - val_loss: 25.6462\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.9375 - val_loss: 25.5870\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.0880 - val_loss: 25.5372\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.7019 - val_loss: 25.4934\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.5203 - val_loss: 25.4482\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.4298 - val_loss: 25.3790\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.0882 - val_loss: 25.3131\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.1416 - val_loss: 25.2587\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.8497 - val_loss: 25.1912\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.8033 - val_loss: 25.1257\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.7116 - val_loss: 25.0801\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.4994 - val_loss: 25.0275\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.5042 - val_loss: 24.9671\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.3055 - val_loss: 24.8982\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.2187 - val_loss: 24.8291\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.0582 - val_loss: 24.7648\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.7904 - val_loss: 24.7066\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.9243 - val_loss: 24.6525\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.7821 - val_loss: 24.5795\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.5503 - val_loss: 24.5181\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.4129 - val_loss: 24.4803\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.3827 - val_loss: 24.4190\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.3831 - val_loss: 24.3546\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.1336 - val_loss: 24.2975\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.9944 - val_loss: 24.2439\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.9829 - val_loss: 24.1665\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0002 - val_loss: 24.1009\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.8961 - val_loss: 24.0621\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.7481 - val_loss: 24.0060\n",
      "\n",
      "Feature shape is (179, 50)\n",
      "\n",
      "Feature test shape is (45, 50)\n",
      "\n",
      "After SMOTE feature shape is (268, 50)\n",
      "Model: \"sequential_235\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1707 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1473 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1708 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1474 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1709 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1475 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1710 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1476 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1711 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1477 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1712 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1478 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1713 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1479 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1714 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1480 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1715 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 207s 2s/step - loss: 166.5142 - val_loss: 54.0568\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 133.8628 - val_loss: 46.4011\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 112.3532 - val_loss: 41.2970\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 98.9450 - val_loss: 37.4494\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 88.3281 - val_loss: 34.5176\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 79.7646 - val_loss: 32.2441\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 73.4164 - val_loss: 30.4406\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 69.2830 - val_loss: 28.9010\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 65.8652 - val_loss: 27.5903\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 62.2268 - val_loss: 26.4821\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 59.6594 - val_loss: 25.5069\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 56.5989 - val_loss: 24.6312\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 54.9579 - val_loss: 23.7997\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 52.4858 - val_loss: 22.9966\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 50.3897 - val_loss: 22.2121\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 48.5282 - val_loss: 21.4441\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 46.4535 - val_loss: 20.6876\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 44.3372 - val_loss: 19.9324\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 43.1719 - val_loss: 19.1704\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 41.0246 - val_loss: 18.4145\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 39.2863 - val_loss: 17.6489\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 37.4544 - val_loss: 16.8773\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 35.5892 - val_loss: 16.1069\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 34.0405 - val_loss: 15.3428\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 32.4782 - val_loss: 14.5872\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 30.1920 - val_loss: 13.8637\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 28.8193 - val_loss: 13.1781\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 27.9283 - val_loss: 12.5288\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 26.4919 - val_loss: 11.9413\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 24.8667 - val_loss: 11.4075\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 3ms/step - loss: 23.8433 - val_loss: 10.9351\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.7209 - val_loss: 10.5168\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.0298 - val_loss: 10.1459\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.1444 - val_loss: 9.8236\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.3805 - val_loss: 9.5267\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.8058 - val_loss: 9.2539\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.1246 - val_loss: 9.0079\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.5195 - val_loss: 8.7777\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.0264 - val_loss: 8.5668\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.6558 - val_loss: 8.3677\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.1268 - val_loss: 8.1833\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.9015 - val_loss: 8.0105\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.3988 - val_loss: 7.8491\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.9342 - val_loss: 7.6936\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.5087 - val_loss: 7.5474\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.1520 - val_loss: 7.4049\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.7591 - val_loss: 7.2688\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.6937 - val_loss: 7.1425\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.2420 - val_loss: 7.0222\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.8616 - val_loss: 6.9055\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.8151 - val_loss: 6.7922\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.3388 - val_loss: 6.6830\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.1497 - val_loss: 6.5802\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.8973 - val_loss: 6.4813\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.6922 - val_loss: 6.3851\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.4956 - val_loss: 6.2949\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.0928 - val_loss: 6.2062\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.8654 - val_loss: 6.1224\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.7431 - val_loss: 6.0410\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.6631 - val_loss: 5.9625\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.4088 - val_loss: 5.8847\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.1247 - val_loss: 5.8112\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.1316 - val_loss: 5.7413\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.8225 - val_loss: 5.6717\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.8021 - val_loss: 5.6056\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.9452 - val_loss: 5.5404\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.4358 - val_loss: 5.4777\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.4247 - val_loss: 5.4154\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.1086 - val_loss: 5.3557\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.9587 - val_loss: 5.2986\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.8736 - val_loss: 5.2444\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.8285 - val_loss: 5.1900\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.8237 - val_loss: 5.1372\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.4557 - val_loss: 5.0849\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.5175 - val_loss: 5.0351\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.4003 - val_loss: 4.9872\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.2210 - val_loss: 4.9391\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.2795 - val_loss: 4.8936\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.0390 - val_loss: 4.8493\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.9488 - val_loss: 4.8054\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.8252 - val_loss: 4.7625\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.8104 - val_loss: 4.7211\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.5626 - val_loss: 4.6807\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.6741 - val_loss: 4.6413\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.6024 - val_loss: 4.6028\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.4410 - val_loss: 4.5666\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.3756 - val_loss: 4.5293\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1015 - val_loss: 4.4935\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1852 - val_loss: 4.4587\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0332 - val_loss: 4.4250\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.9494 - val_loss: 4.3920\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.9125 - val_loss: 4.3587\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0064 - val_loss: 4.3266\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.8663 - val_loss: 4.2947\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.7788 - val_loss: 4.2643\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.7006 - val_loss: 4.2346\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.6783 - val_loss: 4.2051\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.5516 - val_loss: 4.1766\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.4965 - val_loss: 4.1491\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.3689 - val_loss: 4.1225\n",
      "Model: \"sequential_236\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1716 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1481 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1717 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1482 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1718 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1483 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1719 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1484 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1720 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1485 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1721 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1486 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1722 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1487 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1723 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1488 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1724 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 202s 2s/step - loss: 182.6825 - val_loss: 55.9495\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 152.8045 - val_loss: 50.6715\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 136.0137 - val_loss: 46.5667\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 120.8868 - val_loss: 43.3373\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 110.9804 - val_loss: 40.7041\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 103.1583 - val_loss: 38.5013\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 95.1914 - val_loss: 36.6822\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 88.7975 - val_loss: 35.0814\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 83.7465 - val_loss: 33.6347\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 79.2004 - val_loss: 32.3414\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 74.9485 - val_loss: 31.1684\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 72.5088 - val_loss: 30.0500\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 68.7390 - val_loss: 29.0158\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 66.0953 - val_loss: 28.0074\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 63.5719 - val_loss: 27.0485\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 60.1451 - val_loss: 26.1185\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 57.9050 - val_loss: 25.1996\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 55.4861 - val_loss: 24.3146\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 53.3008 - val_loss: 23.4337\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 51.0215 - val_loss: 22.5473\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 48.4907 - val_loss: 21.6749\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 46.4523 - val_loss: 20.8184\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 44.8409 - val_loss: 19.9647\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 42.1111 - val_loss: 19.1396\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 40.0546 - val_loss: 18.3384\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 38.1523 - val_loss: 17.5596\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 36.5692 - val_loss: 16.8098\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 34.8198 - val_loss: 16.1016\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 33.3631 - val_loss: 15.4383\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 31.7296 - val_loss: 14.8313\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 30.5555 - val_loss: 14.2772\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 28.7484 - val_loss: 13.7642\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 27.8061 - val_loss: 13.2944\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 27.2053 - val_loss: 12.8682\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 25.7269 - val_loss: 12.4882\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 24.8413 - val_loss: 12.1358\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 24.0687 - val_loss: 11.8119\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 23.3867 - val_loss: 11.4995\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.3857 - val_loss: 11.2143\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.7047 - val_loss: 10.9448\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.2902 - val_loss: 10.6911\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.8545 - val_loss: 10.4573\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.0678 - val_loss: 10.2327\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.5838 - val_loss: 10.0156\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.1235 - val_loss: 9.8102\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.6095 - val_loss: 9.6209\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.1439 - val_loss: 9.4355\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.6651 - val_loss: 9.2583\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.5591 - val_loss: 9.0888\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.0308 - val_loss: 8.9242\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.3114 - val_loss: 8.7705\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.4241 - val_loss: 8.6189\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.9626 - val_loss: 8.4766\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.4597 - val_loss: 8.3375\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.2970 - val_loss: 8.2018\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.6386 - val_loss: 8.0723\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.2524 - val_loss: 7.9411\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.1705 - val_loss: 7.8221\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.8682 - val_loss: 7.7085\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.6877 - val_loss: 7.5992\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.1205 - val_loss: 7.4929\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.2755 - val_loss: 7.3906\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.7196 - val_loss: 7.2916\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - ETA: 0s - loss: 13.56 - 0s 3ms/step - loss: 12.7089 - val_loss: 7.1917\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.3715 - val_loss: 7.0952\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.4096 - val_loss: 7.0067\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.0344 - val_loss: 6.9141\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.7905 - val_loss: 6.8263\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.5056 - val_loss: 6.7445\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.6016 - val_loss: 6.6647\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.2161 - val_loss: 6.5898\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.9801 - val_loss: 6.5124\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.0228 - val_loss: 6.4414\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.8434 - val_loss: 6.3713\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.8727 - val_loss: 6.3027\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.5638 - val_loss: 6.2347\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.2991 - val_loss: 6.1683\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.0155 - val_loss: 6.1038\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.1361 - val_loss: 6.0384\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.9018 - val_loss: 5.9780\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.8352 - val_loss: 5.9191\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.6208 - val_loss: 5.8630\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.5846 - val_loss: 5.8087\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.4773 - val_loss: 5.7545\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.3410 - val_loss: 5.7012\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.3608 - val_loss: 5.6481\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.1082 - val_loss: 5.5968\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.9627 - val_loss: 5.5454\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.0361 - val_loss: 5.4955\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.8894 - val_loss: 5.4482\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.8342 - val_loss: 5.4014\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.6362 - val_loss: 5.3585\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.4922 - val_loss: 5.3142\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.5208 - val_loss: 5.2721\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2726 - val_loss: 5.2304\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2527 - val_loss: 5.1887\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1671 - val_loss: 5.1506\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2423 - val_loss: 5.1107\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.9642 - val_loss: 5.0718\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0582 - val_loss: 5.0351\n",
      "['../Cli3/UTSW_Cli_224P_OrderFea_20_SMOTE_CV_it_2_10_5.mat', '../PrePost/PET_MOO/HN_MR_2_PPD_SMOTE_CV5_fea50_it_50_5.mat', '../PrePost/CT_MOO/HN_MR_2_PPD_SMOTE_CV5_fea50_val_it_50_5.mat']\n",
      "\n",
      "... Processing ../PrePost/PET_MOO/HN_MR_2_PPD_SMOTE_CV5_fea50_it_50_5 ...\n",
      "PET_feature shape is (179, 50)\n",
      "\n",
      "... Processing ../PrePost/CT_MOO/HN_MR_2_PPD_SMOTE_CV5_fea50_val_it_50_5 ...\n",
      "CT_feature shape is (179, 50)\n",
      "\n",
      "Feature shape is (179, 50)\n",
      "\n",
      "Label shape is (179, 1)\n",
      "\n",
      "Feature test shape is (45, 50)\n",
      "\n",
      "Label test shape is (45, 1)\n",
      "\n",
      "After SMOTE feature shape is (268, 50)\n",
      "Model: \"sequential_237\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1725 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1489 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1726 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1490 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1727 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1491 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1728 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1492 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1729 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1493 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1730 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1494 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1731 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1495 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1732 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1496 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1733 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 197s 2s/step - loss: 208.0315 - val_loss: 81.1470\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 168.7473 - val_loss: 69.4603\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 140.7479 - val_loss: 61.3023\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 123.8954 - val_loss: 55.3572\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 111.6758 - val_loss: 50.6975\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 100.2244 - val_loss: 46.9461\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 91.5617 - val_loss: 43.8422\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 84.8400 - val_loss: 41.3106\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 79.6284 - val_loss: 39.1467\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 74.2204 - val_loss: 37.3676\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 70.2969 - val_loss: 35.7833\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 66.6066 - val_loss: 34.4181\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 63.9512 - val_loss: 33.1461\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 60.0756 - val_loss: 31.9797\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 57.9552 - val_loss: 30.9238\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 55.9451 - val_loss: 29.9261\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 53.6045 - val_loss: 28.9522\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 51.3588 - val_loss: 28.0536\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 49.4840 - val_loss: 27.1716\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 47.7544 - val_loss: 26.3286\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 45.6398 - val_loss: 25.5280\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 43.3463 - val_loss: 24.6901\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 42.0043 - val_loss: 23.8580\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 40.0845 - val_loss: 23.0961\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 38.2135 - val_loss: 22.3142\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 37.1456 - val_loss: 21.5723\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 3ms/step - loss: 35.5725 - val_loss: 20.8405\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 33.6319 - val_loss: 20.1336\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 32.3327 - val_loss: 19.4347\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 31.0120 - val_loss: 18.7544\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 29.7096 - val_loss: 18.1158\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 28.7212 - val_loss: 17.5265\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 27.5010 - val_loss: 16.9597\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 26.4285 - val_loss: 16.4137\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 25.0540 - val_loss: 15.9316\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 24.1461 - val_loss: 15.4867\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 23.2609 - val_loss: 15.0963\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.5217 - val_loss: 14.7273\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22.0716 - val_loss: 14.3972\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21.2716 - val_loss: 14.1014\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.7403 - val_loss: 13.8298\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20.2305 - val_loss: 13.5523\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 19.6811 - val_loss: 13.3102\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.7556 - val_loss: 13.0766\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.4868 - val_loss: 12.8682\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.1031 - val_loss: 12.6397\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.5234 - val_loss: 12.4503\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.2110 - val_loss: 12.2507\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.0693 - val_loss: 12.0612\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.3345 - val_loss: 11.8696\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.1588 - val_loss: 11.6997\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.9705 - val_loss: 11.5472\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.8158 - val_loss: 11.4090\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.2728 - val_loss: 11.2540\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.2313 - val_loss: 11.1052\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.8446 - val_loss: 10.9642\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.4991 - val_loss: 10.8355\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.3803 - val_loss: 10.7145\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.8855 - val_loss: 10.5845\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.6351 - val_loss: 10.4551\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.5977 - val_loss: 10.3270\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.1387 - val_loss: 10.2161\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.9525 - val_loss: 10.1154\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.8558 - val_loss: 10.0038\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.8379 - val_loss: 9.8980\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.5435 - val_loss: 9.8067\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.9973 - val_loss: 9.7065\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.2017 - val_loss: 9.6155\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.9485 - val_loss: 9.5265\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.7506 - val_loss: 9.4336\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.5207 - val_loss: 9.3363\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.4837 - val_loss: 9.2472\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.1929 - val_loss: 9.1594\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.1777 - val_loss: 9.0795\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.9077 - val_loss: 9.0005\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.8599 - val_loss: 8.9255\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.7851 - val_loss: 8.8512\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.4929 - val_loss: 8.7852\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.5850 - val_loss: 8.7126\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.3931 - val_loss: 8.6348\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.2812 - val_loss: 8.5604\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.0536 - val_loss: 8.4947\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.2000 - val_loss: 8.4241\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.7002 - val_loss: 8.3635\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.6921 - val_loss: 8.3028\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.5861 - val_loss: 8.2432\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.5645 - val_loss: 8.1862\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.4616 - val_loss: 8.1250\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.3852 - val_loss: 8.0667\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.2745 - val_loss: 8.0062\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.0879 - val_loss: 7.9449\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.1495 - val_loss: 7.8906\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.8358 - val_loss: 7.8354\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.8374 - val_loss: 7.7847\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.8315 - val_loss: 7.7370\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.6413 - val_loss: 7.6891\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.5780 - val_loss: 7.6416\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.4437 - val_loss: 7.5929\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.5395 - val_loss: 7.5434\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.2771 - val_loss: 7.4932\n",
      "Model: \"sequential_238\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1734 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1497 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1735 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1498 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1736 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1499 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1737 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1500 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1738 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1501 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1739 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1502 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1740 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1503 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1741 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1504 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1742 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 197s 2s/step - loss: 198.0904 - val_loss: 80.4062\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 173.5284 - val_loss: 70.6964\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 150.7545 - val_loss: 63.4081\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 135.8654 - val_loss: 57.8874\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 121.4679 - val_loss: 53.4666\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 113.3658 - val_loss: 49.9090\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 103.9875 - val_loss: 46.9315\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 96.7783 - val_loss: 44.3599\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 91.6968 - val_loss: 42.1050\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 87.1117 - val_loss: 40.1867\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 81.9555 - val_loss: 38.3923\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 77.0232 - val_loss: 36.7274\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 75.5233 - val_loss: 35.1815\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 71.3547 - val_loss: 33.6907\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 68.8737 - val_loss: 32.2679\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 64.4238 - val_loss: 30.8860\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 60.4078 - val_loss: 29.5239\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 58.5579 - val_loss: 28.1906\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 56.2086 - val_loss: 26.8602\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 52.9655 - val_loss: 25.5567\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 49.4947 - val_loss: 24.2601\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 46.8439 - val_loss: 23.0208\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 45.3532 - val_loss: 21.8717\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 42.3090 - val_loss: 20.7955\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 40.3671 - val_loss: 19.8354\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 38.3083 - val_loss: 18.9921\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 36.7669 - val_loss: 18.2242\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 35.1500 - val_loss: 17.5242\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 33.5788 - val_loss: 16.8872\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 31.6528 - val_loss: 16.3063\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 31.4008 - val_loss: 15.7566\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 29.8323 - val_loss: 15.2412\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 28.7010 - val_loss: 14.7706\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 27.8612 - val_loss: 14.3210\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 26.5643 - val_loss: 13.9057\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 25.6367 - val_loss: 13.5135\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 25.1470 - val_loss: 13.1383\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 24.4103 - val_loss: 12.7764\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 23.9397 - val_loss: 12.4405\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22.5625 - val_loss: 12.1277\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21.9234 - val_loss: 11.8275\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21.6213 - val_loss: 11.5441\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20.8336 - val_loss: 11.2798\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20.4319 - val_loss: 11.0191\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 19.7017 - val_loss: 10.7718\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 19.3654 - val_loss: 10.5323\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.6843 - val_loss: 10.3070\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.5268 - val_loss: 10.0952\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.7906 - val_loss: 9.8904\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.2896 - val_loss: 9.6963\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.8497 - val_loss: 9.5102\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.4953 - val_loss: 9.3357\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.8134 - val_loss: 9.1650\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.9294 - val_loss: 8.9988\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.5419 - val_loss: 8.8382\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.9770 - val_loss: 8.6826\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.9137 - val_loss: 8.5327\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.6695 - val_loss: 8.3917\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.2853 - val_loss: 8.2559\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.0000 - val_loss: 8.1288\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.7919 - val_loss: 7.9996\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.6579 - val_loss: 7.8746\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.1489 - val_loss: 7.7553\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.9317 - val_loss: 7.6383\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.6158 - val_loss: 7.5260\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.4116 - val_loss: 7.4209\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.2156 - val_loss: 7.3162\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.0503 - val_loss: 7.2115\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.8102 - val_loss: 7.1085\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.7560 - val_loss: 7.0109\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.5811 - val_loss: 6.9204\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.2769 - val_loss: 6.8315\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.1504 - val_loss: 6.7450\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.9954 - val_loss: 6.6614\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.8319 - val_loss: 6.5788\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.4745 - val_loss: 6.5012\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.4614 - val_loss: 6.4239\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.1961 - val_loss: 6.3484\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.0858 - val_loss: 6.2779\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.0266 - val_loss: 6.2064\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.8542 - val_loss: 6.1381\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.7300 - val_loss: 6.0721\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.6408 - val_loss: 6.0071\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.5549 - val_loss: 5.9460\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.3159 - val_loss: 5.8804\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.3987 - val_loss: 5.8214\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.0199 - val_loss: 5.7616\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.0520 - val_loss: 5.7055\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.0668 - val_loss: 5.6508\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.8854 - val_loss: 5.5960\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.6849 - val_loss: 5.5440\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.5046 - val_loss: 5.4930\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.6063 - val_loss: 5.4434\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.3518 - val_loss: 5.3967\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.2282 - val_loss: 5.3503\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.1871 - val_loss: 5.3036\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.0967 - val_loss: 5.2598\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.0840 - val_loss: 5.2152\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.9651 - val_loss: 5.1714\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0751 - val_loss: 5.1278\n",
      "\n",
      "Feature shape is (179, 50)\n",
      "\n",
      "Feature test shape is (45, 50)\n",
      "\n",
      "After SMOTE feature shape is (268, 50)\n",
      "Model: \"sequential_239\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1743 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1505 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1744 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1506 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1745 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1507 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1746 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1508 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1747 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1509 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1748 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1510 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1749 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1511 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1750 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1512 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1751 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 198s 2s/step - loss: 159.7732 - val_loss: 68.9713\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 134.2987 - val_loss: 59.1408\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 113.2864 - val_loss: 51.9818\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 99.8927 - val_loss: 46.6072\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 89.4736 - val_loss: 42.3731\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 79.6184 - val_loss: 39.0112\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 72.9202 - val_loss: 36.3291\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 68.9849 - val_loss: 34.0936\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 64.8282 - val_loss: 32.1789\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 60.8209 - val_loss: 30.6233\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 57.6795 - val_loss: 29.2025\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 55.4933 - val_loss: 27.9356\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 52.7408 - val_loss: 26.7591\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 50.3145 - val_loss: 25.6606\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 48.4123 - val_loss: 24.6219\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 46.6043 - val_loss: 23.6025\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 44.3454 - val_loss: 22.6122\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 42.4508 - val_loss: 21.6544\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 40.7867 - val_loss: 20.6932\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 38.7464 - val_loss: 19.7523\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 37.2449 - val_loss: 18.8728\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 35.3642 - val_loss: 18.0139\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 33.8969 - val_loss: 17.1787\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 31.6830 - val_loss: 16.4021\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 30.7232 - val_loss: 15.6822\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 28.5049 - val_loss: 15.0153\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 27.9968 - val_loss: 14.4051\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 26.4476 - val_loss: 13.8621\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 25.8670 - val_loss: 13.3796\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 24.3367 - val_loss: 12.9542\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.7101 - val_loss: 12.5480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.5894 - val_loss: 12.1705\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.0019 - val_loss: 11.8174\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21.2271 - val_loss: 11.4752\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.4994 - val_loss: 11.1536\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.1716 - val_loss: 10.8482\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.4017 - val_loss: 10.5562\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - ETA: 0s - loss: 19.73 - 0s 3ms/step - loss: 19.0494 - val_loss: 10.2898\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.4605 - val_loss: 10.0405\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.7781 - val_loss: 9.8033\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.3208 - val_loss: 9.5686\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.2603 - val_loss: 9.3481\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.4082 - val_loss: 9.1380\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.0855 - val_loss: 8.9404\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.6268 - val_loss: 8.7583\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.4021 - val_loss: 8.5745\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.7700 - val_loss: 8.4102\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.4071 - val_loss: 8.2553\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.3148 - val_loss: 8.1014\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.0877 - val_loss: 7.9490\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.5932 - val_loss: 7.8061\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.4093 - val_loss: 7.6732\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.1042 - val_loss: 7.5463\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.9204 - val_loss: 7.4173\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.4962 - val_loss: 7.3009\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.5150 - val_loss: 7.1812\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.2411 - val_loss: 7.0700\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.8906 - val_loss: 6.9664\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.8117 - val_loss: 6.8612\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.5586 - val_loss: 6.7633\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.3755 - val_loss: 6.6750\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.3419 - val_loss: 6.5883\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.0342 - val_loss: 6.5003\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.8719 - val_loss: 6.4209\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.6569 - val_loss: 6.3369\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.4200 - val_loss: 6.2545\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.3116 - val_loss: 6.1763\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.1689 - val_loss: 6.0947\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.8913 - val_loss: 6.0214\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.8274 - val_loss: 5.9522\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.7681 - val_loss: 5.8846\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.6857 - val_loss: 5.8149\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.5024 - val_loss: 5.7501\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.3423 - val_loss: 5.6865\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.4030 - val_loss: 5.6183\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.2968 - val_loss: 5.5560\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.0670 - val_loss: 5.4939\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.8615 - val_loss: 5.4321\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.7025 - val_loss: 5.3770\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.6787 - val_loss: 5.3195\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.6206 - val_loss: 5.2681\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.4360 - val_loss: 5.2162\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.3374 - val_loss: 5.1641\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0807 - val_loss: 5.1153\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1611 - val_loss: 5.0671\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1024 - val_loss: 5.0189\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0577 - val_loss: 4.9740\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.9086 - val_loss: 4.9290\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.8057 - val_loss: 4.8855\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.6886 - val_loss: 4.8470\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.7449 - val_loss: 4.8056\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.5489 - val_loss: 4.7634\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.6167 - val_loss: 4.7236\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.6337 - val_loss: 4.6804\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.3715 - val_loss: 4.6432\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.2701 - val_loss: 4.6072\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.2907 - val_loss: 4.5740\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.2125 - val_loss: 4.5373\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.2239 - val_loss: 4.5033\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.1732 - val_loss: 4.4692\n",
      "Model: \"sequential_240\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1752 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1513 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1753 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1514 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1754 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1515 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1755 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1516 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1756 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1517 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1757 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1518 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1758 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1519 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1759 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1520 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1760 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 202s 2s/step - loss: 180.0766 - val_loss: 58.1855\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 152.7265 - val_loss: 52.1360\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 133.0239 - val_loss: 47.4526\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 118.1197 - val_loss: 43.8043\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 106.4232 - val_loss: 40.9456\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 98.0501 - val_loss: 38.5646\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 91.3180 - val_loss: 36.5529\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 85.0435 - val_loss: 34.8669\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 80.4642 - val_loss: 33.4073\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 76.3470 - val_loss: 32.1162\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 72.1065 - val_loss: 30.9486\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 69.0736 - val_loss: 29.8998\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 66.1853 - val_loss: 28.9091\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 63.3952 - val_loss: 27.9736\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 60.9145 - val_loss: 27.0500\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 58.2962 - val_loss: 26.1605\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 56.0585 - val_loss: 25.2767\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 53.8082 - val_loss: 24.3923\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 51.5268 - val_loss: 23.4918\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 49.3478 - val_loss: 22.5835\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 47.2537 - val_loss: 21.6661\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 44.6339 - val_loss: 20.7576\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 42.3933 - val_loss: 19.8536\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 40.7427 - val_loss: 18.9621\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 38.1926 - val_loss: 18.1052\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 36.8130 - val_loss: 17.2836\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 34.6975 - val_loss: 16.5231\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 33.1454 - val_loss: 15.8216\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 31.6576 - val_loss: 15.1946\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 30.1673 - val_loss: 14.6287\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 28.8334 - val_loss: 14.1256\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 27.4626 - val_loss: 13.6740\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 26.7222 - val_loss: 13.2541\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 25.5750 - val_loss: 12.8720\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 25.0622 - val_loss: 12.5031\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.8821 - val_loss: 12.1589\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.2654 - val_loss: 11.8353\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.5449 - val_loss: 11.5307\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.0050 - val_loss: 11.2440\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.4384 - val_loss: 10.9725\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.7358 - val_loss: 10.7106\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.0589 - val_loss: 10.4625\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.5643 - val_loss: 10.2272\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.9360 - val_loss: 10.0014\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.7631 - val_loss: 9.7872\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.0656 - val_loss: 9.5829\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.8828 - val_loss: 9.3841\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.3240 - val_loss: 9.1993\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.7576 - val_loss: 9.0190\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.5970 - val_loss: 8.8473\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.8885 - val_loss: 8.6836\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.7866 - val_loss: 8.5237\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.3627 - val_loss: 8.3710\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.0935 - val_loss: 8.2238\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.7066 - val_loss: 8.0820\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.4987 - val_loss: 7.9466\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.3153 - val_loss: 7.8121\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.7632 - val_loss: 7.6878\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.7630 - val_loss: 7.5632\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.2853 - val_loss: 7.4429\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.2033 - val_loss: 7.3267\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.7944 - val_loss: 7.2120\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.7460 - val_loss: 7.1038\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.4266 - val_loss: 7.0010\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.2226 - val_loss: 6.9015\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.1343 - val_loss: 6.8035\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.9417 - val_loss: 6.7070\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.8099 - val_loss: 6.6157\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.5398 - val_loss: 6.5271\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.2956 - val_loss: 6.4419\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.1005 - val_loss: 6.3572\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.1141 - val_loss: 6.2763\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.8043 - val_loss: 6.1969\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.6365 - val_loss: 6.1212\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.5746 - val_loss: 6.0483\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.5792 - val_loss: 5.9770\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.1805 - val_loss: 5.9055\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.2051 - val_loss: 5.8374\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.9839 - val_loss: 5.7732\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.6243 - val_loss: 5.7079\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.7979 - val_loss: 5.6451\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.6683 - val_loss: 5.5851\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.5191 - val_loss: 5.5238\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.2004 - val_loss: 5.4662\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.2733 - val_loss: 5.4096\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.2014 - val_loss: 5.3552\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.9971 - val_loss: 5.3010\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.8742 - val_loss: 5.2478\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.7750 - val_loss: 5.1966\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.8690 - val_loss: 5.1461\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.6129 - val_loss: 5.0965\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.5638 - val_loss: 5.0481\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.4537 - val_loss: 5.0029\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2744 - val_loss: 4.9578\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.4941 - val_loss: 4.9142\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1913 - val_loss: 4.8701\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.0601 - val_loss: 4.8280\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1922 - val_loss: 4.7867\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.8141 - val_loss: 4.7457\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.8637 - val_loss: 4.7077\n",
      "['../Cli3/UTSW_Cli_224P_OrderFea_30_SMOTE_CV_it_2_10_1.mat', '../PrePost/PET_MOO/HN_MR_3_PPD_SMOTE_CV5_fea50_it_50_1.mat', '../PrePost/CT_MOO/HN_MR_3_PPD_SMOTE_CV5_fea50_val_it_50_1.mat']\n",
      "\n",
      "... Processing ../PrePost/PET_MOO/HN_MR_3_PPD_SMOTE_CV5_fea50_it_50_1 ...\n",
      "PET_feature shape is (179, 50)\n",
      "\n",
      "... Processing ../PrePost/CT_MOO/HN_MR_3_PPD_SMOTE_CV5_fea50_val_it_50_1 ...\n",
      "CT_feature shape is (179, 50)\n",
      "\n",
      "Feature shape is (179, 50)\n",
      "\n",
      "Label shape is (179, 1)\n",
      "\n",
      "Feature test shape is (45, 50)\n",
      "\n",
      "Label test shape is (45, 1)\n",
      "\n",
      "After SMOTE feature shape is (266, 50)\n",
      "Model: \"sequential_241\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1761 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1521 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1762 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1522 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1763 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1523 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1764 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1524 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1765 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1525 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1766 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1526 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1767 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1527 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1768 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1528 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1769 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 196s 2s/step - loss: 199.4078 - val_loss: 88.8745\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 167.0034 - val_loss: 77.2898\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 142.5823 - val_loss: 68.1694\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 124.4445 - val_loss: 61.2505\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 110.5356 - val_loss: 55.6676\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 99.5173 - val_loss: 51.0464\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 92.0874 - val_loss: 47.1034\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 85.5781 - val_loss: 43.8418\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 79.7557 - val_loss: 40.9752\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 74.1936 - val_loss: 38.5124\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 71.0039 - val_loss: 36.2677\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 66.6805 - val_loss: 34.3063\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 63.4660 - val_loss: 32.5007\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 60.3625 - val_loss: 30.8321\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 57.5960 - val_loss: 29.2514\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 55.0743 - val_loss: 27.7787\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 52.1117 - val_loss: 26.3772\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 50.0800 - val_loss: 25.0312\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 47.5142 - val_loss: 23.8042\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 44.9083 - val_loss: 22.6095\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 42.7309 - val_loss: 21.4660\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 40.6040 - val_loss: 20.3337\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 38.7388 - val_loss: 19.2608\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 36.3173 - val_loss: 18.2452\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 34.9580 - val_loss: 17.2829\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 33.1376 - val_loss: 16.3306\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 3ms/step - loss: 30.8380 - val_loss: 15.4807\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 29.7257 - val_loss: 14.6863\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 28.1871 - val_loss: 13.9533\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 27.0176 - val_loss: 13.2876\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 25.7148 - val_loss: 12.6836\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 24.7252 - val_loss: 12.1441\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 23.5031 - val_loss: 11.6874\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 22.7247 - val_loss: 11.2490\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 21.9200 - val_loss: 10.8545\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 21.3765 - val_loss: 10.4931\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 20.1826 - val_loss: 10.1433\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 19.8227 - val_loss: 9.8271\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 18.9769 - val_loss: 9.5333\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 18.5259 - val_loss: 9.2594\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 17.8477 - val_loss: 8.9991\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 17.5672 - val_loss: 8.7529\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 17.0208 - val_loss: 8.5165\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.6419 - val_loss: 8.3055\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.1354 - val_loss: 8.1004\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.6446 - val_loss: 7.9186\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.2433 - val_loss: 7.7458\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.8933 - val_loss: 7.5700\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.4658 - val_loss: 7.4174\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.2679 - val_loss: 7.2638\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.7157 - val_loss: 7.1138\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.7220 - val_loss: 6.9756\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.3946 - val_loss: 6.8467\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.2585 - val_loss: 6.7206\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.8874 - val_loss: 6.6030\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.4061 - val_loss: 6.4893\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.1618 - val_loss: 6.3825\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.9740 - val_loss: 6.2816\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - ETA: 0s - loss: 12.71 - 0s 3ms/step - loss: 11.9613 - val_loss: 6.1883\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.5998 - val_loss: 6.0912\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.4849 - val_loss: 6.0027\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.2458 - val_loss: 5.9179\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.0848 - val_loss: 5.8332\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.7873 - val_loss: 5.7523\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.6346 - val_loss: 5.6721\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.4704 - val_loss: 5.5953\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.3163 - val_loss: 5.5245\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.3170 - val_loss: 5.4527\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.0852 - val_loss: 5.3839\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.9678 - val_loss: 5.3194\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.7179 - val_loss: 5.2587\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.6575 - val_loss: 5.2006\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.6164 - val_loss: 5.1447\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.2671 - val_loss: 5.0890\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.4010 - val_loss: 5.0357\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.1560 - val_loss: 4.9830\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.1279 - val_loss: 4.9285\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.8725 - val_loss: 4.8785\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.8356 - val_loss: 4.8319\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.6388 - val_loss: 4.7852\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.5592 - val_loss: 4.7406\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.5560 - val_loss: 4.6945\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.4124 - val_loss: 4.6510\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.3661 - val_loss: 4.6100\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.1783 - val_loss: 4.5701\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.1213 - val_loss: 4.5312\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.0134 - val_loss: 4.4944\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.8745 - val_loss: 4.4578\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.9772 - val_loss: 4.4213\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.7926 - val_loss: 4.3854\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.8611 - val_loss: 4.3518\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.7974 - val_loss: 4.3197\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.6141 - val_loss: 4.2874\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.3099 - val_loss: 4.2568\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.4617 - val_loss: 4.2267\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.4597 - val_loss: 4.1963\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.2527 - val_loss: 4.1672\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.2804 - val_loss: 4.1398\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.1239 - val_loss: 4.1127\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.1227 - val_loss: 4.0855\n",
      "Model: \"sequential_242\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1770 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1529 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1771 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1530 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1772 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1531 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1773 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1532 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1774 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1533 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1775 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1534 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1776 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1535 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1777 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1536 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1778 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 196s 2s/step - loss: 190.8650 - val_loss: 60.6113\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 159.6537 - val_loss: 54.4507\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 142.7625 - val_loss: 49.6419\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 125.8678 - val_loss: 46.0191\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 113.5000 - val_loss: 43.0085\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 104.3884 - val_loss: 40.5991\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 97.1876 - val_loss: 38.4840\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 89.2174 - val_loss: 36.7383\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 85.6802 - val_loss: 35.1969\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 79.1568 - val_loss: 33.7975\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 75.4493 - val_loss: 32.4757\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 72.3626 - val_loss: 31.2148\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 67.9903 - val_loss: 30.0488\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 64.7010 - val_loss: 28.9491\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 62.2284 - val_loss: 27.8233\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 59.8704 - val_loss: 26.7142\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 56.5616 - val_loss: 25.6375\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 53.9573 - val_loss: 24.5365\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 51.8208 - val_loss: 23.4531\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 48.5137 - val_loss: 22.3598\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 46.1377 - val_loss: 21.2915\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 43.9346 - val_loss: 20.2380\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 40.5837 - val_loss: 19.2184\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 38.6318 - val_loss: 18.2724\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 37.0120 - val_loss: 17.4018\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 34.5923 - val_loss: 16.6250\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 33.6971 - val_loss: 15.9543\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 32.2547 - val_loss: 15.3372\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 30.2959 - val_loss: 14.7921\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 29.5196 - val_loss: 14.2846\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 28.3083 - val_loss: 13.7935\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 27.4268 - val_loss: 13.3452\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 25.8827 - val_loss: 12.9369\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 25.5773 - val_loss: 12.5353\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 24.2513 - val_loss: 12.1470\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 23.6039 - val_loss: 11.7940\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 23.0728 - val_loss: 11.4507\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 21.6200 - val_loss: 11.1135\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 21.3908 - val_loss: 10.7932\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 20.5931 - val_loss: 10.4981\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 20.1266 - val_loss: 10.2194\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 19.3831 - val_loss: 9.9619\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 19.0347 - val_loss: 9.7266\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 18.4060 - val_loss: 9.4798\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 17.8644 - val_loss: 9.2483\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 17.1843 - val_loss: 9.0350\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.7514 - val_loss: 8.8339\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.2472 - val_loss: 8.6337\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.1558 - val_loss: 8.4512\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.6500 - val_loss: 8.2734\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.3158 - val_loss: 8.1101\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.9123 - val_loss: 7.9460\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.6661 - val_loss: 7.7887\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.3242 - val_loss: 7.6361\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.9451 - val_loss: 7.4908\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.5720 - val_loss: 7.3504\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.2903 - val_loss: 7.2177\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.0241 - val_loss: 7.0879\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.8383 - val_loss: 6.9563\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.4717 - val_loss: 6.8410\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.3530 - val_loss: 6.7273\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.0405 - val_loss: 6.6110\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.7908 - val_loss: 6.5061\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.5566 - val_loss: 6.4011\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.4128 - val_loss: 6.3015\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.9698 - val_loss: 6.2041\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.0897 - val_loss: 6.1132\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.6425 - val_loss: 6.0303\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.6864 - val_loss: 5.9485\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.4963 - val_loss: 5.8681\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.1544 - val_loss: 5.7844\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.0917 - val_loss: 5.7079\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.1003 - val_loss: 5.6284\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.9525 - val_loss: 5.5573\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.6524 - val_loss: 5.4797\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.4219 - val_loss: 5.4169\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.3615 - val_loss: 5.3452\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.2628 - val_loss: 5.2806\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.1521 - val_loss: 5.2183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.0477 - val_loss: 5.1547\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.9125 - val_loss: 5.0960\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.8145 - val_loss: 5.0341\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.6076 - val_loss: 4.9751\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.4859 - val_loss: 4.9230\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.5124 - val_loss: 4.8718\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.2484 - val_loss: 4.8173\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.1633 - val_loss: 4.7663\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.1425 - val_loss: 4.7177\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.0168 - val_loss: 4.6703\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.0004 - val_loss: 4.6220\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.7143 - val_loss: 4.5769\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.7069 - val_loss: 4.5288\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.6661 - val_loss: 4.4847\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.5457 - val_loss: 4.4430\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.4977 - val_loss: 4.4014\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.4638 - val_loss: 4.3634\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.3664 - val_loss: 4.3220\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.2346 - val_loss: 4.2804\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.2849 - val_loss: 4.2441\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.1542 - val_loss: 4.2061\n",
      "\n",
      "Feature shape is (179, 50)\n",
      "\n",
      "Feature test shape is (45, 50)\n",
      "\n",
      "After SMOTE feature shape is (266, 50)\n",
      "Model: \"sequential_243\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1779 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1537 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1780 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1538 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1781 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1539 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1782 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1540 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1783 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1541 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1784 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1542 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1785 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1543 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1786 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1544 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1787 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 202s 2s/step - loss: 186.3394 - val_loss: 73.8006\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 153.1790 - val_loss: 64.2899\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 128.4859 - val_loss: 57.9945\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 114.4829 - val_loss: 53.1363\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 101.9216 - val_loss: 49.4491\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 91.3444 - val_loss: 46.5355\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 87.4933 - val_loss: 44.0123\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 80.1653 - val_loss: 41.9069\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 75.6750 - val_loss: 40.1071\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 71.9683 - val_loss: 38.4750\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 67.5745 - val_loss: 37.0293\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 65.5375 - val_loss: 35.6887\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 62.2026 - val_loss: 34.4465\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 59.4981 - val_loss: 33.2862\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 57.0982 - val_loss: 32.2278\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 55.0063 - val_loss: 31.1782\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 52.5907 - val_loss: 30.2072\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 50.4798 - val_loss: 29.2650\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 49.3665 - val_loss: 28.2931\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 47.3395 - val_loss: 27.3339\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 45.8628 - val_loss: 26.3914\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 43.7454 - val_loss: 25.5054\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 42.1761 - val_loss: 24.6110\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 40.4047 - val_loss: 23.7163\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 38.0366 - val_loss: 22.8325\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 37.3399 - val_loss: 21.9372\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 35.7779 - val_loss: 21.0679\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 33.1552 - val_loss: 20.2008\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 31.7314 - val_loss: 19.3670\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 30.4524 - val_loss: 18.5633\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 29.1064 - val_loss: 17.8026\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 27.7185 - val_loss: 17.0564\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 25.8600 - val_loss: 16.3687\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 24.6155 - val_loss: 15.7303\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 24.0732 - val_loss: 15.1579\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 22.6481 - val_loss: 14.6514\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 21.6977 - val_loss: 14.2000\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - ETA: 0s - loss: 21.71 - 0s 3ms/step - loss: 20.9500 - val_loss: 13.7704\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 20.7366 - val_loss: 13.3890\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 19.5296 - val_loss: 13.0389\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 19.3092 - val_loss: 12.7098\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 18.8848 - val_loss: 12.4037\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 18.1673 - val_loss: 12.1048\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 17.5368 - val_loss: 11.8399\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 17.0255 - val_loss: 11.5756\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.7581 - val_loss: 11.3263\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.0690 - val_loss: 11.0967\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.4752 - val_loss: 10.8649\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.3956 - val_loss: 10.6392\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.2485 - val_loss: 10.4363\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.6235 - val_loss: 10.2398\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.3711 - val_loss: 10.0607\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.9568 - val_loss: 9.8721\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.6675 - val_loss: 9.6983\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.5057 - val_loss: 9.5350\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.0680 - val_loss: 9.3633\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.0418 - val_loss: 9.2020\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.8490 - val_loss: 9.0486\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.5065 - val_loss: 8.9144\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.1600 - val_loss: 8.7656\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.0735 - val_loss: 8.6345\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.6865 - val_loss: 8.5019\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.4846 - val_loss: 8.3701\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.2543 - val_loss: 8.2494\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.1557 - val_loss: 8.1400\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.0501 - val_loss: 8.0201\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.8682 - val_loss: 7.9076\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.5969 - val_loss: 7.7998\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.3582 - val_loss: 7.6940\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.3029 - val_loss: 7.5961\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.3137 - val_loss: 7.4946\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.0403 - val_loss: 7.4024\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.0736 - val_loss: 7.3139\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.7675 - val_loss: 7.2238\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.5023 - val_loss: 7.1398\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.5153 - val_loss: 7.0575\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.5016 - val_loss: 6.9777\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.3107 - val_loss: 6.8979\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.2061 - val_loss: 6.8182\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.1323 - val_loss: 6.7423\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.8960 - val_loss: 6.6670\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.8015 - val_loss: 6.5965\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.7237 - val_loss: 6.5330\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.5807 - val_loss: 6.4645\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.4617 - val_loss: 6.4025\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.5230 - val_loss: 6.3410\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.3276 - val_loss: 6.2843\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.2829 - val_loss: 6.2253\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.0733 - val_loss: 6.1656\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.0330 - val_loss: 6.1076\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.9711 - val_loss: 6.0539\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.7138 - val_loss: 6.0032\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.7552 - val_loss: 5.9549\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.6790 - val_loss: 5.8997\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.7589 - val_loss: 5.8455\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.6205 - val_loss: 5.7978\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.5251 - val_loss: 5.7495\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.5155 - val_loss: 5.7060\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.3735 - val_loss: 5.6627\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.2705 - val_loss: 5.6173\n",
      "Model: \"sequential_244\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1788 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1545 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1789 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1546 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1790 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1547 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1791 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1548 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1792 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1549 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1793 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1550 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1794 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1551 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1795 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1552 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1796 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 202s 2s/step - loss: 191.4614 - val_loss: 80.8511\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 164.5453 - val_loss: 70.5233\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 142.4720 - val_loss: 62.9856\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 127.0367 - val_loss: 57.1471\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 113.4077 - val_loss: 52.4425\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 104.2742 - val_loss: 48.6794\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 98.3573 - val_loss: 45.5304\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 90.2386 - val_loss: 42.8690\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 84.0453 - val_loss: 40.6553\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 80.8343 - val_loss: 38.6852\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 76.8288 - val_loss: 36.9559\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 72.4328 - val_loss: 35.4242\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 69.7054 - val_loss: 34.0363\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 67.3595 - val_loss: 32.7662\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 64.7018 - val_loss: 31.5780\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 61.8055 - val_loss: 30.4844\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 58.9315 - val_loss: 29.4335\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 57.5136 - val_loss: 28.4260\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 55.4179 - val_loss: 27.4380\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 53.0638 - val_loss: 26.4740\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 51.0909 - val_loss: 25.5209\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 48.9009 - val_loss: 24.5832\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 46.9775 - val_loss: 23.6714\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 45.2819 - val_loss: 22.7634\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 42.7592 - val_loss: 21.8754\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 41.0477 - val_loss: 21.0009\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 39.6157 - val_loss: 20.1329\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 37.5717 - val_loss: 19.3018\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 35.4280 - val_loss: 18.5070\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 34.2809 - val_loss: 17.7425\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 32.4387 - val_loss: 17.0209\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 31.1045 - val_loss: 16.3489\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - ETA: 0s - loss: 30.46 - 0s 3ms/step - loss: 29.2332 - val_loss: 15.7245\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 28.4310 - val_loss: 15.1557\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 27.3926 - val_loss: 14.6389\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 26.3002 - val_loss: 14.1709\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 25.2565 - val_loss: 13.7570\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 24.7014 - val_loss: 13.3645\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 23.9061 - val_loss: 13.0006\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 22.9679 - val_loss: 12.6607\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 22.3443 - val_loss: 12.3413\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 21.5236 - val_loss: 12.0382\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 21.0396 - val_loss: 11.7542\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 20.2756 - val_loss: 11.4832\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 19.8131 - val_loss: 11.2344\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 19.1569 - val_loss: 10.9941\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 18.8366 - val_loss: 10.7624\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 18.4494 - val_loss: 10.5381\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 17.8103 - val_loss: 10.3289\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 17.7280 - val_loss: 10.1226\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 17.1225 - val_loss: 9.9317\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.3551 - val_loss: 9.7450\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.0335 - val_loss: 9.5685\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.5881 - val_loss: 9.4013\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.9182 - val_loss: 9.2347\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.3063 - val_loss: 9.0779\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.8073 - val_loss: 8.9226\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.4823 - val_loss: 8.7825\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.2478 - val_loss: 8.6407\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.1167 - val_loss: 8.5018\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.9920 - val_loss: 8.3663\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.6217 - val_loss: 8.2391\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.3843 - val_loss: 8.1131\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.1827 - val_loss: 7.9957\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.8964 - val_loss: 7.8804\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.6137 - val_loss: 7.7677\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.3921 - val_loss: 7.6593\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.2855 - val_loss: 7.5581\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.9743 - val_loss: 7.4564\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.9045 - val_loss: 7.3593\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.6651 - val_loss: 7.2625\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.4231 - val_loss: 7.1700\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.3008 - val_loss: 7.0821\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.0322 - val_loss: 6.9935\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.9314 - val_loss: 6.9086\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.7932 - val_loss: 6.8284\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.8504 - val_loss: 6.7467\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.7572 - val_loss: 6.6698\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.1900 - val_loss: 6.5952\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.1525 - val_loss: 6.5206\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.2622 - val_loss: 6.4485\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.2098 - val_loss: 6.3804\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.7568 - val_loss: 6.3134\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.4864 - val_loss: 6.2474\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.7857 - val_loss: 6.1839\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.4911 - val_loss: 6.1233\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.1872 - val_loss: 6.0622\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.3500 - val_loss: 6.0027\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.9742 - val_loss: 5.9452\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.9773 - val_loss: 5.8899\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.8139 - val_loss: 5.8340\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.8776 - val_loss: 5.7808\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.7828 - val_loss: 5.7277\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.5938 - val_loss: 5.6785\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.5904 - val_loss: 5.6285\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.4021 - val_loss: 5.5783\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.4149 - val_loss: 5.5308\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.3601 - val_loss: 5.4840\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.4275 - val_loss: 5.4385\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.9865 - val_loss: 5.3936\n",
      "['../Cli3/UTSW_Cli_224P_OrderFea_30_SMOTE_CV_it_2_10_2.mat', '../PrePost/PET_MOO/HN_MR_3_PPD_SMOTE_CV5_fea50_it_50_2.mat', '../PrePost/CT_MOO/HN_MR_3_PPD_SMOTE_CV5_fea50_val_it_50_2.mat']\n",
      "\n",
      "... Processing ../PrePost/PET_MOO/HN_MR_3_PPD_SMOTE_CV5_fea50_it_50_2 ...\n",
      "PET_feature shape is (178, 50)\n",
      "\n",
      "... Processing ../PrePost/CT_MOO/HN_MR_3_PPD_SMOTE_CV5_fea50_val_it_50_2 ...\n",
      "CT_feature shape is (178, 50)\n",
      "\n",
      "Feature shape is (178, 50)\n",
      "\n",
      "Label shape is (178, 1)\n",
      "\n",
      "Feature test shape is (46, 50)\n",
      "\n",
      "Label test shape is (46, 1)\n",
      "\n",
      "After SMOTE feature shape is (266, 50)\n",
      "Model: \"sequential_245\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1797 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1553 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1798 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1554 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1799 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1555 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1800 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1556 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1801 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1557 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1802 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1558 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1803 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1559 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1804 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1560 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1805 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 200s 2s/step - loss: 202.7701 - val_loss: 77.9753\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 165.4227 - val_loss: 67.1095\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 138.6936 - val_loss: 59.2854\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 122.9814 - val_loss: 53.2900\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 108.9424 - val_loss: 48.7852\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 98.6262 - val_loss: 45.1353\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 88.5624 - val_loss: 42.2222\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 82.8427 - val_loss: 39.7860\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 77.1774 - val_loss: 37.7655\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 72.3286 - val_loss: 36.0423\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 67.3429 - val_loss: 34.5617\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 64.7272 - val_loss: 33.2454\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 61.1458 - val_loss: 32.0343\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 58.1992 - val_loss: 30.8436\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 54.9215 - val_loss: 29.7195\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 52.8109 - val_loss: 28.6229\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 49.7983 - val_loss: 27.5339\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 47.6300 - val_loss: 26.4400\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 44.8551 - val_loss: 25.3870\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 43.1589 - val_loss: 24.2839\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 40.2963 - val_loss: 23.2300\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 38.4563 - val_loss: 22.1907\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 36.4814 - val_loss: 21.1856\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 34.2444 - val_loss: 20.2805\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 33.0838 - val_loss: 19.4137\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 31.1930 - val_loss: 18.6279\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 29.5466 - val_loss: 17.9198\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 28.4861 - val_loss: 17.2763\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 26.7711 - val_loss: 16.6755\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 25.7933 - val_loss: 16.1147\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 24.6865 - val_loss: 15.6271\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 23.7684 - val_loss: 15.1403\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 22.9869 - val_loss: 14.6995\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 21.7438 - val_loss: 14.2695\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 21.2240 - val_loss: 13.8620\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 20.5708 - val_loss: 13.4902\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 20.0637 - val_loss: 13.1255\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 19.3247 - val_loss: 12.8008\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 18.8293 - val_loss: 12.4622\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 18.1654 - val_loss: 12.1354\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 17.7104 - val_loss: 11.8426\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 17.1124 - val_loss: 11.5574\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.5985 - val_loss: 11.3076\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.1281 - val_loss: 11.0649\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.0135 - val_loss: 10.8248\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.3261 - val_loss: 10.5805\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.0293 - val_loss: 10.3528\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.7746 - val_loss: 10.1366\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.2995 - val_loss: 9.9382\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.9948 - val_loss: 9.7493\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.7254 - val_loss: 9.5585\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.3008 - val_loss: 9.3746\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.1336 - val_loss: 9.2054\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.7529 - val_loss: 9.0397\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.5802 - val_loss: 8.8766\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.2987 - val_loss: 8.7185\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.9652 - val_loss: 8.5718\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.8463 - val_loss: 8.4247\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.4733 - val_loss: 8.2804\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.5296 - val_loss: 8.1457\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.3878 - val_loss: 8.0196\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.0667 - val_loss: 7.8877\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.9223 - val_loss: 7.7627\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.4536 - val_loss: 7.6439\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.4024 - val_loss: 7.5309\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.3364 - val_loss: 7.4217\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.0563 - val_loss: 7.3173\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.0150 - val_loss: 7.2175\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.0085 - val_loss: 7.1150\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.8790 - val_loss: 7.0157\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.6469 - val_loss: 6.9187\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.4712 - val_loss: 6.8240\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.3086 - val_loss: 6.7396\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.2148 - val_loss: 6.6523\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.1809 - val_loss: 6.5798\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.0576 - val_loss: 6.4900\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.0268 - val_loss: 6.4106\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.8128 - val_loss: 6.3339\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.5301 - val_loss: 6.2644\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.6257 - val_loss: 6.1901\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.5041 - val_loss: 6.1131\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.2804 - val_loss: 6.0463\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.2969 - val_loss: 5.9840\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.2936 - val_loss: 5.9092\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.0122 - val_loss: 5.8475\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.0801 - val_loss: 5.7825\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.8539 - val_loss: 5.7204\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.9126 - val_loss: 5.6594\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.9505 - val_loss: 5.6040\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.7772 - val_loss: 5.5473\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.7091 - val_loss: 5.4885\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.6601 - val_loss: 5.4354\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.4620 - val_loss: 5.3793\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.5402 - val_loss: 5.3284\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.4847 - val_loss: 5.2792\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.2910 - val_loss: 5.2329\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.3043 - val_loss: 5.1854\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.1545 - val_loss: 5.1357\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.0991 - val_loss: 5.0921\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.1701 - val_loss: 5.0453\n",
      "Model: \"sequential_246\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1806 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1561 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1807 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1562 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1808 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1563 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1809 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1564 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1810 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1565 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1811 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1566 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1812 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1567 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1813 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1568 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1814 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 195s 2s/step - loss: 200.4806 - val_loss: 61.5974\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 169.7325 - val_loss: 55.8678\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 145.8652 - val_loss: 51.4156\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 129.3347 - val_loss: 47.7823\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 117.2146 - val_loss: 44.8627\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 108.7156 - val_loss: 42.3464\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 99.0956 - val_loss: 40.1872\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 92.9512 - val_loss: 38.3221\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 86.6444 - val_loss: 36.6946\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 80.7301 - val_loss: 35.2391\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 77.9906 - val_loss: 33.9000\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 73.0155 - val_loss: 32.6381\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 69.2508 - val_loss: 31.4545\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 66.7721 - val_loss: 30.3352\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 63.6734 - val_loss: 29.2180\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 60.3162 - val_loss: 28.1461\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 57.3122 - val_loss: 27.1149\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 55.2965 - val_loss: 26.0639\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 51.7998 - val_loss: 25.0208\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 49.1048 - val_loss: 23.9805\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 46.1494 - val_loss: 22.9211\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 44.0843 - val_loss: 21.8721\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 41.6920 - val_loss: 20.8291\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 38.8108 - val_loss: 19.8022\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 37.4826 - val_loss: 18.8693\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 35.1805 - val_loss: 18.0017\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 33.2911 - val_loss: 17.2488\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 31.8421 - val_loss: 16.5757\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 30.3061 - val_loss: 15.9942\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 29.2839 - val_loss: 15.4596\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 28.2399 - val_loss: 14.9493\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 26.8797 - val_loss: 14.4779\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 25.9928 - val_loss: 14.0424\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 24.5444 - val_loss: 13.6319\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 24.0568 - val_loss: 13.2529\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 23.2836 - val_loss: 12.8838\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 22.3805 - val_loss: 12.5227\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 21.3628 - val_loss: 12.1930\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 20.6971 - val_loss: 11.8787\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 20.2267 - val_loss: 11.5785\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 19.7019 - val_loss: 11.2875\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 19.2062 - val_loss: 11.0280\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 18.5982 - val_loss: 10.7686\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 17.8441 - val_loss: 10.5232\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 17.3490 - val_loss: 10.2912\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.9789 - val_loss: 10.0756\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.8176 - val_loss: 9.8669\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.2760 - val_loss: 9.6692\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.5350 - val_loss: 9.4745\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.4009 - val_loss: 9.2911\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.2378 - val_loss: 9.1101\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.7942 - val_loss: 8.9328\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.2325 - val_loss: 8.7683\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.9559 - val_loss: 8.6170\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.6599 - val_loss: 8.4580\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.3991 - val_loss: 8.3057\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.9660 - val_loss: 8.1591\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.9530 - val_loss: 8.0226\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.6324 - val_loss: 7.8885\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.6331 - val_loss: 7.7576\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.1193 - val_loss: 7.6338\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.8052 - val_loss: 7.5115\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.7360 - val_loss: 7.3957\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.5105 - val_loss: 7.2798\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.3107 - val_loss: 7.1729\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.1680 - val_loss: 7.0669\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.9030 - val_loss: 6.9673\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.7957 - val_loss: 6.8677\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.7393 - val_loss: 6.7664\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.5029 - val_loss: 6.6708\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.4002 - val_loss: 6.5822\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.0510 - val_loss: 6.4924\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.1403 - val_loss: 6.4045\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.7808 - val_loss: 6.3228\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.8174 - val_loss: 6.2383\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.5344 - val_loss: 6.1607\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.5464 - val_loss: 6.0824\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.2540 - val_loss: 6.0093\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.1930 - val_loss: 5.9373\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.2525 - val_loss: 5.8667\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.9391 - val_loss: 5.7951\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.8219 - val_loss: 5.7257\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.5954 - val_loss: 5.6626\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.5216 - val_loss: 5.6007\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.4834 - val_loss: 5.5380\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.3827 - val_loss: 5.4772\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.1630 - val_loss: 5.4187\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.1639 - val_loss: 5.3613\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.1521 - val_loss: 5.3065\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.9968 - val_loss: 5.2506\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.9701 - val_loss: 5.1987\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.9737 - val_loss: 5.1467\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.8214 - val_loss: 5.0972\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.8350 - val_loss: 5.0491\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.6909 - val_loss: 5.0020\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.6298 - val_loss: 4.9551\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.3849 - val_loss: 4.9098\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.4430 - val_loss: 4.8650\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.5333 - val_loss: 4.8204\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.2358 - val_loss: 4.7785\n",
      "\n",
      "Feature shape is (178, 50)\n",
      "\n",
      "Feature test shape is (46, 50)\n",
      "\n",
      "After SMOTE feature shape is (266, 50)\n",
      "Model: \"sequential_247\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1815 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1569 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1816 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1570 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1817 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1571 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1818 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1572 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1819 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1573 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1820 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1574 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1821 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1575 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1822 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1576 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1823 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 192s 2s/step - loss: 179.7837 - val_loss: 62.2123\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 144.0876 - val_loss: 53.4379\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 120.0490 - val_loss: 47.6171\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 103.6311 - val_loss: 43.4641\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 92.2238 - val_loss: 40.2029\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 84.3382 - val_loss: 37.5370\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 79.7218 - val_loss: 35.2864\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 72.5784 - val_loss: 33.3341\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 68.6811 - val_loss: 31.7024\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 65.6851 - val_loss: 30.2632\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 63.4808 - val_loss: 28.9928\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 60.3679 - val_loss: 27.8356\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 58.0004 - val_loss: 26.7557\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 55.8778 - val_loss: 25.7531\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 53.5427 - val_loss: 24.8329\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 52.0095 - val_loss: 23.9594\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 50.2413 - val_loss: 23.1397\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 48.2639 - val_loss: 22.3315\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 46.2323 - val_loss: 21.5537\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 45.5343 - val_loss: 20.7707\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 43.2861 - val_loss: 20.0148\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 42.1476 - val_loss: 19.2737\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 40.1527 - val_loss: 18.5322\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 38.4789 - val_loss: 17.8015\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 37.1572 - val_loss: 17.0809\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 35.4023 - val_loss: 16.3511\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 33.8898 - val_loss: 15.6393\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 32.2513 - val_loss: 14.9349\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 31.1854 - val_loss: 14.2504\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 29.2081 - val_loss: 13.6041\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 28.1104 - val_loss: 12.9792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 26.4847 - val_loss: 12.3764\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 25.4715 - val_loss: 11.8200\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 24.0054 - val_loss: 11.2921\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 23.3060 - val_loss: 10.7982\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 21.9495 - val_loss: 10.3559\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 21.5660 - val_loss: 9.9474\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 20.0505 - val_loss: 9.5806\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 19.7243 - val_loss: 9.2610\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 19.1096 - val_loss: 8.9686\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 18.4490 - val_loss: 8.7081\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 17.6458 - val_loss: 8.4736\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 17.1180 - val_loss: 8.2618\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 17.0755 - val_loss: 8.0673\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.5314 - val_loss: 7.8903\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.0399 - val_loss: 7.7250\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.8994 - val_loss: 7.5674\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.2409 - val_loss: 7.4224\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.1006 - val_loss: 7.2835\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.7833 - val_loss: 7.1450\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.5672 - val_loss: 7.0169\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.0386 - val_loss: 6.8920\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.8911 - val_loss: 6.7783\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.7667 - val_loss: 6.6638\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.5824 - val_loss: 6.5579\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.1717 - val_loss: 6.4556\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.9784 - val_loss: 6.3572\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.5905 - val_loss: 6.2623\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 12.2450 - val_loss: 6.1721\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.4411 - val_loss: 6.0871\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.9939 - val_loss: 6.0055\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.7085 - val_loss: 5.9283\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.5776 - val_loss: 5.8538\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.3969 - val_loss: 5.7803\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.2255 - val_loss: 5.7107\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.0636 - val_loss: 5.6427\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.9853 - val_loss: 5.5749\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.7318 - val_loss: 5.5132\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.4320 - val_loss: 5.4499\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.3287 - val_loss: 5.3913\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.2319 - val_loss: 5.3350\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.1155 - val_loss: 5.2796\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.1560 - val_loss: 5.2261\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.8519 - val_loss: 5.1754\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.9286 - val_loss: 5.1266\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.5805 - val_loss: 5.0758\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.6105 - val_loss: 5.0279\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.2469 - val_loss: 4.9813\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.1202 - val_loss: 4.9367\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.0911 - val_loss: 4.8938\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.0837 - val_loss: 4.8523\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.1963 - val_loss: 4.8097\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.8266 - val_loss: 4.7694\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.7674 - val_loss: 4.7307\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.6627 - val_loss: 4.6927\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.5926 - val_loss: 4.6555\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.3601 - val_loss: 4.6202\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.5574 - val_loss: 4.5864\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.2441 - val_loss: 4.5525\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.4190 - val_loss: 4.5186\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.2686 - val_loss: 4.4847\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.1718 - val_loss: 4.4529\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.9389 - val_loss: 4.4229\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.8673 - val_loss: 4.3916\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.9053 - val_loss: 4.3611\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.9657 - val_loss: 4.3316\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.7456 - val_loss: 4.3036\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.6426 - val_loss: 4.2756\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.5092 - val_loss: 4.2490\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.4572 - val_loss: 4.2223\n",
      "Model: \"sequential_248\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1824 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1577 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1825 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1578 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1826 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1579 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1827 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1580 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1828 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1581 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1829 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1582 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1830 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1583 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1831 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1584 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1832 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 192s 2s/step - loss: 151.3182 - val_loss: 77.9917\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 131.7924 - val_loss: 70.5477\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 117.6409 - val_loss: 64.5553\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 105.9469 - val_loss: 59.4757\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 97.4923 - val_loss: 55.3183\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 91.7888 - val_loss: 51.6680\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 87.2119 - val_loss: 48.5252\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 81.3583 - val_loss: 45.7588\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 76.9583 - val_loss: 43.3579\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 72.2063 - val_loss: 41.2432\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 70.1660 - val_loss: 39.2478\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 65.7782 - val_loss: 37.5208\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 63.2650 - val_loss: 35.8791\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 60.0218 - val_loss: 34.3618\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 57.4005 - val_loss: 32.9129\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 55.7541 - val_loss: 31.5227\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 53.1526 - val_loss: 30.1375\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 50.8721 - val_loss: 28.8491\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 48.3873 - val_loss: 27.5673\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 46.2925 - val_loss: 26.3177\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 44.3231 - val_loss: 25.0510\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 41.4471 - val_loss: 23.8697\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 39.4511 - val_loss: 22.6812\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 37.2987 - val_loss: 21.5715\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 35.3974 - val_loss: 20.5128\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 33.8604 - val_loss: 19.5491\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 31.9903 - val_loss: 18.6510\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 30.5817 - val_loss: 17.8677\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 29.0536 - val_loss: 17.1838\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 28.6508 - val_loss: 16.5530\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 27.1429 - val_loss: 15.9715\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 26.0616 - val_loss: 15.4549\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 24.9813 - val_loss: 14.9783\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 24.0235 - val_loss: 14.5382\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 23.2178 - val_loss: 14.1069\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 22.5861 - val_loss: 13.7061\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 22.0417 - val_loss: 13.3385\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 21.2684 - val_loss: 13.0064\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 20.8882 - val_loss: 12.6757\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 20.0160 - val_loss: 12.3593\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 19.4851 - val_loss: 12.0710\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 19.0544 - val_loss: 11.7954\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 18.6724 - val_loss: 11.5305\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 17.7962 - val_loss: 11.2719\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 17.2527 - val_loss: 11.0374\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 17.1272 - val_loss: 10.8104\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.8110 - val_loss: 10.5857\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.1714 - val_loss: 10.3680\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.1670 - val_loss: 10.1482\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.5472 - val_loss: 9.9344\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.2320 - val_loss: 9.7429\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.8344 - val_loss: 9.5610\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.4200 - val_loss: 9.3937\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 14.1589 - val_loss: 9.2307\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.9154 - val_loss: 9.0551\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.5484 - val_loss: 8.9019\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 13.3352 - val_loss: 8.7445\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.9782 - val_loss: 8.6032\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.7448 - val_loss: 8.4644\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.5515 - val_loss: 8.3244\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.4098 - val_loss: 8.1878\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.0935 - val_loss: 8.0760\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.5865 - val_loss: 7.9515\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.4763 - val_loss: 7.8320\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.3090 - val_loss: 7.7184\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.2603 - val_loss: 7.6226\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.0120 - val_loss: 7.5223\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.9895 - val_loss: 7.4176\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.5962 - val_loss: 7.3158\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.4485 - val_loss: 7.2230\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.2183 - val_loss: 7.1277\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10.0533 - val_loss: 7.0373\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.7658 - val_loss: 6.9527\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.7480 - val_loss: 6.8633\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.7329 - val_loss: 6.7812\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.8157 - val_loss: 6.6996\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.4408 - val_loss: 6.6273\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.2970 - val_loss: 6.5511\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.2878 - val_loss: 6.4730\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.1947 - val_loss: 6.4052\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - ETA: 0s - loss: 9.567 - 0s 3ms/step - loss: 9.0933 - val_loss: 6.3330\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.5777 - val_loss: 6.2627\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.6699 - val_loss: 6.2009\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.4605 - val_loss: 6.1383\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.4036 - val_loss: 6.0849\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.3743 - val_loss: 6.0193\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.1045 - val_loss: 5.9590\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.0901 - val_loss: 5.9025\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.9642 - val_loss: 5.8534\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.8404 - val_loss: 5.7965\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.8617 - val_loss: 5.7411\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.8161 - val_loss: 5.6848\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.7315 - val_loss: 5.6331\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.6128 - val_loss: 5.5810\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.4968 - val_loss: 5.5288\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.4703 - val_loss: 5.4843\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.3985 - val_loss: 5.4395\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.3354 - val_loss: 5.3956\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.1676 - val_loss: 5.3510\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.1498 - val_loss: 5.3057\n",
      "['../Cli3/UTSW_Cli_224P_OrderFea_30_SMOTE_CV_it_2_10_3.mat', '../PrePost/PET_MOO/HN_MR_3_PPD_SMOTE_CV5_fea50_it_50_3.mat', '../PrePost/CT_MOO/HN_MR_3_PPD_SMOTE_CV5_fea50_val_it_50_3.mat']\n",
      "\n",
      "... Processing ../PrePost/PET_MOO/HN_MR_3_PPD_SMOTE_CV5_fea50_it_50_3 ...\n",
      "PET_feature shape is (180, 50)\n",
      "\n",
      "... Processing ../PrePost/CT_MOO/HN_MR_3_PPD_SMOTE_CV5_fea50_val_it_50_3 ...\n",
      "CT_feature shape is (180, 50)\n",
      "\n",
      "Feature shape is (180, 50)\n",
      "\n",
      "Label shape is (180, 1)\n",
      "\n",
      "Feature test shape is (44, 50)\n",
      "\n",
      "Label test shape is (44, 1)\n",
      "\n",
      "After SMOTE feature shape is (268, 50)\n",
      "Model: \"sequential_249\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1833 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1585 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1834 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1586 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1835 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1587 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1836 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1588 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1837 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1589 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1838 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1590 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1839 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1591 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1840 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1592 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1841 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 193s 2s/step - loss: 198.5101 - val_loss: 73.5257\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 160.6666 - val_loss: 62.9631\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 140.3675 - val_loss: 55.0904\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 117.2049 - val_loss: 49.3224\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 106.3250 - val_loss: 44.7763\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 95.6815 - val_loss: 41.1349\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 85.9028 - val_loss: 38.1958\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 78.8995 - val_loss: 35.7380\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 74.3951 - val_loss: 33.6476\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 69.3714 - val_loss: 31.8097\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 65.0433 - val_loss: 30.1543\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 61.7538 - val_loss: 28.6535\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 57.9808 - val_loss: 27.2924\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 55.2642 - val_loss: 25.9773\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 52.0689 - val_loss: 24.7411\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 49.3443 - val_loss: 23.5323\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 46.6033 - val_loss: 22.3504\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 44.3766 - val_loss: 21.1892\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 41.7553 - val_loss: 20.0565\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 39.2176 - val_loss: 18.9666\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 37.0283 - val_loss: 17.9021\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 34.9163 - val_loss: 16.8848\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 32.6786 - val_loss: 15.9512\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 31.2285 - val_loss: 15.1202\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 29.2649 - val_loss: 14.3884\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 27.9083 - val_loss: 13.7558\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 3ms/step - loss: 26.4740 - val_loss: 13.1999\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 25.4180 - val_loss: 12.6863\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 24.7806 - val_loss: 12.2112\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.5656 - val_loss: 11.7850\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.3462 - val_loss: 11.3962\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21.8415 - val_loss: 11.0321\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.9454 - val_loss: 10.6910\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.4493 - val_loss: 10.3716\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.8503 - val_loss: 10.0593\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.1317 - val_loss: 9.7725\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.5876 - val_loss: 9.4985\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.9740 - val_loss: 9.2511\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.3352 - val_loss: 9.0233\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.8712 - val_loss: 8.8018\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.4580 - val_loss: 8.5970\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.2933 - val_loss: 8.3921\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.6497 - val_loss: 8.1973\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.4721 - val_loss: 8.0157\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.0140 - val_loss: 7.8485\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.5784 - val_loss: 7.6838\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.3280 - val_loss: 7.5226\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.0570 - val_loss: 7.3706\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.7490 - val_loss: 7.2318\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.3834 - val_loss: 7.0988\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.1755 - val_loss: 6.9691\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.0273 - val_loss: 6.8457\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.4743 - val_loss: 6.7267\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.4786 - val_loss: 6.6107\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.1841 - val_loss: 6.5026\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.1432 - val_loss: 6.3978\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.7458 - val_loss: 6.2955\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.6552 - val_loss: 6.1978\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.3092 - val_loss: 6.1037\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.2750 - val_loss: 6.0106\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.9729 - val_loss: 5.9243\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.7986 - val_loss: 5.8407\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.7282 - val_loss: 5.7599\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.4790 - val_loss: 5.6774\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.2733 - val_loss: 5.6004\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.1373 - val_loss: 5.5273\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.1197 - val_loss: 5.4559\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.9630 - val_loss: 5.3865\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.6345 - val_loss: 5.3193\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.5974 - val_loss: 5.2560\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.5082 - val_loss: 5.1925\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.5005 - val_loss: 5.1325\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.2225 - val_loss: 5.0752\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.1157 - val_loss: 5.0206\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.9993 - val_loss: 4.9649\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.8627 - val_loss: 4.9116\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.8456 - val_loss: 4.8608\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.6350 - val_loss: 4.8092\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.7375 - val_loss: 4.7599\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.4943 - val_loss: 4.7129\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.4944 - val_loss: 4.6665\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.3560 - val_loss: 4.6224\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2444 - val_loss: 4.5794\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1931 - val_loss: 4.5374\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0382 - val_loss: 4.4956\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.9655 - val_loss: 4.4562\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.9312 - val_loss: 4.4179\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.7611 - val_loss: 4.3797\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.8140 - val_loss: 4.3425\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.7467 - val_loss: 4.3066\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.6187 - val_loss: 4.2720\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.6550 - val_loss: 4.2374\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.5619 - val_loss: 4.2036\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.2220 - val_loss: 4.1708\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.3560 - val_loss: 4.1397\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.3184 - val_loss: 4.1082\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.0618 - val_loss: 4.0781\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.1279 - val_loss: 4.0489\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.0657 - val_loss: 4.0201\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6.9948 - val_loss: 3.9916\n",
      "Model: \"sequential_250\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1842 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1593 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1843 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1594 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1844 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1595 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1845 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1596 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1846 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1597 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1847 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1598 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1848 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1599 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1849 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1600 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1850 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 195s 2s/step - loss: 200.0501 - val_loss: 79.0415\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 171.7688 - val_loss: 71.3361\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 144.4974 - val_loss: 65.3168\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 129.5567 - val_loss: 60.3286\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 114.0604 - val_loss: 56.3619\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 106.9937 - val_loss: 52.9906\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 98.3126 - val_loss: 50.1872\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 90.5743 - val_loss: 47.8059\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 85.4048 - val_loss: 45.7462\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 80.3335 - val_loss: 43.9077\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 76.2676 - val_loss: 42.2595\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 71.6665 - val_loss: 40.8163\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 68.2458 - val_loss: 39.4564\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 66.3323 - val_loss: 38.2346\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 62.5664 - val_loss: 37.0611\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 60.6545 - val_loss: 35.9664\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 58.3382 - val_loss: 34.9033\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 55.8533 - val_loss: 33.8760\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 54.1081 - val_loss: 32.8867\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 51.7705 - val_loss: 31.9540\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 49.8665 - val_loss: 31.0041\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 48.4877 - val_loss: 30.1029\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 46.3286 - val_loss: 29.1860\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 43.8478 - val_loss: 28.2825\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 42.8223 - val_loss: 27.3652\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 40.3876 - val_loss: 26.5002\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 38.6378 - val_loss: 25.6058\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 37.3262 - val_loss: 24.7319\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 35.4928 - val_loss: 23.8731\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 33.3894 - val_loss: 23.0489\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 32.0131 - val_loss: 22.2580\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 30.6278 - val_loss: 21.4857\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 28.8722 - val_loss: 20.7653\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 27.5996 - val_loss: 20.0978\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 26.5530 - val_loss: 19.5186\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 25.1455 - val_loss: 18.9659\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 24.0452 - val_loss: 18.4937\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22.8483 - val_loss: 18.0755\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22.2928 - val_loss: 17.6794\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.4534 - val_loss: 17.3420\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20.8511 - val_loss: 17.0270\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20.2073 - val_loss: 16.7234\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.5964 - val_loss: 16.4407\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 19.1333 - val_loss: 16.1562\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.4276 - val_loss: 15.8927\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.1608 - val_loss: 15.6411\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.3588 - val_loss: 15.4183\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.1791 - val_loss: 15.1912\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.6457 - val_loss: 14.9969\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.2836 - val_loss: 14.8050\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.8319 - val_loss: 14.6145\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.5840 - val_loss: 14.4327\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.1357 - val_loss: 14.2416\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.6672 - val_loss: 14.0698\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.3418 - val_loss: 13.9114\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.2340 - val_loss: 13.7602\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.7982 - val_loss: 13.6055\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.3082 - val_loss: 13.4717\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.2550 - val_loss: 13.3456\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.8603 - val_loss: 13.2322\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.7670 - val_loss: 13.0936\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.4991 - val_loss: 12.9679\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.3143 - val_loss: 12.8440\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.9457 - val_loss: 12.7332\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.7845 - val_loss: 12.6204\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.7241 - val_loss: 12.5045\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.5660 - val_loss: 12.4052\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.2556 - val_loss: 12.3126\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.9655 - val_loss: 12.2139\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.6117 - val_loss: 12.1247\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.6947 - val_loss: 12.0227\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.6036 - val_loss: 11.9389\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.4502 - val_loss: 11.8565\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.1363 - val_loss: 11.7732\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.0222 - val_loss: 11.7018\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.9199 - val_loss: 11.6366\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.6616 - val_loss: 11.5660\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.7365 - val_loss: 11.4977\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.5329 - val_loss: 11.4255\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.3557 - val_loss: 11.3563\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.2989 - val_loss: 11.2889\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.0355 - val_loss: 11.2247\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.0519 - val_loss: 11.1617\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.0440 - val_loss: 11.0930\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.8462 - val_loss: 11.0255\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.7469 - val_loss: 10.9685\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.7191 - val_loss: 10.9123\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.6428 - val_loss: 10.8601\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.4416 - val_loss: 10.8049\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.3093 - val_loss: 10.7393\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.2090 - val_loss: 10.6914\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2515 - val_loss: 10.6419\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.1215 - val_loss: 10.5950\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.9346 - val_loss: 10.5487\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.8817 - val_loss: 10.5093\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.7720 - val_loss: 10.4589\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.6854 - val_loss: 10.4146\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.7375 - val_loss: 10.3696\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.7107 - val_loss: 10.3347\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.5271 - val_loss: 10.2970\n",
      "\n",
      "Feature shape is (180, 50)\n",
      "\n",
      "Feature test shape is (44, 50)\n",
      "\n",
      "After SMOTE feature shape is (268, 50)\n",
      "Model: \"sequential_251\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1851 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1601 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1852 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1602 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1853 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1603 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1854 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1604 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1855 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1605 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1856 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1606 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1857 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1607 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1858 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1608 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1859 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 195s 2s/step - loss: 178.6337 - val_loss: 60.0998\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 146.9447 - val_loss: 52.3344\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 122.1978 - val_loss: 46.6025\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 105.8696 - val_loss: 42.2404\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 94.7035 - val_loss: 38.7736\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 85.0407 - val_loss: 36.0087\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 78.0950 - val_loss: 33.7535\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 73.3673 - val_loss: 31.8436\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 69.0000 - val_loss: 30.1740\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 64.1504 - val_loss: 28.7063\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 60.9212 - val_loss: 27.3913\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 58.6519 - val_loss: 26.1908\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 55.3021 - val_loss: 25.0336\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 52.4967 - val_loss: 23.9260\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 49.7653 - val_loss: 22.8234\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 47.7186 - val_loss: 21.7187\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 45.2489 - val_loss: 20.6245\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 42.1236 - val_loss: 19.5467\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 40.5456 - val_loss: 18.5023\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 38.2144 - val_loss: 17.5071\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 35.8942 - val_loss: 16.6155\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 34.0836 - val_loss: 15.8039\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 32.0022 - val_loss: 15.0844\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 31.4300 - val_loss: 14.4483\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 29.7802 - val_loss: 13.8739\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 28.7094 - val_loss: 13.3550\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 27.4447 - val_loss: 12.8684\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 26.2073 - val_loss: 12.4182\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 25.1720 - val_loss: 12.0068\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 24.3249 - val_loss: 11.6207\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 2ms/step - loss: 23.2866 - val_loss: 11.2657\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.9727 - val_loss: 10.9293\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.8541 - val_loss: 10.6148\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.5798 - val_loss: 10.3217\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20.6781 - val_loss: 10.0440\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.2128 - val_loss: 9.7777\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.2740 - val_loss: 9.5281\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.9797 - val_loss: 9.2866\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.3073 - val_loss: 9.0571\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.8178 - val_loss: 8.8479\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.4975 - val_loss: 8.6491\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.0711 - val_loss: 8.4567\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.7455 - val_loss: 8.2671\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.2459 - val_loss: 8.0928\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.8893 - val_loss: 7.9249\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.6353 - val_loss: 7.7639\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.0172 - val_loss: 7.6037\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.9559 - val_loss: 7.4563\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.5134 - val_loss: 7.3152\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.1686 - val_loss: 7.1890\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.9761 - val_loss: 7.0619\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.4307 - val_loss: 6.9366\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.0942 - val_loss: 6.8238\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.0132 - val_loss: 6.7113\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.8635 - val_loss: 6.6071\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.4764 - val_loss: 6.4935\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.1618 - val_loss: 6.3857\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.0895 - val_loss: 6.2876\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.9410 - val_loss: 6.1871\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.6983 - val_loss: 6.0895\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.3980 - val_loss: 5.9997\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.1202 - val_loss: 5.9161\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.9952 - val_loss: 5.8287\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.9443 - val_loss: 5.7466\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.7231 - val_loss: 5.6702\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.4314 - val_loss: 5.5988\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.4518 - val_loss: 5.5258\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.3652 - val_loss: 5.4547\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.9835 - val_loss: 5.3882\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.9265 - val_loss: 5.3198\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.7674 - val_loss: 5.2587\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.7265 - val_loss: 5.1948\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.5715 - val_loss: 5.1316\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.4087 - val_loss: 5.0727\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.3260 - val_loss: 5.0153\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.3122 - val_loss: 4.9590\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.0641 - val_loss: 4.9020\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.8833 - val_loss: 4.8438\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.7459 - val_loss: 4.7908\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.7844 - val_loss: 4.7418\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.6953 - val_loss: 4.6923\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.4774 - val_loss: 4.6433\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.6197 - val_loss: 4.5930\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.3082 - val_loss: 4.5439\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.3136 - val_loss: 4.5009\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2551 - val_loss: 4.4534\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0180 - val_loss: 4.4137\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0211 - val_loss: 4.3706\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.8288 - val_loss: 4.3264\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.7803 - val_loss: 4.2875\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.6379 - val_loss: 4.2483\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.6003 - val_loss: 4.2030\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.4933 - val_loss: 4.1641\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.5448 - val_loss: 4.1287\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.5148 - val_loss: 4.0937\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.2526 - val_loss: 4.0607\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.3005 - val_loss: 4.0272\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.1841 - val_loss: 3.9914\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.2419 - val_loss: 3.9570\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.0880 - val_loss: 3.9265\n",
      "Model: \"sequential_252\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1860 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1609 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1861 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1610 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1862 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1611 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1863 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1612 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1864 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1613 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1865 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1614 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1866 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1615 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1867 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1616 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1868 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 196s 2s/step - loss: 171.4276 - val_loss: 78.4591\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 151.2988 - val_loss: 69.3842\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 131.5051 - val_loss: 62.3148\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 117.8301 - val_loss: 56.6017\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 106.0710 - val_loss: 51.9977\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 96.9420 - val_loss: 48.2496\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 90.6930 - val_loss: 45.2185\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 83.6791 - val_loss: 42.6348\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 78.1853 - val_loss: 40.3669\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 74.3485 - val_loss: 38.3754\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 70.2026 - val_loss: 36.5978\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 67.6219 - val_loss: 35.0154\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 64.8989 - val_loss: 33.5047\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 61.7424 - val_loss: 32.1136\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 58.5200 - val_loss: 30.8381\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 55.7994 - val_loss: 29.5875\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 53.5883 - val_loss: 28.3574\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 50.8408 - val_loss: 27.1820\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 48.7325 - val_loss: 26.0287\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 45.7016 - val_loss: 24.8737\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 43.9817 - val_loss: 23.7467\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 41.5749 - val_loss: 22.6421\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 39.1179 - val_loss: 21.6076\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 37.7428 - val_loss: 20.6107\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 35.7497 - val_loss: 19.7072\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 33.6978 - val_loss: 18.8737\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 32.0667 - val_loss: 18.1201\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 31.0412 - val_loss: 17.4366\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 29.4682 - val_loss: 16.8043\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 28.6620 - val_loss: 16.2304\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 27.4413 - val_loss: 15.7106\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 26.4669 - val_loss: 15.2275\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 25.1963 - val_loss: 14.7574\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 25.0097 - val_loss: 14.3234\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.6833 - val_loss: 13.9183\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.1971 - val_loss: 13.5172\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.3030 - val_loss: 13.1533\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.7865 - val_loss: 12.8077\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.0350 - val_loss: 12.4796\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.4925 - val_loss: 12.1693\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.8451 - val_loss: 11.8827\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.6238 - val_loss: 11.5843\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.9401 - val_loss: 11.3117\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.1843 - val_loss: 11.0653\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.6901 - val_loss: 10.8274\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.3601 - val_loss: 10.5963\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.0465 - val_loss: 10.3806\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.5962 - val_loss: 10.1653\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.1738 - val_loss: 9.9639\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.8043 - val_loss: 9.7697\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.2306 - val_loss: 9.5918\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.2621 - val_loss: 9.4093\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.0082 - val_loss: 9.2436\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.5693 - val_loss: 9.0822\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.4474 - val_loss: 8.9233\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.1342 - val_loss: 8.7696\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.9093 - val_loss: 8.6240\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.4887 - val_loss: 8.4822\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.1492 - val_loss: 8.3470\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.0467 - val_loss: 8.2132\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.6601 - val_loss: 8.0899\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.5681 - val_loss: 7.9714\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.5189 - val_loss: 7.8552\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.2656 - val_loss: 7.7390\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.0823 - val_loss: 7.6307\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.7846 - val_loss: 7.5211\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.6474 - val_loss: 7.4187\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.5883 - val_loss: 7.3172\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.2207 - val_loss: 7.2136\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.1857 - val_loss: 7.1181\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.1342 - val_loss: 7.0225\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.8124 - val_loss: 6.9345\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.6561 - val_loss: 6.8450\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.5463 - val_loss: 6.7567\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.4098 - val_loss: 6.6734\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.1949 - val_loss: 6.5925\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.0032 - val_loss: 6.5157\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.1155 - val_loss: 6.4394\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.8325 - val_loss: 6.3616\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.7718 - val_loss: 6.2908\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.5075 - val_loss: 6.2199\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.6282 - val_loss: 6.1544\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.2122 - val_loss: 6.0868\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.1246 - val_loss: 6.0229\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.2412 - val_loss: 5.9631\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.2881 - val_loss: 5.9011\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.9856 - val_loss: 5.8410\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.7040 - val_loss: 5.7802\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.8000 - val_loss: 5.7244\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.5383 - val_loss: 5.6675\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.5689 - val_loss: 5.6158\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.5130 - val_loss: 5.5625\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.4735 - val_loss: 5.5110\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.3458 - val_loss: 5.4598\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2175 - val_loss: 5.4127\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.9144 - val_loss: 5.3664\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0229 - val_loss: 5.3183\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.9642 - val_loss: 5.2729\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.8410 - val_loss: 5.2269\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.8221 - val_loss: 5.1847\n",
      "['../Cli3/UTSW_Cli_224P_OrderFea_30_SMOTE_CV_it_2_10_4.mat', '../PrePost/PET_MOO/HN_MR_3_PPD_SMOTE_CV5_fea50_it_50_4.mat', '../PrePost/CT_MOO/HN_MR_3_PPD_SMOTE_CV5_fea50_val_it_50_4.mat']\n",
      "\n",
      "... Processing ../PrePost/PET_MOO/HN_MR_3_PPD_SMOTE_CV5_fea50_it_50_4 ...\n",
      "PET_feature shape is (179, 50)\n",
      "\n",
      "... Processing ../PrePost/CT_MOO/HN_MR_3_PPD_SMOTE_CV5_fea50_val_it_50_4 ...\n",
      "CT_feature shape is (179, 50)\n",
      "\n",
      "Feature shape is (179, 50)\n",
      "\n",
      "Label shape is (179, 1)\n",
      "\n",
      "Feature test shape is (45, 50)\n",
      "\n",
      "Label test shape is (45, 1)\n",
      "\n",
      "After SMOTE feature shape is (268, 50)\n",
      "Model: \"sequential_253\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1869 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1617 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1870 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1618 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1871 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1619 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1872 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1620 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1873 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1621 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1874 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1622 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1875 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1623 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1876 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1624 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1877 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 206s 2s/step - loss: 190.0251 - val_loss: 62.7902\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 160.7708 - val_loss: 55.6529\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 135.5789 - val_loss: 50.2166\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 119.1407 - val_loss: 45.9566\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 108.3022 - val_loss: 42.5095\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 98.6222 - val_loss: 39.6920\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 90.4322 - val_loss: 37.2952\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 84.2134 - val_loss: 35.2415\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 79.0595 - val_loss: 33.4445\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 73.7745 - val_loss: 31.8784\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 69.1954 - val_loss: 30.5121\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 65.6031 - val_loss: 29.2837\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 62.8411 - val_loss: 28.1841\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 59.7473 - val_loss: 27.1568\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 56.8959 - val_loss: 26.2091\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 54.9406 - val_loss: 25.2891\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 52.8089 - val_loss: 24.3982\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 50.6326 - val_loss: 23.5506\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 48.6599 - val_loss: 22.7106\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 46.3761 - val_loss: 21.8876\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 44.6662 - val_loss: 21.0717\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 42.6126 - val_loss: 20.2649\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 40.5371 - val_loss: 19.4662\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 38.9619 - val_loss: 18.6818\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 37.0095 - val_loss: 17.9019\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 35.4021 - val_loss: 17.1331\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 2ms/step - loss: 33.4890 - val_loss: 16.3874\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 32.2117 - val_loss: 15.6667\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 30.4650 - val_loss: 14.9804\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 28.7580 - val_loss: 14.3302\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 27.5364 - val_loss: 13.7245\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 26.4706 - val_loss: 13.1652\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 25.2950 - val_loss: 12.6681\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 24.1460 - val_loss: 12.2152\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.8994 - val_loss: 11.8018\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.2597 - val_loss: 11.4302\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.3205 - val_loss: 11.0952\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20.9849 - val_loss: 10.7856\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.4213 - val_loss: 10.5005\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 19.8190 - val_loss: 10.2327\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 19.2213 - val_loss: 9.9865\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.6300 - val_loss: 9.7518\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.1424 - val_loss: 9.5317\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.5536 - val_loss: 9.3233\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.1207 - val_loss: 9.1240\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.7066 - val_loss: 8.9378\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.2445 - val_loss: 8.7603\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.3008 - val_loss: 8.5869\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.6509 - val_loss: 8.4265\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.1857 - val_loss: 8.2719\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.0136 - val_loss: 8.1205\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.5806 - val_loss: 7.9769\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.2353 - val_loss: 7.8438\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.1390 - val_loss: 7.7129\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.9387 - val_loss: 7.5854\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.5364 - val_loss: 7.4656\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.5507 - val_loss: 7.3467\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.9000 - val_loss: 7.2333\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.0243 - val_loss: 7.1242\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.6149 - val_loss: 7.0191\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.3270 - val_loss: 6.9173\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.2944 - val_loss: 6.8195\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.8997 - val_loss: 6.7242\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.7830 - val_loss: 6.6341\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.5414 - val_loss: 6.5453\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.3870 - val_loss: 6.4591\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.4941 - val_loss: 6.3742\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.9673 - val_loss: 6.2954\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.0160 - val_loss: 6.2193\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.8211 - val_loss: 6.1415\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.6491 - val_loss: 6.0651\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.5293 - val_loss: 5.9937\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.3848 - val_loss: 5.9241\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.2118 - val_loss: 5.8568\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.0587 - val_loss: 5.7892\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.8503 - val_loss: 5.7240\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.7854 - val_loss: 5.6615\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.8402 - val_loss: 5.5999\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.5763 - val_loss: 5.5407\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.4908 - val_loss: 5.4827\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.4664 - val_loss: 5.4263\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.2650 - val_loss: 5.3731\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.2622 - val_loss: 5.3210\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.9523 - val_loss: 5.2705\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.2028 - val_loss: 5.2191\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.9429 - val_loss: 5.1687\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.7278 - val_loss: 5.1203\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.7363 - val_loss: 5.0740\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.5752 - val_loss: 5.0283\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.5150 - val_loss: 4.9823\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.4345 - val_loss: 4.9392\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2571 - val_loss: 4.8964\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.1399 - val_loss: 4.8539\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.2866 - val_loss: 4.8138\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.1931 - val_loss: 4.7738\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.9476 - val_loss: 4.7349\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0208 - val_loss: 4.6961\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.9379 - val_loss: 4.6595\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.9386 - val_loss: 4.6250\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.8786 - val_loss: 4.5895\n",
      "Model: \"sequential_254\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1878 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1625 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1879 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1626 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1880 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1627 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1881 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1628 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1882 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1629 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1883 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1630 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1884 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1631 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1885 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1632 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1886 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 207s 2s/step - loss: 201.7299 - val_loss: 49.8976\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 164.9866 - val_loss: 45.4956\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 144.3620 - val_loss: 42.0798\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 125.7508 - val_loss: 39.3471\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 117.5912 - val_loss: 37.0993\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 107.0633 - val_loss: 35.2423\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 97.4592 - val_loss: 33.6567\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 90.8897 - val_loss: 32.3017\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 83.8672 - val_loss: 31.0738\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 79.0971 - val_loss: 29.9582\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 74.1225 - val_loss: 28.9205\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 73.4922 - val_loss: 27.9312\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 69.0447 - val_loss: 26.9844\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 66.7017 - val_loss: 26.0628\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 63.5446 - val_loss: 25.1505\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 61.0141 - val_loss: 24.2274\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 57.5356 - val_loss: 23.2951\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 54.3357 - val_loss: 22.3489\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 52.7842 - val_loss: 21.4082\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 49.4007 - val_loss: 20.4511\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 47.9095 - val_loss: 19.5059\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 45.0003 - val_loss: 18.5769\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 43.0242 - val_loss: 17.6623\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 40.4061 - val_loss: 16.7890\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 38.7609 - val_loss: 15.9729\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 36.5680 - val_loss: 15.2202\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 35.0914 - val_loss: 14.5314\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 33.4776 - val_loss: 13.9201\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 31.6376 - val_loss: 13.3802\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 30.2390 - val_loss: 12.9041\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 29.2589 - val_loss: 12.4709\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 27.9603 - val_loss: 12.0773\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 27.1742 - val_loss: 11.7121\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 26.4170 - val_loss: 11.3734\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 25.0014 - val_loss: 11.0556\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 24.3167 - val_loss: 10.7596\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 23.1992 - val_loss: 10.4808\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.7252 - val_loss: 10.2099\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.6266 - val_loss: 9.9539\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.2261 - val_loss: 9.7095\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21.1120 - val_loss: 9.4805\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.1923 - val_loss: 9.2603\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 19.8394 - val_loss: 9.0550\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 19.3020 - val_loss: 8.8584\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.8334 - val_loss: 8.6691\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.4581 - val_loss: 8.4891\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.9054 - val_loss: 8.3205\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.5117 - val_loss: 8.1561\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.3645 - val_loss: 7.9975\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.5953 - val_loss: 7.8461\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.1560 - val_loss: 7.7038\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.8208 - val_loss: 7.5638\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.3890 - val_loss: 7.4289\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.1465 - val_loss: 7.3027\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.6131 - val_loss: 7.1785\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.7012 - val_loss: 7.0597\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.4230 - val_loss: 6.9450\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.0115 - val_loss: 6.8324\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.7409 - val_loss: 6.7243\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.3208 - val_loss: 6.6233\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.1986 - val_loss: 6.5229\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.9563 - val_loss: 6.4243\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.7126 - val_loss: 6.3300\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.5503 - val_loss: 6.2416\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.3406 - val_loss: 6.1539\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.1319 - val_loss: 6.0695\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.0435 - val_loss: 5.9879\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.8092 - val_loss: 5.9083\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.5217 - val_loss: 5.8299\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.2684 - val_loss: 5.7545\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.3320 - val_loss: 5.6823\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.9671 - val_loss: 5.6109\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.6858 - val_loss: 5.5426\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.6243 - val_loss: 5.4756\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.4492 - val_loss: 5.4102\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.2459 - val_loss: 5.3493\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.2313 - val_loss: 5.2878\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.0148 - val_loss: 5.2281\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.8425 - val_loss: 5.1697\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.8390 - val_loss: 5.1127\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.7123 - val_loss: 5.0588\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.6522 - val_loss: 5.0051\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - ETA: 0s - loss: 10.08 - 0s 3ms/step - loss: 9.5527 - val_loss: 4.9528\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.3165 - val_loss: 4.9010\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.3082 - val_loss: 4.8521\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.1231 - val_loss: 4.8031\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.9163 - val_loss: 4.7552\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.9457 - val_loss: 4.7096\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.8581 - val_loss: 4.6640\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.7139 - val_loss: 4.6190\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.7404 - val_loss: 4.5762\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.6571 - val_loss: 4.5343\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.5011 - val_loss: 4.4931\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.4743 - val_loss: 4.4515\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2509 - val_loss: 4.4121\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0949 - val_loss: 4.3729\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1840 - val_loss: 4.3356\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.8979 - val_loss: 4.2994\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0331 - val_loss: 4.2632\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.9185 - val_loss: 4.2287\n",
      "\n",
      "Feature shape is (179, 50)\n",
      "\n",
      "Feature test shape is (45, 50)\n",
      "\n",
      "After SMOTE feature shape is (268, 50)\n",
      "Model: \"sequential_255\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1887 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1633 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1888 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1634 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1889 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1635 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1890 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1636 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1891 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1637 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1892 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1638 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1893 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1639 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1894 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1640 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1895 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 219s 2s/step - loss: 167.9144 - val_loss: 61.4009\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 142.8998 - val_loss: 53.8165\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 119.6434 - val_loss: 48.2453\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 108.9036 - val_loss: 43.8999\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 96.6691 - val_loss: 40.4948\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 89.8673 - val_loss: 37.7971\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 82.8120 - val_loss: 35.5575\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 77.7141 - val_loss: 33.6604\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 73.2058 - val_loss: 32.0277\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 68.2560 - val_loss: 30.6193\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 65.2271 - val_loss: 29.3097\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 62.4967 - val_loss: 28.1307\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 59.6795 - val_loss: 27.0209\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 57.3764 - val_loss: 25.9854\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 54.8172 - val_loss: 24.9783\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 52.4034 - val_loss: 24.0158\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 50.2519 - val_loss: 23.0801\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 48.2046 - val_loss: 22.1524\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 46.1844 - val_loss: 21.2663\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 43.9333 - val_loss: 20.3846\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 41.7671 - val_loss: 19.5129\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 40.1248 - val_loss: 18.6455\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 38.3430 - val_loss: 17.8044\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 36.2274 - val_loss: 16.9765\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 34.1943 - val_loss: 16.1789\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 32.8890 - val_loss: 15.3993\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 30.9950 - val_loss: 14.6657\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 29.3961 - val_loss: 13.9693\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 28.3069 - val_loss: 13.3294\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 26.6037 - val_loss: 12.7407\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 3ms/step - loss: 25.4525 - val_loss: 12.2022\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 24.4568 - val_loss: 11.7272\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.0477 - val_loss: 11.2959\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22.2794 - val_loss: 10.9143\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.2576 - val_loss: 10.5723\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20.4094 - val_loss: 10.2675\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.1713 - val_loss: 9.9943\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.1996 - val_loss: 9.7461\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.7008 - val_loss: 9.5192\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.3774 - val_loss: 9.3075\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.9273 - val_loss: 9.1021\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.4700 - val_loss: 8.9146\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.9532 - val_loss: 8.7435\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.9759 - val_loss: 8.5800\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.3724 - val_loss: 8.4232\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.8404 - val_loss: 8.2677\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.4953 - val_loss: 8.1200\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.2421 - val_loss: 7.9783\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.8275 - val_loss: 7.8413\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.7008 - val_loss: 7.7128\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.2146 - val_loss: 7.5908\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.7217 - val_loss: 7.4713\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.7392 - val_loss: 7.3575\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.3327 - val_loss: 7.2445\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.1854 - val_loss: 7.1340\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.9543 - val_loss: 7.0333\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.5695 - val_loss: 6.9382\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.3749 - val_loss: 6.8419\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.2333 - val_loss: 6.7517\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.0262 - val_loss: 6.6637\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.0237 - val_loss: 6.5769\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.8232 - val_loss: 6.4930\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.6568 - val_loss: 6.4123\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.2614 - val_loss: 6.3307\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.1311 - val_loss: 6.2541\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.0793 - val_loss: 6.1780\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.8056 - val_loss: 6.1051\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.5684 - val_loss: 6.0352\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.5493 - val_loss: 5.9667\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.2752 - val_loss: 5.8999\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.3004 - val_loss: 5.8344\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.2381 - val_loss: 5.7693\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.8598 - val_loss: 5.7067\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.8275 - val_loss: 5.6442\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.6808 - val_loss: 5.5852\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.6629 - val_loss: 5.5284\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.2821 - val_loss: 5.4721\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.2448 - val_loss: 5.4169\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.0160 - val_loss: 5.3669\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.0778 - val_loss: 5.3150\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.9259 - val_loss: 5.2630\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.7005 - val_loss: 5.2139\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.8322 - val_loss: 5.1649\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.6993 - val_loss: 5.1151\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.5880 - val_loss: 5.0663\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.4137 - val_loss: 5.0205\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.3997 - val_loss: 4.9771\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.3227 - val_loss: 4.9316\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.9989 - val_loss: 4.8910\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0022 - val_loss: 4.8504\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.8697 - val_loss: 4.8120\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.8674 - val_loss: 4.7722\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.7516 - val_loss: 4.7338\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.8247 - val_loss: 4.6946\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.8221 - val_loss: 4.6566\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.6558 - val_loss: 4.6220\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.6261 - val_loss: 4.5841\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.4380 - val_loss: 4.5491\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.4869 - val_loss: 4.5141\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.3814 - val_loss: 4.4802\n",
      "Model: \"sequential_256\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1896 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1641 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1897 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1642 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1898 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1643 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1899 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1644 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1900 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1645 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1901 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1646 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1902 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1647 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1903 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1648 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1904 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 208s 2s/step - loss: 177.6145 - val_loss: 73.8525\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 154.3036 - val_loss: 66.5304\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 133.3841 - val_loss: 60.8752\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 117.6690 - val_loss: 56.5824\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 107.3719 - val_loss: 52.9942\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 99.0087 - val_loss: 50.0150\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 94.0161 - val_loss: 47.5563\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 87.6174 - val_loss: 45.3341\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 83.2247 - val_loss: 43.4485\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 78.9990 - val_loss: 41.7710\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 75.3851 - val_loss: 40.1906\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 71.4855 - val_loss: 38.7632\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 67.8456 - val_loss: 37.4066\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 65.3980 - val_loss: 36.0839\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 61.7810 - val_loss: 34.8176\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 59.3264 - val_loss: 33.5626\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 56.6340 - val_loss: 32.2888\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 53.9575 - val_loss: 31.0283\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 51.3697 - val_loss: 29.7883\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 48.4184 - val_loss: 28.6014\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 46.3356 - val_loss: 27.4103\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 43.8637 - val_loss: 26.2693\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 41.4293 - val_loss: 25.1551\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 39.5710 - val_loss: 24.1573\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 37.9514 - val_loss: 23.2469\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 36.3108 - val_loss: 22.4124\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 34.4747 - val_loss: 21.6289\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 32.5221 - val_loss: 20.9207\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 31.2983 - val_loss: 20.2595\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 29.7987 - val_loss: 19.6446\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 29.2403 - val_loss: 19.0707\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 27.8274 - val_loss: 18.5216\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 26.7530 - val_loss: 17.9905\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 25.7036 - val_loss: 17.5139\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 25.1874 - val_loss: 17.0497\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 24.2229 - val_loss: 16.6053\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 23.5653 - val_loss: 16.1967\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.8287 - val_loss: 15.7940\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.9075 - val_loss: 15.4158\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.4366 - val_loss: 15.0473\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.0895 - val_loss: 14.7064\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.5085 - val_loss: 14.3714\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.6331 - val_loss: 14.0530\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.1403 - val_loss: 13.7648\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.5943 - val_loss: 13.4809\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.3109 - val_loss: 13.2003\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17.9106 - val_loss: 12.9399\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.1944 - val_loss: 12.6855\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.8155 - val_loss: 12.4225\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.4755 - val_loss: 12.1805\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.0408 - val_loss: 11.9319\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.6742 - val_loss: 11.7068\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.1869 - val_loss: 11.4997\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.9315 - val_loss: 11.2895\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.7279 - val_loss: 11.0787\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.1834 - val_loss: 10.8855\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.1147 - val_loss: 10.7035\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.6152 - val_loss: 10.5158\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.5718 - val_loss: 10.3412\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.0589 - val_loss: 10.1780\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.0495 - val_loss: 10.0056\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.8173 - val_loss: 9.8377\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.6652 - val_loss: 9.6878\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.3156 - val_loss: 9.5372\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.1221 - val_loss: 9.4010\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.9109 - val_loss: 9.2659\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.6192 - val_loss: 9.1372\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.4059 - val_loss: 9.0085\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.2617 - val_loss: 8.8784\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.0110 - val_loss: 8.7653\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.8401 - val_loss: 8.6493\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.6820 - val_loss: 8.5301\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.6026 - val_loss: 8.4170\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.3905 - val_loss: 8.3059\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.1692 - val_loss: 8.2035\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10.1874 - val_loss: 8.1034\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.9043 - val_loss: 8.0040\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.9423 - val_loss: 7.9067\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.5789 - val_loss: 7.8182\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.5500 - val_loss: 7.7238\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.4296 - val_loss: 7.6328\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.3549 - val_loss: 7.5431\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.2098 - val_loss: 7.4609\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.0565 - val_loss: 7.3748\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.7696 - val_loss: 7.2923\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.7898 - val_loss: 7.2098\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.7349 - val_loss: 7.1349\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.5860 - val_loss: 7.0653\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.4469 - val_loss: 6.9914\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.4706 - val_loss: 6.9181\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.3082 - val_loss: 6.8519\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2921 - val_loss: 6.7849\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1858 - val_loss: 6.7217\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0915 - val_loss: 6.6549\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.8894 - val_loss: 6.5946\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0748 - val_loss: 6.5298\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.9636 - val_loss: 6.4699\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.6852 - val_loss: 6.4107\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.6057 - val_loss: 6.3558\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.5701 - val_loss: 6.2997\n",
      "['../Cli3/UTSW_Cli_224P_OrderFea_30_SMOTE_CV_it_2_10_5.mat', '../PrePost/PET_MOO/HN_MR_3_PPD_SMOTE_CV5_fea50_it_50_5.mat', '../PrePost/CT_MOO/HN_MR_3_PPD_SMOTE_CV5_fea50_val_it_50_5.mat']\n",
      "\n",
      "... Processing ../PrePost/PET_MOO/HN_MR_3_PPD_SMOTE_CV5_fea50_it_50_5 ...\n",
      "PET_feature shape is (180, 50)\n",
      "\n",
      "... Processing ../PrePost/CT_MOO/HN_MR_3_PPD_SMOTE_CV5_fea50_val_it_50_5 ...\n",
      "CT_feature shape is (180, 50)\n",
      "\n",
      "Feature shape is (180, 50)\n",
      "\n",
      "Label shape is (180, 1)\n",
      "\n",
      "Feature test shape is (44, 50)\n",
      "\n",
      "Label test shape is (44, 1)\n",
      "\n",
      "After SMOTE feature shape is (268, 50)\n",
      "Model: \"sequential_257\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1905 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1649 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1906 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1650 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1907 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1651 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1908 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1652 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1909 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1653 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1910 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1654 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1911 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1655 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1912 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1656 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1913 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 219s 2s/step - loss: 215.3991 - val_loss: 84.7858\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 169.2773 - val_loss: 71.0941\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 145.4857 - val_loss: 61.8340\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 125.3894 - val_loss: 55.0189\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 108.3236 - val_loss: 49.8336\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 99.3988 - val_loss: 45.5993\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 90.0922 - val_loss: 42.1314\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 85.2590 - val_loss: 39.2336\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 80.2238 - val_loss: 36.7785\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 74.9823 - val_loss: 34.7820\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 70.8872 - val_loss: 33.0571\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 67.3722 - val_loss: 31.5016\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 64.7137 - val_loss: 30.1194\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 60.6302 - val_loss: 28.8947\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 57.7508 - val_loss: 27.7936\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 56.9521 - val_loss: 26.7318\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 54.7626 - val_loss: 25.7537\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 52.5486 - val_loss: 24.8235\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 50.5400 - val_loss: 23.9527\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 48.2366 - val_loss: 23.1186\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 46.8065 - val_loss: 22.3119\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 44.9645 - val_loss: 21.5082\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 43.6350 - val_loss: 20.7241\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 41.9077 - val_loss: 19.9453\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 39.7030 - val_loss: 19.1952\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 38.4982 - val_loss: 18.4522\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 3ms/step - loss: 36.8339 - val_loss: 17.7085\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 35.3664 - val_loss: 16.9757\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 33.1420 - val_loss: 16.2613\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 31.9793 - val_loss: 15.5501\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 29.8782 - val_loss: 14.8576\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 28.8601 - val_loss: 14.1898\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 27.3918 - val_loss: 13.5533\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 26.6145 - val_loss: 12.9443\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 25.1087 - val_loss: 12.3779\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 24.2493 - val_loss: 11.8510\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.8607 - val_loss: 11.3686\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.9172 - val_loss: 10.9289\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.9445 - val_loss: 10.5314\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.1807 - val_loss: 10.1771\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.4306 - val_loss: 9.8560\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.7343 - val_loss: 9.5686\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.2016 - val_loss: 9.3148\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.7560 - val_loss: 9.0837\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.3142 - val_loss: 8.8724\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.7566 - val_loss: 8.6758\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.4298 - val_loss: 8.4948\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.9849 - val_loss: 8.3255\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.2723 - val_loss: 8.1658\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.3516 - val_loss: 8.0131\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.6973 - val_loss: 7.8667\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.4678 - val_loss: 7.7326\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.3387 - val_loss: 7.6049\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.9860 - val_loss: 7.4800\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.6763 - val_loss: 7.3614\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13.4647 - val_loss: 7.2469\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.0670 - val_loss: 7.1387\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.9775 - val_loss: 7.0345\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.6797 - val_loss: 6.9317\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.5156 - val_loss: 6.8345\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.3731 - val_loss: 6.7423\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.9249 - val_loss: 6.6521\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.9741 - val_loss: 6.5687\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.9299 - val_loss: 6.4857\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.4739 - val_loss: 6.4051\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.2252 - val_loss: 6.3274\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.3203 - val_loss: 6.2537\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.0724 - val_loss: 6.1812\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.9783 - val_loss: 6.1119\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.7656 - val_loss: 6.0433\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.5162 - val_loss: 5.9774\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.3636 - val_loss: 5.9150\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.3232 - val_loss: 5.8538\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.1812 - val_loss: 5.7944\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.9828 - val_loss: 5.7371\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.0059 - val_loss: 5.6819\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.7973 - val_loss: 5.6262\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.6810 - val_loss: 5.5722\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.4869 - val_loss: 5.5209\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.6122 - val_loss: 5.4706\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.3180 - val_loss: 5.4200\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.2615 - val_loss: 5.3735\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.0625 - val_loss: 5.3265\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.9441 - val_loss: 5.2804\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.9563 - val_loss: 5.2357\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.8320 - val_loss: 5.1940\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.7800 - val_loss: 5.1502\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.7194 - val_loss: 5.1090\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.5195 - val_loss: 5.0691\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.5800 - val_loss: 5.0306\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.4400 - val_loss: 4.9910\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2684 - val_loss: 4.9551\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1909 - val_loss: 4.9196\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0436 - val_loss: 4.8833\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0052 - val_loss: 4.8481\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8.1085 - val_loss: 4.8128\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.9859 - val_loss: 4.7781\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.8393 - val_loss: 4.7448\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.8625 - val_loss: 4.7134\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.8322 - val_loss: 4.6817\n",
      "Model: \"sequential_258\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1914 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1657 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1915 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1658 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1916 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1659 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1917 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1660 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1918 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1661 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1919 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1662 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1920 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1663 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1921 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1664 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1922 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 214s 2s/step - loss: 210.3757 - val_loss: 94.3837\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 170.8772 - val_loss: 84.4003\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 144.4931 - val_loss: 77.0689\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 126.1594 - val_loss: 71.3032\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 115.1217 - val_loss: 66.7944\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 105.6175 - val_loss: 63.2117\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 95.4209 - val_loss: 60.3675\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 89.4170 - val_loss: 57.9919\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 83.8125 - val_loss: 56.0417\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 78.0153 - val_loss: 54.3187\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 73.7254 - val_loss: 52.7693\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - ETA: 0s - loss: 73.70 - 0s 3ms/step - loss: 70.2500 - val_loss: 51.4301\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 66.4065 - val_loss: 50.2290\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 64.0107 - val_loss: 49.0652\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 61.1705 - val_loss: 48.0361\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 58.2699 - val_loss: 47.1229\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 56.5966 - val_loss: 46.1216\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 53.7102 - val_loss: 45.2219\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - ETA: 0s - loss: 55.63 - 0s 3ms/step - loss: 52.0074 - val_loss: 44.3316\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 49.6781 - val_loss: 43.4941\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 47.6410 - val_loss: 42.6431\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 45.6536 - val_loss: 41.7810\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 43.3967 - val_loss: 40.9381\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 41.8292 - val_loss: 40.1010\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 39.9041 - val_loss: 39.2541\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 38.0202 - val_loss: 38.4741\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 36.4221 - val_loss: 37.7244\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 34.8107 - val_loss: 36.9955\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 32.6676 - val_loss: 36.2647\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 31.6751 - val_loss: 35.5690\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 30.0329 - val_loss: 34.8822\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 28.7517 - val_loss: 34.2830\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 27.2968 - val_loss: 33.6707\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 25.9519 - val_loss: 33.0908\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 25.3359 - val_loss: 32.5585\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 24.1700 - val_loss: 32.0457\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.9648 - val_loss: 31.6125\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.3845 - val_loss: 31.2285\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.4220 - val_loss: 30.8561\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.6600 - val_loss: 30.5326\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.1220 - val_loss: 30.2243\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.2420 - val_loss: 29.9258\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.9868 - val_loss: 29.6972\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.5098 - val_loss: 29.4245\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.0534 - val_loss: 29.2113\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.9128 - val_loss: 28.9703\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.1804 - val_loss: 28.7874\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.7081 - val_loss: 28.5962\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.2995 - val_loss: 28.3644\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.7959 - val_loss: 28.1637\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.5908 - val_loss: 28.0189\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.2699 - val_loss: 27.8309\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.7840 - val_loss: 27.6406\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.6307 - val_loss: 27.5060\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.2036 - val_loss: 27.3549\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.0438 - val_loss: 27.1605\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.6716 - val_loss: 27.0394\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.5900 - val_loss: 26.8785\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.3311 - val_loss: 26.7457\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.8137 - val_loss: 26.6012\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.6798 - val_loss: 26.4700\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.5537 - val_loss: 26.3406\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.1403 - val_loss: 26.2568\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.9098 - val_loss: 26.1262\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.7815 - val_loss: 26.0191\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.5911 - val_loss: 25.9115\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.7122 - val_loss: 25.7935\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.3308 - val_loss: 25.6813\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.9783 - val_loss: 25.5433\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.8587 - val_loss: 25.4381\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.8176 - val_loss: 25.3383\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.6071 - val_loss: 25.2228\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.5689 - val_loss: 25.1486\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.4215 - val_loss: 25.0467\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.1731 - val_loss: 24.9744\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.1688 - val_loss: 24.8602\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.9040 - val_loss: 24.7935\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.8388 - val_loss: 24.7356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.7578 - val_loss: 24.6685\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.6073 - val_loss: 24.5935\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.3280 - val_loss: 24.5050\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.2803 - val_loss: 24.4104\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.2488 - val_loss: 24.3141\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.1540 - val_loss: 24.2531\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.9074 - val_loss: 24.2040\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.0488 - val_loss: 24.1244\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.7726 - val_loss: 24.0617\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.6569 - val_loss: 23.9946\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.6561 - val_loss: 23.9171\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.4322 - val_loss: 23.8571\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.3800 - val_loss: 23.7901\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2558 - val_loss: 23.7258\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2537 - val_loss: 23.6888\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1847 - val_loss: 23.6169\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2880 - val_loss: 23.5527\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.9856 - val_loss: 23.5163\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.9498 - val_loss: 23.4593\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - ETA: 0s - loss: 8.310 - 0s 3ms/step - loss: 7.9099 - val_loss: 23.3989\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.7804 - val_loss: 23.3618\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.7912 - val_loss: 23.3124\n",
      "\n",
      "Feature shape is (180, 50)\n",
      "\n",
      "Feature test shape is (44, 50)\n",
      "\n",
      "After SMOTE feature shape is (268, 50)\n",
      "Model: \"sequential_259\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1923 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1665 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1924 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1666 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1925 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1667 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1926 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1668 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1927 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1669 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1928 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1670 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1929 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1671 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1930 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1672 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1931 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 213s 2s/step - loss: 162.0013 - val_loss: 54.1213\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 133.3321 - val_loss: 46.5375\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 113.1647 - val_loss: 41.3133\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 99.8786 - val_loss: 37.5023\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 88.4360 - val_loss: 34.7136\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 80.6909 - val_loss: 32.5909\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 75.5318 - val_loss: 30.8934\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 70.1951 - val_loss: 29.4940\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 66.0174 - val_loss: 28.3155\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 63.2081 - val_loss: 27.2847\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 60.1580 - val_loss: 26.3529\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 57.0857 - val_loss: 25.4981\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 55.0123 - val_loss: 24.6968\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 52.4697 - val_loss: 23.9241\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 50.4048 - val_loss: 23.1975\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 48.2356 - val_loss: 22.4841\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 46.5550 - val_loss: 21.7795\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 45.0344 - val_loss: 21.0745\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 43.2065 - val_loss: 20.3771\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 41.3182 - val_loss: 19.6828\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 39.8119 - val_loss: 18.9898\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 37.6761 - val_loss: 18.2919\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 36.5653 - val_loss: 17.5975\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 34.7974 - val_loss: 16.8950\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 33.3355 - val_loss: 16.1938\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 31.8171 - val_loss: 15.5036\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 30.2058 - val_loss: 14.8255\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 28.8661 - val_loss: 14.1675\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 27.4013 - val_loss: 13.5376\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 25.9049 - val_loss: 12.9430\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 24.5637 - val_loss: 12.3899\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.4992 - val_loss: 11.8803\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.1371 - val_loss: 11.4165\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.2380 - val_loss: 10.9931\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.5906 - val_loss: 10.6163\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.1310 - val_loss: 10.2873\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.9653 - val_loss: 9.9988\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.5444 - val_loss: 9.7418\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.2011 - val_loss: 9.5034\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.5580 - val_loss: 9.2810\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.1853 - val_loss: 9.0750\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.4726 - val_loss: 8.8856\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.2694 - val_loss: 8.7033\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.7340 - val_loss: 8.5348\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.6202 - val_loss: 8.3682\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.4239 - val_loss: 8.2100\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.9140 - val_loss: 8.0471\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14.2904 - val_loss: 7.8942\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.0976 - val_loss: 7.7530\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.9893 - val_loss: 7.6212\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.5325 - val_loss: 7.4928\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.1908 - val_loss: 7.3647\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.0359 - val_loss: 7.2424\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.6956 - val_loss: 7.1225\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.2815 - val_loss: 7.0122\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.2123 - val_loss: 6.9043\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.8356 - val_loss: 6.8010\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.9977 - val_loss: 6.6986\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.4736 - val_loss: 6.6040\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.3761 - val_loss: 6.5097\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.3301 - val_loss: 6.4192\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.9878 - val_loss: 6.3327\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.7219 - val_loss: 6.2493\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.6852 - val_loss: 6.1685\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.6249 - val_loss: 6.0899\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - ETA: 0s - loss: 10.77 - 0s 3ms/step - loss: 10.3165 - val_loss: 6.0173\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.1201 - val_loss: 5.9471\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.1165 - val_loss: 5.8767\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.0540 - val_loss: 5.8087\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.7530 - val_loss: 5.7424\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.6397 - val_loss: 5.6781\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.4370 - val_loss: 5.6159\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.2619 - val_loss: 5.5557\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.1988 - val_loss: 5.4948\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.2383 - val_loss: 5.4406\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.0150 - val_loss: 5.3884\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.8470 - val_loss: 5.3357\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.8614 - val_loss: 5.2812\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.7337 - val_loss: 5.2306\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.7962 - val_loss: 5.1834\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.5022 - val_loss: 5.1360\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.3856 - val_loss: 5.0889\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.3907 - val_loss: 5.0423\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1943 - val_loss: 4.9989\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1088 - val_loss: 4.9559\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1169 - val_loss: 4.9124\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2640 - val_loss: 4.8693\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0568 - val_loss: 4.8280\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.7995 - val_loss: 4.7900\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.7671 - val_loss: 4.7530\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.6637 - val_loss: 4.7149\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.6229 - val_loss: 4.6781\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.7064 - val_loss: 4.6443\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.6109 - val_loss: 4.6103\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.5103 - val_loss: 4.5748\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.3993 - val_loss: 4.5401\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.3435 - val_loss: 4.5094\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.3224 - val_loss: 4.4765\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.0330 - val_loss: 4.4448\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.0227 - val_loss: 4.4132\n",
      "Model: \"sequential_260\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1932 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1673 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1933 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1674 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1934 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1675 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1935 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1676 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1936 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1677 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1937 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1678 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1938 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1679 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1939 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1680 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1940 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 229s 2s/step - loss: 208.8879 - val_loss: 72.2561\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 171.9505 - val_loss: 63.9621\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 145.0053 - val_loss: 58.0820\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 126.9152 - val_loss: 53.5782\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 117.8731 - val_loss: 49.9216\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 109.3760 - val_loss: 46.8223\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 101.0668 - val_loss: 44.1506\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 93.9782 - val_loss: 41.8356\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 89.5010 - val_loss: 39.7589\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 84.2157 - val_loss: 37.9596\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 79.8295 - val_loss: 36.3399\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 75.9746 - val_loss: 34.8647\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 72.9479 - val_loss: 33.4988\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 69.1599 - val_loss: 32.2579\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 66.9471 - val_loss: 31.0671\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 64.8496 - val_loss: 29.9091\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 61.2169 - val_loss: 28.8396\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 59.3550 - val_loss: 27.8024\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 57.3750 - val_loss: 26.7900\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 54.9003 - val_loss: 25.8216\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 52.8298 - val_loss: 24.8692\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 50.5282 - val_loss: 23.9411\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 48.6154 - val_loss: 23.0246\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 46.3878 - val_loss: 22.1270\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 44.0101 - val_loss: 21.2543\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 42.8184 - val_loss: 20.3960\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 40.7219 - val_loss: 19.5680\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 38.9215 - val_loss: 18.7705\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 36.3838 - val_loss: 18.0124\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 35.7267 - val_loss: 17.2849\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 33.7201 - val_loss: 16.6014\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 32.2622 - val_loss: 15.9617\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 31.3047 - val_loss: 15.3773\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 29.5341 - val_loss: 14.8375\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 28.2681 - val_loss: 14.3483\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 27.4786 - val_loss: 13.9000\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 25.9945 - val_loss: 13.4887\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 25.3997 - val_loss: 13.1135\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 24.9008 - val_loss: 12.7699\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.8501 - val_loss: 12.4473\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.1165 - val_loss: 12.1375\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.6820 - val_loss: 11.8614\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.8205 - val_loss: 11.5879\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.2129 - val_loss: 11.3247\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.8217 - val_loss: 11.0808\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.0827 - val_loss: 10.8475\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.6808 - val_loss: 10.6217\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.2313 - val_loss: 10.4066\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.6788 - val_loss: 10.1952\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.3384 - val_loss: 9.9949\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.7891 - val_loss: 9.8098\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.4741 - val_loss: 9.6261\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.1263 - val_loss: 9.4541\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.9884 - val_loss: 9.2854\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.2707 - val_loss: 9.1238\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.8866 - val_loss: 8.9668\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.4392 - val_loss: 8.8180\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.3427 - val_loss: 8.6706\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.8854 - val_loss: 8.5269\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.7667 - val_loss: 8.3911\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.2951 - val_loss: 8.2590\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.2183 - val_loss: 8.1323\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.9065 - val_loss: 8.0107\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.5731 - val_loss: 7.8923\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.4803 - val_loss: 7.7759\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.1122 - val_loss: 7.6625\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.8053 - val_loss: 7.5537\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.6137 - val_loss: 7.4507\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.5340 - val_loss: 7.3474\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.2375 - val_loss: 7.2519\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.1044 - val_loss: 7.1564\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.9886 - val_loss: 7.0623\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.7465 - val_loss: 6.9716\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.4711 - val_loss: 6.8850\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.4384 - val_loss: 6.7978\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.0977 - val_loss: 6.7162\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.9814 - val_loss: 6.6368\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.8354 - val_loss: 6.5615\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.6480 - val_loss: 6.4847\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.6047 - val_loss: 6.4112\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.3764 - val_loss: 6.3393\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.3228 - val_loss: 6.2684\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.1302 - val_loss: 6.1976\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.0924 - val_loss: 6.1304\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.9283 - val_loss: 6.0640\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.8150 - val_loss: 5.9993\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.5885 - val_loss: 5.9384\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.5826 - val_loss: 5.8783\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.5316 - val_loss: 5.8203\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.3357 - val_loss: 5.7628\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.1077 - val_loss: 5.7087\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.0395 - val_loss: 5.6551\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.9291 - val_loss: 5.6024\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.8368 - val_loss: 5.5484\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.6153 - val_loss: 5.4949\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.7790 - val_loss: 5.4464\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.7672 - val_loss: 5.3977\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.3248 - val_loss: 5.3497\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.3966 - val_loss: 5.3018\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2486 - val_loss: 5.2575\n",
      "['../Cli3/UTSW_Cli_224P_OrderFea_40_SMOTE_CV_it_2_10_1.mat', '../PrePost/PET_MOO/HN_MR_4_PPD_SMOTE_CV5_fea50_it_50_1.mat', '../PrePost/CT_MOO/HN_MR_4_PPD_SMOTE_CV5_fea50_val_it_50_1.mat']\n",
      "\n",
      "... Processing ../PrePost/PET_MOO/HN_MR_4_PPD_SMOTE_CV5_fea50_it_50_1 ...\n",
      "PET_feature shape is (178, 50)\n",
      "\n",
      "... Processing ../PrePost/CT_MOO/HN_MR_4_PPD_SMOTE_CV5_fea50_val_it_50_1 ...\n",
      "CT_feature shape is (178, 50)\n",
      "\n",
      "Feature shape is (178, 50)\n",
      "\n",
      "Label shape is (178, 1)\n",
      "\n",
      "Feature test shape is (46, 50)\n",
      "\n",
      "Label test shape is (46, 1)\n",
      "\n",
      "After SMOTE feature shape is (266, 50)\n",
      "Model: \"sequential_261\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1941 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1681 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1942 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1682 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1943 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1683 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1944 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1684 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1945 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1685 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1946 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1686 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1947 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1687 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1948 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1688 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1949 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 236s 2s/step - loss: 188.7220 - val_loss: 53.7398\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 152.4572 - val_loss: 47.7972\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 128.6779 - val_loss: 43.3967\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 111.0771 - val_loss: 39.9935\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 98.7040 - val_loss: 37.3034\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 89.4046 - val_loss: 35.0963\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 82.0861 - val_loss: 33.3176\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 75.1281 - val_loss: 31.7980\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 69.3415 - val_loss: 30.4862\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 64.5115 - val_loss: 29.3395\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 61.6136 - val_loss: 28.3373\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 57.9563 - val_loss: 27.4352\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 55.6443 - val_loss: 26.5974\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 52.8469 - val_loss: 25.8265\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 51.0534 - val_loss: 25.0663\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 48.4590 - val_loss: 24.3220\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 46.7882 - val_loss: 23.6010\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 45.0761 - val_loss: 22.8850\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 43.5958 - val_loss: 22.1690\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 41.6589 - val_loss: 21.4562\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 39.9114 - val_loss: 20.7349\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 38.0885 - val_loss: 20.0080\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 36.4494 - val_loss: 19.2753\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 34.9490 - val_loss: 18.5507\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 33.3262 - val_loss: 17.8290\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 31.2945 - val_loss: 17.1199\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 3ms/step - loss: 30.1388 - val_loss: 16.4154\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 28.6885 - val_loss: 15.7355\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 27.2017 - val_loss: 15.0875\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 25.7130 - val_loss: 14.4681\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 24.7377 - val_loss: 13.8832\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 23.5541 - val_loss: 13.3420\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 22.4471 - val_loss: 12.8521\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 21.1466 - val_loss: 12.4053\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 20.4875 - val_loss: 12.0040\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 19.8685 - val_loss: 11.6444\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 18.9335 - val_loss: 11.3136\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 18.4919 - val_loss: 11.0168\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 17.9132 - val_loss: 10.7469\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 17.3884 - val_loss: 10.5045\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.8793 - val_loss: 10.2864\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.2785 - val_loss: 10.0775\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.6688 - val_loss: 9.8848\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.6114 - val_loss: 9.7058\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.2438 - val_loss: 9.5413\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.0094 - val_loss: 9.3775\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.5157 - val_loss: 9.2177\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.1452 - val_loss: 9.0628\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.9899 - val_loss: 8.9188\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.6577 - val_loss: 8.7817\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.1910 - val_loss: 8.6489\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.1223 - val_loss: 8.5221\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.0051 - val_loss: 8.3943\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.7618 - val_loss: 8.2731\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.1147 - val_loss: 8.1584\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.2171 - val_loss: 8.0468\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.9352 - val_loss: 7.9399\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.6623 - val_loss: 7.8370\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.5997 - val_loss: 7.7370\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.3783 - val_loss: 7.6363\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.3421 - val_loss: 7.5368\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.0310 - val_loss: 7.4408\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.9041 - val_loss: 7.3514\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.5970 - val_loss: 7.2606\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.5572 - val_loss: 7.1758\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.3570 - val_loss: 7.0925\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - ETA: 0s - loss: 10.76 - 0s 3ms/step - loss: 10.1920 - val_loss: 7.0096\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.0605 - val_loss: 6.9285\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.0159 - val_loss: 6.8516\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.8866 - val_loss: 6.7793\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.7701 - val_loss: 6.7085\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.5822 - val_loss: 6.6361\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.4623 - val_loss: 6.5659\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.2631 - val_loss: 6.5003\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.1757 - val_loss: 6.4350\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.0267 - val_loss: 6.3706\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.0479 - val_loss: 6.3073\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.6872 - val_loss: 6.2466\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.7546 - val_loss: 6.1876\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.6655 - val_loss: 6.1307\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.7622 - val_loss: 6.0760\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.2914 - val_loss: 6.0209\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.4011 - val_loss: 5.9675\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.3822 - val_loss: 5.9145\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.2066 - val_loss: 5.8621\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.1874 - val_loss: 5.8127\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.9882 - val_loss: 5.7636\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.9225 - val_loss: 5.7159\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.8832 - val_loss: 5.6694\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.8046 - val_loss: 5.6228\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.8321 - val_loss: 5.5767\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.6866 - val_loss: 5.5333\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.4750 - val_loss: 5.4912\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.5485 - val_loss: 5.4480\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.3490 - val_loss: 5.4079\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.3401 - val_loss: 5.3696\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.3443 - val_loss: 5.3308\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.3760 - val_loss: 5.2901\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.0979 - val_loss: 5.2531\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.1630 - val_loss: 5.2178\n",
      "Model: \"sequential_262\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1950 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1689 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1951 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1690 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1952 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1691 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1953 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1692 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1954 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1693 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1955 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1694 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1956 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1695 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1957 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1696 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1958 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 237s 2s/step - loss: 202.5124 - val_loss: 40.7259\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 161.5704 - val_loss: 36.9380\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 142.1560 - val_loss: 34.0524\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 129.1831 - val_loss: 31.7937\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 115.7783 - val_loss: 30.0017\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 107.4173 - val_loss: 28.5091\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 98.3072 - val_loss: 27.2693\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 91.9275 - val_loss: 26.1865\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 85.6694 - val_loss: 25.2272\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 80.6900 - val_loss: 24.3659\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 76.8638 - val_loss: 23.5778\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 70.8594 - val_loss: 22.8364\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 68.9602 - val_loss: 22.1270\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 66.9330 - val_loss: 21.4625\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 63.6667 - val_loss: 20.8136\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 60.4900 - val_loss: 20.1536\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 58.0949 - val_loss: 19.5071\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 55.9062 - val_loss: 18.8398\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 53.1994 - val_loss: 18.1616\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 49.7627 - val_loss: 17.4565\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 48.9409 - val_loss: 16.7522\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 46.5890 - val_loss: 16.0399\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 44.4393 - val_loss: 15.3220\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 42.1794 - val_loss: 14.5897\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 40.6265 - val_loss: 13.8700\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 38.7735 - val_loss: 13.1638\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 36.1896 - val_loss: 12.4786\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 34.8820 - val_loss: 11.8511\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 32.8437 - val_loss: 11.2765\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 30.9414 - val_loss: 10.7651\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 30.2990 - val_loss: 10.3174\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 28.8604 - val_loss: 9.9131\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 27.8577 - val_loss: 9.5557\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 26.8063 - val_loss: 9.2281\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 25.1505 - val_loss: 8.9175\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 25.1121 - val_loss: 8.6331\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 23.8509 - val_loss: 8.3718\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 23.2353 - val_loss: 8.1276\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 22.2369 - val_loss: 7.8988\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 21.5628 - val_loss: 7.6811\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 21.0170 - val_loss: 7.4835\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 20.4729 - val_loss: 7.2973\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 19.7378 - val_loss: 7.1252\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 19.1865 - val_loss: 6.9547\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 18.9730 - val_loss: 6.7982\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 18.2554 - val_loss: 6.6475\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 17.5672 - val_loss: 6.5065\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 17.1469 - val_loss: 6.3723\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.9373 - val_loss: 6.2450\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.3665 - val_loss: 6.1220\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.1985 - val_loss: 6.0095\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.8418 - val_loss: 5.8952\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.2365 - val_loss: 5.7897\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.0595 - val_loss: 5.6891\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.6513 - val_loss: 5.5891\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.3603 - val_loss: 5.4972\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.3413 - val_loss: 5.4089\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.9549 - val_loss: 5.3212\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.5624 - val_loss: 5.2368\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.4439 - val_loss: 5.1594\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.8764 - val_loss: 5.0829\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.7193 - val_loss: 5.0078\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.6929 - val_loss: 4.9372\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.2742 - val_loss: 4.8666\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.2253 - val_loss: 4.8024\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.1039 - val_loss: 4.7383\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.8990 - val_loss: 4.6776\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.5649 - val_loss: 4.6195\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.3546 - val_loss: 4.5623\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.2623 - val_loss: 4.5060\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.0713 - val_loss: 4.4513\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.7455 - val_loss: 4.3976\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.5306 - val_loss: 4.3456\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.6761 - val_loss: 4.2942\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.5000 - val_loss: 4.2446\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.2318 - val_loss: 4.1974\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.0406 - val_loss: 4.1502\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.9990 - val_loss: 4.1041\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.6868 - val_loss: 4.0603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.7495 - val_loss: 4.0178\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.5667 - val_loss: 3.9753\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.5097 - val_loss: 3.9348\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.4398 - val_loss: 3.8949\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.3785 - val_loss: 3.8552\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.1665 - val_loss: 3.8166\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.0755 - val_loss: 3.7799\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.0272 - val_loss: 3.7439\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.7377 - val_loss: 3.7079\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.8337 - val_loss: 3.6728\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.6120 - val_loss: 3.6386\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.4076 - val_loss: 3.6057\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.4733 - val_loss: 3.5741\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.3805 - val_loss: 3.5427\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.2815 - val_loss: 3.5120\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.1515 - val_loss: 3.4816\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.0483 - val_loss: 3.4514\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.9796 - val_loss: 3.4235\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.8054 - val_loss: 3.3963\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.8643 - val_loss: 3.3680\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.7172 - val_loss: 3.3408\n",
      "\n",
      "Feature shape is (178, 50)\n",
      "\n",
      "Feature test shape is (46, 50)\n",
      "\n",
      "After SMOTE feature shape is (266, 50)\n",
      "Model: \"sequential_263\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1959 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1697 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1960 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1698 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1961 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1699 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1962 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1700 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1963 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1701 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1964 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1702 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1965 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1703 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1966 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1704 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1967 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 225s 2s/step - loss: 192.3046 - val_loss: 73.5273\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 157.5640 - val_loss: 63.1350\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 134.2030 - val_loss: 55.4483\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 114.4949 - val_loss: 49.6054\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 103.2480 - val_loss: 45.1293\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 88.7230 - val_loss: 41.5646\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 82.7806 - val_loss: 38.6766\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 76.9405 - val_loss: 36.3466\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 70.9566 - val_loss: 34.4045\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 67.4756 - val_loss: 32.7469\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 63.4929 - val_loss: 31.2822\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 59.8404 - val_loss: 29.9473\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 56.1689 - val_loss: 28.7223\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 55.0052 - val_loss: 27.5265\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 51.8584 - val_loss: 26.3865\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 49.5506 - val_loss: 25.2749\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 46.1934 - val_loss: 24.1851\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 43.8918 - val_loss: 23.1402\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - ETA: 0s - loss: 45.07 - 0s 3ms/step - loss: 41.8426 - val_loss: 22.0813\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 40.1166 - val_loss: 21.0488\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 38.0333 - val_loss: 20.0621\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - ETA: 0s - loss: 36.85 - 0s 3ms/step - loss: 35.2721 - val_loss: 19.1268\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 33.9396 - val_loss: 18.2597\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 31.8607 - val_loss: 17.4549\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 30.4463 - val_loss: 16.7434\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 29.3550 - val_loss: 16.1120\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 28.1081 - val_loss: 15.5331\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 26.5591 - val_loss: 15.0155\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 25.2964 - val_loss: 14.5448\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 24.9278 - val_loss: 14.1149\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 23.8601 - val_loss: 13.7146\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 22.9703 - val_loss: 13.3503\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 22.7690 - val_loss: 13.0028\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 21.8307 - val_loss: 12.6791\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 20.7991 - val_loss: 12.3817\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 20.0446 - val_loss: 12.0944\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 19.6998 - val_loss: 11.8236\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 18.8354 - val_loss: 11.5768\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 18.6041 - val_loss: 11.3505\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 18.0887 - val_loss: 11.1362\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 17.2972 - val_loss: 10.9287\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 17.0327 - val_loss: 10.7199\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 16.6687 - val_loss: 10.5245\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.4810 - val_loss: 10.3433\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.7272 - val_loss: 10.1749\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 15.5930 - val_loss: 10.0071\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.3482 - val_loss: 9.8458\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.0926 - val_loss: 9.6871\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.5122 - val_loss: 9.5397\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.4768 - val_loss: 9.3883\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.0949 - val_loss: 9.2464\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.5820 - val_loss: 9.1113\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.3488 - val_loss: 8.9841\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.2485 - val_loss: 8.8591\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.0458 - val_loss: 8.7344\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.8082 - val_loss: 8.6167\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.5368 - val_loss: 8.5056\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.3215 - val_loss: 8.4005\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.3508 - val_loss: 8.2916\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.1168 - val_loss: 8.1909\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.7735 - val_loss: 8.0955\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.6278 - val_loss: 7.9974\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 11.2635 - val_loss: 7.9033\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.1304 - val_loss: 7.8163\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.1648 - val_loss: 7.7334\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.7764 - val_loss: 7.6473\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.7077 - val_loss: 7.5637\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.4213 - val_loss: 7.4820\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.4085 - val_loss: 7.4068\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.0915 - val_loss: 7.3287\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.9862 - val_loss: 7.2556\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.2283 - val_loss: 7.1856\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.9173 - val_loss: 7.1152\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.7341 - val_loss: 7.0492\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.6407 - val_loss: 6.9852\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.4083 - val_loss: 6.9237\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.3864 - val_loss: 6.8619\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.1526 - val_loss: 6.8007\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9.1807 - val_loss: 6.7424\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.0362 - val_loss: 6.6863\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.8005 - val_loss: 6.6300\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8.7322 - val_loss: 6.5765\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.8968 - val_loss: 6.5255\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.6917 - val_loss: 6.4712\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.5549 - val_loss: 6.4201\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.3819 - val_loss: 6.3712\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.4143 - val_loss: 6.3185\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.2276 - val_loss: 6.2704\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.0260 - val_loss: 6.2261\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.9981 - val_loss: 6.1814\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.9426 - val_loss: 6.1355\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.9061 - val_loss: 6.0902\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.8810 - val_loss: 6.0453\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.8541 - val_loss: 6.0039\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.6665 - val_loss: 5.9624\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.5540 - val_loss: 5.9243\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.5278 - val_loss: 5.8857\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.4813 - val_loss: 5.8481\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.3960 - val_loss: 5.8086\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7.4007 - val_loss: 5.7709\n",
      "Model: \"sequential_264\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1968 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1705 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1969 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1706 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1970 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1707 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1971 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1708 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1972 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1709 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1973 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1710 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1974 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1711 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1975 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1712 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1976 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 224s 2s/step - loss: 174.5119 - val_loss: 76.3924\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 153.7959 - val_loss: 68.1947\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 132.1775 - val_loss: 61.5644\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 119.9345 - val_loss: 56.0847\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 108.9758 - val_loss: 51.6549\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 100.4828 - val_loss: 47.9932\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 95.5492 - val_loss: 44.7646\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 86.9127 - val_loss: 42.1182\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 82.4034 - val_loss: 39.7893\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 78.5294 - val_loss: 37.6708\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 74.0318 - val_loss: 35.8451\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 69.8031 - val_loss: 34.1461\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 65.7359 - val_loss: 32.5664\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 63.5675 - val_loss: 31.0560\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 59.4791 - val_loss: 29.6272\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 57.1848 - val_loss: 28.2385\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 54.4911 - val_loss: 26.9234\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 51.5049 - val_loss: 25.6298\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 48.5920 - val_loss: 24.3907\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 46.6852 - val_loss: 23.1900\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 43.3675 - val_loss: 22.0189\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 41.5785 - val_loss: 20.8995\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 39.4218 - val_loss: 19.8490\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 37.3869 - val_loss: 18.8837\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 35.1025 - val_loss: 17.9931\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 33.3775 - val_loss: 17.1829\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 31.7314 - val_loss: 16.4628\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 30.1247 - val_loss: 15.8369\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 28.6635 - val_loss: 15.2692\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 27.4613 - val_loss: 14.7499\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 26.7319 - val_loss: 14.2642\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 25.2910 - val_loss: 13.8110\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 24.6730 - val_loss: 13.3912\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 23.7439 - val_loss: 13.0133\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 22.9267 - val_loss: 12.6370\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 22.3179 - val_loss: 12.2900\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 21.5445 - val_loss: 11.9618\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 20.9584 - val_loss: 11.6495\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 20.2719 - val_loss: 11.3560\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 19.5510 - val_loss: 11.0762\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 18.8738 - val_loss: 10.8122\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 18.5282 - val_loss: 10.5612\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 18.1183 - val_loss: 10.3258\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 17.5181 - val_loss: 10.1009\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.8922 - val_loss: 9.8785\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.5049 - val_loss: 9.6766\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.8414 - val_loss: 9.4814\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.9227 - val_loss: 9.2946\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.4139 - val_loss: 9.1172\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.2287 - val_loss: 8.9474\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.6972 - val_loss: 8.7858\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.4117 - val_loss: 8.6318\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.0959 - val_loss: 8.4777\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.6650 - val_loss: 8.3348\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.4859 - val_loss: 8.1912\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.1864 - val_loss: 8.0558\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.8465 - val_loss: 7.9279\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.6182 - val_loss: 7.8000\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.2485 - val_loss: 7.6766\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.3812 - val_loss: 7.5581\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.8426 - val_loss: 7.4402\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.7360 - val_loss: 7.3308\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.5141 - val_loss: 7.2270\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.3872 - val_loss: 7.1216\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.1369 - val_loss: 7.0196\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.8901 - val_loss: 6.9231\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.8880 - val_loss: 6.8278\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 10.6634 - val_loss: 6.7348\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.4344 - val_loss: 6.6446\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.4326 - val_loss: 6.5568\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.0164 - val_loss: 6.4781\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.1121 - val_loss: 6.3964\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.9244 - val_loss: 6.3166\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.6229 - val_loss: 6.2365\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.5554 - val_loss: 6.1609\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.4303 - val_loss: 6.0900\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.2765 - val_loss: 6.0222\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.0832 - val_loss: 5.9538\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.1509 - val_loss: 5.8857\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.8828 - val_loss: 5.8202\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.8410 - val_loss: 5.7547\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.7194 - val_loss: 5.6920\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.5606 - val_loss: 5.6334\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.5515 - val_loss: 5.5774\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.4812 - val_loss: 5.5201\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.2533 - val_loss: 5.4657\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.0266 - val_loss: 5.4102\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.1579 - val_loss: 5.3561\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.0477 - val_loss: 5.3075\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.0210 - val_loss: 5.2578\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.9163 - val_loss: 5.2088\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.8714 - val_loss: 5.1628\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.5884 - val_loss: 5.1150\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.6020 - val_loss: 5.0693\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.6201 - val_loss: 5.0252\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.4383 - val_loss: 4.9814\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.3943 - val_loss: 4.9382\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.1787 - val_loss: 4.8993\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.2143 - val_loss: 4.8591\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.2403 - val_loss: 4.8201\n",
      "['../Cli3/UTSW_Cli_224P_OrderFea_40_SMOTE_CV_it_2_10_2.mat', '../PrePost/PET_MOO/HN_MR_4_PPD_SMOTE_CV5_fea50_it_50_2.mat', '../PrePost/CT_MOO/HN_MR_4_PPD_SMOTE_CV5_fea50_val_it_50_2.mat']\n",
      "\n",
      "... Processing ../PrePost/PET_MOO/HN_MR_4_PPD_SMOTE_CV5_fea50_it_50_2 ...\n",
      "PET_feature shape is (180, 50)\n",
      "\n",
      "... Processing ../PrePost/CT_MOO/HN_MR_4_PPD_SMOTE_CV5_fea50_val_it_50_2 ...\n",
      "CT_feature shape is (180, 50)\n",
      "\n",
      "Feature shape is (180, 50)\n",
      "\n",
      "Label shape is (180, 1)\n",
      "\n",
      "Feature test shape is (44, 50)\n",
      "\n",
      "Label test shape is (44, 1)\n",
      "\n",
      "After SMOTE feature shape is (268, 50)\n",
      "Model: \"sequential_265\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1977 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1713 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1978 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1714 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1979 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1715 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1980 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1716 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1981 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1717 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1982 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1718 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1983 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1719 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1984 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1720 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1985 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 223s 2s/step - loss: 160.1713 - val_loss: 69.0861\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 137.0810 - val_loss: 60.2079\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 118.0474 - val_loss: 53.4699\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 102.4581 - val_loss: 48.4232\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 92.1002 - val_loss: 44.4467\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 83.0592 - val_loss: 41.1728\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 76.5126 - val_loss: 38.4713\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 71.8447 - val_loss: 36.2228\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 67.3978 - val_loss: 34.2956\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 63.2745 - val_loss: 32.5844\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 60.1861 - val_loss: 31.0752\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 57.1873 - val_loss: 29.7247\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 54.9230 - val_loss: 28.5206\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 52.3777 - val_loss: 27.3962\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 50.4877 - val_loss: 26.3879\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 48.5066 - val_loss: 25.4097\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 46.8494 - val_loss: 24.4952\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 44.8960 - val_loss: 23.6107\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 43.2863 - val_loss: 22.7969\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 41.6197 - val_loss: 21.9806\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 39.7478 - val_loss: 21.1756\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 38.2703 - val_loss: 20.3800\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 36.6665 - val_loss: 19.6137\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 35.1423 - val_loss: 18.8573\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 33.5776 - val_loss: 18.1199\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 32.2406 - val_loss: 17.3997\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 3ms/step - loss: 30.4759 - val_loss: 16.7081\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 29.2410 - val_loss: 16.0390\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 27.9422 - val_loss: 15.4084\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 26.8170 - val_loss: 14.8015\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 25.7091 - val_loss: 14.2441\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 24.5184 - val_loss: 13.7189\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.2635 - val_loss: 13.2335\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.0643 - val_loss: 12.7943\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.5873 - val_loss: 12.3831\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.7937 - val_loss: 12.0095\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.2812 - val_loss: 11.6749\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.5651 - val_loss: 11.3686\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.9085 - val_loss: 11.0788\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.3208 - val_loss: 10.8216\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.9009 - val_loss: 10.5781\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.5629 - val_loss: 10.3498\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.2388 - val_loss: 10.1315\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.5961 - val_loss: 9.9245\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.3790 - val_loss: 9.7298\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - ETA: 0s - loss: 17.28 - 0s 3ms/step - loss: 16.2386 - val_loss: 9.5457\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.4369 - val_loss: 9.3755\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.3435 - val_loss: 9.2141\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.8695 - val_loss: 9.0561\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.9123 - val_loss: 8.9097\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.6398 - val_loss: 8.7642\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.2036 - val_loss: 8.6251\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.8320 - val_loss: 8.4839\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.6700 - val_loss: 8.3574\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.3683 - val_loss: 8.2393\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.1496 - val_loss: 8.1185\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.9606 - val_loss: 8.0028\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.5729 - val_loss: 7.8955\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.4275 - val_loss: 7.7928\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.4929 - val_loss: 7.6905\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.0726 - val_loss: 7.5878\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.9579 - val_loss: 7.4864\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.8589 - val_loss: 7.3936\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.4233 - val_loss: 7.3051\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.6100 - val_loss: 7.2154\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.2512 - val_loss: 7.1285\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.9132 - val_loss: 7.0488\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.8801 - val_loss: 6.9692\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.7562 - val_loss: 6.8941\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.5431 - val_loss: 6.8188\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.9242 - val_loss: 6.7492\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.2088 - val_loss: 6.6778\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.1425 - val_loss: 6.6086\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.1984 - val_loss: 6.5447\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - ETA: 0s - loss: 10.63 - 0s 3ms/step - loss: 10.1549 - val_loss: 6.4742\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.8845 - val_loss: 6.4107\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.6228 - val_loss: 6.3485\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.7101 - val_loss: 6.2892\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.5715 - val_loss: 6.2287\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.7337 - val_loss: 6.1703\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.2534 - val_loss: 6.1144\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.2397 - val_loss: 6.0630\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.2375 - val_loss: 6.0101\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.1198 - val_loss: 5.9576\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.9160 - val_loss: 5.9076\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.9422 - val_loss: 5.8589\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.8194 - val_loss: 5.8135\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.5737 - val_loss: 5.7658\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.6256 - val_loss: 5.7229\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.5591 - val_loss: 5.6790\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.5056 - val_loss: 5.6337\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.3447 - val_loss: 5.5926\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.3604 - val_loss: 5.5534\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2082 - val_loss: 5.5138\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0768 - val_loss: 5.4743\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1264 - val_loss: 5.4357\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.9497 - val_loss: 5.3973\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0009 - val_loss: 5.3606\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.9553 - val_loss: 5.3246\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.9032 - val_loss: 5.2884\n",
      "Model: \"sequential_266\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1986 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1721 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1987 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1722 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1988 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1723 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1989 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1724 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1990 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1725 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1991 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1726 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1992 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1727 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1993 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1728 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1994 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 231s 2s/step - loss: 217.9544 - val_loss: 64.0320\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 183.1075 - val_loss: 56.7282\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 159.2736 - val_loss: 51.3630\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 139.5046 - val_loss: 47.2538\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 126.4025 - val_loss: 44.0098\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 117.9895 - val_loss: 41.3714\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 108.3395 - val_loss: 39.1894\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 98.9935 - val_loss: 37.3313\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 92.7457 - val_loss: 35.7121\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 88.0246 - val_loss: 34.2875\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 84.2543 - val_loss: 32.9765\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 79.7880 - val_loss: 31.7737\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 75.5083 - val_loss: 30.6737\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 70.4656 - val_loss: 29.6291\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 68.8695 - val_loss: 28.6268\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 65.0511 - val_loss: 27.6505\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 62.7090 - val_loss: 26.6937\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 60.4880 - val_loss: 25.7389\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 57.7724 - val_loss: 24.7985\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 54.7434 - val_loss: 23.8482\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 52.6757 - val_loss: 22.9135\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 49.8858 - val_loss: 21.9786\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 47.2280 - val_loss: 21.0540\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 44.7385 - val_loss: 20.1512\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 43.5897 - val_loss: 19.2443\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 41.4557 - val_loss: 18.3552\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 39.4936 - val_loss: 17.5007\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 37.3107 - val_loss: 16.6950\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 35.1504 - val_loss: 15.9220\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 33.4806 - val_loss: 15.2051\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 31.6184 - val_loss: 14.5512\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 30.4740 - val_loss: 13.9610\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 29.0018 - val_loss: 13.4427\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 27.7579 - val_loss: 12.9584\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 26.1913 - val_loss: 12.5387\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 25.8419 - val_loss: 12.1534\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 24.9361 - val_loss: 11.7961\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 24.1541 - val_loss: 11.4628\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.1649 - val_loss: 11.1462\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.4772 - val_loss: 10.8568\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.0497 - val_loss: 10.5784\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.1929 - val_loss: 10.3181\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.4571 - val_loss: 10.0717\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.1923 - val_loss: 9.8311\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.4058 - val_loss: 9.6118\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.0262 - val_loss: 9.3973\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.5523 - val_loss: 9.1945\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.8910 - val_loss: 8.9992\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.5254 - val_loss: 8.8109\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.1796 - val_loss: 8.6276\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.7431 - val_loss: 8.4524\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.4063 - val_loss: 8.2856\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.9126 - val_loss: 8.1279\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.7163 - val_loss: 7.9788\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.0862 - val_loss: 7.8335\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.8694 - val_loss: 7.6904\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.7350 - val_loss: 7.5521\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.4581 - val_loss: 7.4208\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.2829 - val_loss: 7.2966\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.7904 - val_loss: 7.1716\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.6808 - val_loss: 7.0550\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.1608 - val_loss: 6.9383\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.0170 - val_loss: 6.8282\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.8785 - val_loss: 6.7207\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.5745 - val_loss: 6.6195\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.3140 - val_loss: 6.5195\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.3444 - val_loss: 6.4218\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.9673 - val_loss: 6.3281\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.8403 - val_loss: 6.2374\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.5210 - val_loss: 6.1518\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.3509 - val_loss: 6.0683\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.2142 - val_loss: 5.9851\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.8954 - val_loss: 5.9062\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.0101 - val_loss: 5.8304\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.7202 - val_loss: 5.7526\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.4082 - val_loss: 5.6811\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.4450 - val_loss: 5.6119\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.0272 - val_loss: 5.5454\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.9909 - val_loss: 5.4800\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.0498 - val_loss: 5.4170\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.7855 - val_loss: 5.3550\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.8196 - val_loss: 5.2939\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.5367 - val_loss: 5.2350\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.4276 - val_loss: 5.1759\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.1960 - val_loss: 5.1213\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.2914 - val_loss: 5.0690\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.1599 - val_loss: 5.0155\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.0210 - val_loss: 4.9632\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.7279 - val_loss: 4.9122\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.7898 - val_loss: 4.8627\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.6732 - val_loss: 4.8139\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.5315 - val_loss: 4.7693\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.3350 - val_loss: 4.7251\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.3784 - val_loss: 4.6811\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.3464 - val_loss: 4.6383\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0796 - val_loss: 4.5943\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1350 - val_loss: 4.5538\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0653 - val_loss: 4.5135\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.9428 - val_loss: 4.4749\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.8230 - val_loss: 4.4366\n",
      "\n",
      "Feature shape is (180, 50)\n",
      "\n",
      "Feature test shape is (44, 50)\n",
      "\n",
      "After SMOTE feature shape is (268, 50)\n",
      "Model: \"sequential_267\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1995 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1729 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1996 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1730 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1997 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1731 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1998 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1732 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1999 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1733 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2000 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1734 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2001 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1735 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2002 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1736 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2003 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 227s 2s/step - loss: 187.6210 - val_loss: 62.8195\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 155.3427 - val_loss: 54.7738\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 132.2525 - val_loss: 48.7568\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 117.4675 - val_loss: 44.1344\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 104.0508 - val_loss: 40.3978\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 94.6589 - val_loss: 37.3694\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 88.5702 - val_loss: 34.7608\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 81.3709 - val_loss: 32.5621\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 75.6953 - val_loss: 30.6726\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 71.1756 - val_loss: 28.9722\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 66.7105 - val_loss: 27.5002\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 63.5402 - val_loss: 26.1407\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 60.6275 - val_loss: 24.9269\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 57.3929 - val_loss: 23.7496\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 54.4292 - val_loss: 22.6521\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 51.9518 - val_loss: 21.5564\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 49.2658 - val_loss: 20.4762\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 46.5888 - val_loss: 19.4294\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 44.2967 - val_loss: 18.3736\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 41.7489 - val_loss: 17.3688\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 39.3704 - val_loss: 16.3936\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 36.9639 - val_loss: 15.4608\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 35.6255 - val_loss: 14.6135\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 32.8662 - val_loss: 13.8642\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 31.2396 - val_loss: 13.1769\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 30.2432 - val_loss: 12.5794\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 28.1444 - val_loss: 12.0441\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 27.7243 - val_loss: 11.5668\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 26.3227 - val_loss: 11.1323\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 25.3194 - val_loss: 10.7422\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 24.2723 - val_loss: 10.3765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.3909 - val_loss: 10.0385\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.5608 - val_loss: 9.7124\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.6845 - val_loss: 9.4313\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.8658 - val_loss: 9.1618\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 20.4905 - val_loss: 8.9175\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.7598 - val_loss: 8.6899\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.0190 - val_loss: 8.4717\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.2745 - val_loss: 8.2703\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 18.1259 - val_loss: 8.0881\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.4449 - val_loss: 7.8972\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.0300 - val_loss: 7.7183\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.8469 - val_loss: 7.5484\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.3212 - val_loss: 7.3914\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.0419 - val_loss: 7.2451\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.6613 - val_loss: 7.1108\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.2162 - val_loss: 6.9726\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.8443 - val_loss: 6.8477\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.4184 - val_loss: 6.7225\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.1704 - val_loss: 6.6005\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.8806 - val_loss: 6.4823\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.6959 - val_loss: 6.3678\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.3386 - val_loss: 6.2702\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.0314 - val_loss: 6.1757\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.6864 - val_loss: 6.0816\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.5156 - val_loss: 5.9904\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.4702 - val_loss: 5.9069\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 12.0866 - val_loss: 5.8193\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 12.0074 - val_loss: 5.7352\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 11.6942 - val_loss: 5.6556\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 11.6168 - val_loss: 5.5763\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 11.2956 - val_loss: 5.5058\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.1678 - val_loss: 5.4362\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.0957 - val_loss: 5.3675\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 10.7856 - val_loss: 5.3085\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.6654 - val_loss: 5.2436\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.4007 - val_loss: 5.1822\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.3108 - val_loss: 5.1239\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.1375 - val_loss: 5.0638\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.0444 - val_loss: 5.0077\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.9160 - val_loss: 4.9533\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.8387 - val_loss: 4.8962\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.5308 - val_loss: 4.8464\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.4741 - val_loss: 4.7950\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.2483 - val_loss: 4.7416\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.2552 - val_loss: 4.6955\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.0238 - val_loss: 4.6494\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.0671 - val_loss: 4.6012\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.8838 - val_loss: 4.5574\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.7986 - val_loss: 4.5089\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.5924 - val_loss: 4.4691\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.4402 - val_loss: 4.4277\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.5686 - val_loss: 4.3866\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2868 - val_loss: 4.3485\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.3466 - val_loss: 4.3119\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.3136 - val_loss: 4.2712\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1351 - val_loss: 4.2375\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0586 - val_loss: 4.2012\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.9369 - val_loss: 4.1671\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.8416 - val_loss: 4.1324\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.6584 - val_loss: 4.0999\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.6735 - val_loss: 4.0647\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.5827 - val_loss: 4.0346\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.5251 - val_loss: 4.0047\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7.3395 - val_loss: 3.9762\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.3529 - val_loss: 3.9491\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.3757 - val_loss: 3.9206\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.1059 - val_loss: 3.8930\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.1859 - val_loss: 3.8644\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.1084 - val_loss: 3.8383\n",
      "Model: \"sequential_268\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2004 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1737 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2005 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1738 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2006 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1739 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2007 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1740 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2008 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1741 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2009 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1742 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2010 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1743 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2011 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1744 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2012 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 231s 2s/step - loss: 190.4834 - val_loss: 54.7256\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 154.4056 - val_loss: 49.4116\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 142.6438 - val_loss: 45.3840\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 127.6238 - val_loss: 42.2704\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 114.8799 - val_loss: 39.7528\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 106.2375 - val_loss: 37.6041\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 99.2157 - val_loss: 35.7910\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 92.1349 - val_loss: 34.2028\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 85.7579 - val_loss: 32.8025\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 81.1013 - val_loss: 31.5616\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 77.5486 - val_loss: 30.3999\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 73.4040 - val_loss: 29.3224\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 70.0240 - val_loss: 28.3059\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 66.7847 - val_loss: 27.3036\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 63.9638 - val_loss: 26.3321\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 61.5982 - val_loss: 25.3619\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 59.2926 - val_loss: 24.3955\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 55.9106 - val_loss: 23.4007\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 53.9549 - val_loss: 22.4032\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 51.1640 - val_loss: 21.3813\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 48.8273 - val_loss: 20.3643\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 45.8133 - val_loss: 19.3668\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 43.3747 - val_loss: 18.3915\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 41.5977 - val_loss: 17.4673\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 39.3650 - val_loss: 16.6320\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 37.9507 - val_loss: 15.8728\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 36.0653 - val_loss: 15.1898\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 34.0245 - val_loss: 14.5695\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 32.7052 - val_loss: 14.0114\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 30.9725 - val_loss: 13.4948\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 30.1323 - val_loss: 13.0191\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 29.0009 - val_loss: 12.5854\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 28.0205 - val_loss: 12.1803\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 26.9755 - val_loss: 11.8006\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 25.7023 - val_loss: 11.4569\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 24.8998 - val_loss: 11.1292\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.7780 - val_loss: 10.8216\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.4352 - val_loss: 10.5326\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.4180 - val_loss: 10.2622\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.8246 - val_loss: 10.0027\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.0978 - val_loss: 9.7622\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.7059 - val_loss: 9.5351\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.0828 - val_loss: 9.3174\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.5030 - val_loss: 9.1109\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.9482 - val_loss: 8.9194\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.4281 - val_loss: 8.7351\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.8466 - val_loss: 8.5556\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.6514 - val_loss: 8.3837\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.4499 - val_loss: 8.2185\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.5953 - val_loss: 8.0613\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.2953 - val_loss: 7.9103\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.8868 - val_loss: 7.7653\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.5363 - val_loss: 7.6261\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.2069 - val_loss: 7.4930\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.9110 - val_loss: 7.3640\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.7355 - val_loss: 7.2414\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.3464 - val_loss: 7.1208\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.1288 - val_loss: 7.0030\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.6748 - val_loss: 6.8915\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.6095 - val_loss: 6.7823\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.0702 - val_loss: 6.6776\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.0096 - val_loss: 6.5790\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.6734 - val_loss: 6.4813\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.4697 - val_loss: 6.3899\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - ETA: 0s - loss: 13.14 - 0s 3ms/step - loss: 12.3259 - val_loss: 6.3002\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.9402 - val_loss: 6.2125\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.7038 - val_loss: 6.1267\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.5336 - val_loss: 6.0416\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.3404 - val_loss: 5.9612\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.3530 - val_loss: 5.8831\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.9470 - val_loss: 5.8070\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.9066 - val_loss: 5.7337\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.7600 - val_loss: 5.6615\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.6616 - val_loss: 5.5918\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.3520 - val_loss: 5.5245\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.2532 - val_loss: 5.4573\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.9654 - val_loss: 5.3938\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.9211 - val_loss: 5.3308\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.8223 - val_loss: 5.2696\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.5453 - val_loss: 5.2100\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.5022 - val_loss: 5.1522\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.4593 - val_loss: 5.0957\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.1789 - val_loss: 5.0411\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.3599 - val_loss: 4.9888\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.0618 - val_loss: 4.9362\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.9559 - val_loss: 4.8843\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.8738 - val_loss: 4.8319\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.6697 - val_loss: 4.7839\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.5732 - val_loss: 4.7353\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.6127 - val_loss: 4.6896\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.3313 - val_loss: 4.6441\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.3362 - val_loss: 4.5999\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2143 - val_loss: 4.5566\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1336 - val_loss: 4.5147\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0268 - val_loss: 4.4732\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0301 - val_loss: 4.4331\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.8730 - val_loss: 4.3939\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.8783 - val_loss: 4.3548\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.7218 - val_loss: 4.3162\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.6408 - val_loss: 4.2803\n",
      "['../Cli3/UTSW_Cli_224P_OrderFea_40_SMOTE_CV_it_2_10_3.mat', '../PrePost/PET_MOO/HN_MR_4_PPD_SMOTE_CV5_fea50_it_50_3.mat', '../PrePost/CT_MOO/HN_MR_4_PPD_SMOTE_CV5_fea50_val_it_50_3.mat']\n",
      "\n",
      "... Processing ../PrePost/PET_MOO/HN_MR_4_PPD_SMOTE_CV5_fea50_it_50_3 ...\n",
      "PET_feature shape is (180, 50)\n",
      "\n",
      "... Processing ../PrePost/CT_MOO/HN_MR_4_PPD_SMOTE_CV5_fea50_val_it_50_3 ...\n",
      "CT_feature shape is (180, 50)\n",
      "\n",
      "Feature shape is (180, 50)\n",
      "\n",
      "Label shape is (180, 1)\n",
      "\n",
      "Feature test shape is (44, 50)\n",
      "\n",
      "Label test shape is (44, 1)\n",
      "\n",
      "After SMOTE feature shape is (268, 50)\n",
      "Model: \"sequential_269\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2013 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1745 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2014 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1746 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2015 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1747 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2016 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1748 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2017 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1749 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2018 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1750 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2019 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1751 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2020 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1752 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2021 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 235s 2s/step - loss: 193.7991 - val_loss: 64.8486\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 158.5363 - val_loss: 56.2094\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 135.0148 - val_loss: 49.7852\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 117.8172 - val_loss: 44.9119\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 104.9715 - val_loss: 41.1799\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 93.3263 - val_loss: 38.1885\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 84.8036 - val_loss: 35.7777\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 79.2487 - val_loss: 33.8132\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 73.6267 - val_loss: 32.0796\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 69.5006 - val_loss: 30.5632\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 65.5313 - val_loss: 29.2329\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 61.4120 - val_loss: 28.0124\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 58.9641 - val_loss: 26.8717\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 55.7601 - val_loss: 25.7980\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 53.0507 - val_loss: 24.7720\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 50.7211 - val_loss: 23.7743\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 48.3053 - val_loss: 22.7769\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 45.7366 - val_loss: 21.8495\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 43.5104 - val_loss: 20.9479\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 41.4798 - val_loss: 20.0489\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 39.4160 - val_loss: 19.1591\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 37.3792 - val_loss: 18.2907\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 35.5622 - val_loss: 17.4471\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 33.5327 - val_loss: 16.6228\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 31.4978 - val_loss: 15.8151\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 30.1844 - val_loss: 15.0482\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 3ms/step - loss: 28.5340 - val_loss: 14.3285\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 26.9737 - val_loss: 13.6587\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 25.5795 - val_loss: 13.0383\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 24.6146 - val_loss: 12.4772\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.0583 - val_loss: 11.9863\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 22.3615 - val_loss: 11.5287\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.1204 - val_loss: 11.1287\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.4291 - val_loss: 10.7894\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.6571 - val_loss: 10.4661\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.1609 - val_loss: 10.1893\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.4399 - val_loss: 9.9238\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.7795 - val_loss: 9.6665\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.7417 - val_loss: 9.4302\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.1042 - val_loss: 9.2032\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.4463 - val_loss: 9.0007\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.2642 - val_loss: 8.7973\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.7476 - val_loss: 8.6056\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.2205 - val_loss: 8.4315\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.8411 - val_loss: 8.2603\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.6194 - val_loss: 8.0932\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.3197 - val_loss: 7.9386\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.0443 - val_loss: 7.7916\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.7186 - val_loss: 7.6511\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.3943 - val_loss: 7.5229\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.1200 - val_loss: 7.3906\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.8604 - val_loss: 7.2606\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.6056 - val_loss: 7.1375\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.3019 - val_loss: 7.0158\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.0955 - val_loss: 6.9026\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.8215 - val_loss: 6.7925\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.6750 - val_loss: 6.6861\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.4275 - val_loss: 6.5832\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.1745 - val_loss: 6.4881\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.9503 - val_loss: 6.3985\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.8398 - val_loss: 6.3079\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.6164 - val_loss: 6.2155\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.6691 - val_loss: 6.1295\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.2793 - val_loss: 6.0507\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.1378 - val_loss: 5.9668\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.0084 - val_loss: 5.8875\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.8981 - val_loss: 5.8112\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.7289 - val_loss: 5.7385\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.5655 - val_loss: 5.6705\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.3879 - val_loss: 5.6026\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.2503 - val_loss: 5.5390\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.1964 - val_loss: 5.4747\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.9528 - val_loss: 5.4116\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.9429 - val_loss: 5.3529\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.8867 - val_loss: 5.2909\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.7254 - val_loss: 5.2329\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.5497 - val_loss: 5.1784\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.4675 - val_loss: 5.1266\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2697 - val_loss: 5.0735\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.3055 - val_loss: 5.0236\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1343 - val_loss: 4.9772\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0099 - val_loss: 4.9280\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0185 - val_loss: 4.8817\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.9890 - val_loss: 4.8385\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.8589 - val_loss: 4.7943\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.6025 - val_loss: 4.7521\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.5235 - val_loss: 4.7106\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.4961 - val_loss: 4.6676\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.3840 - val_loss: 4.6267\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.3972 - val_loss: 4.5899\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.4572 - val_loss: 4.5496\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7.2997 - val_loss: 4.5127\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.2518 - val_loss: 4.4748\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.1007 - val_loss: 4.4391\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.0923 - val_loss: 4.4033\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.0936 - val_loss: 4.3701\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6.9566 - val_loss: 4.3373\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6.8832 - val_loss: 4.3053\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6.8877 - val_loss: 4.2760\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6.7385 - val_loss: 4.2470\n",
      "Model: \"sequential_270\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2022 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1753 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2023 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1754 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2024 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1755 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2025 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1756 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2026 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1757 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2027 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1758 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2028 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1759 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2029 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1760 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2030 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 245s 2s/step - loss: 195.6962 - val_loss: 100.8828\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 162.4320 - val_loss: 87.7037\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 148.3753 - val_loss: 77.3912\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 128.2871 - val_loss: 69.1908\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 116.7202 - val_loss: 62.8072\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 106.0634 - val_loss: 57.7244\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 99.8370 - val_loss: 53.5544\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 91.0708 - val_loss: 50.1391\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 86.1183 - val_loss: 47.2856\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 81.3931 - val_loss: 44.7702\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 77.4568 - val_loss: 42.5465\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 73.7399 - val_loss: 40.6032\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 70.1204 - val_loss: 38.8764\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 67.1617 - val_loss: 37.2748\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 64.3594 - val_loss: 35.7907\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 61.5701 - val_loss: 34.3801\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 59.2382 - val_loss: 33.0287\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 56.1068 - val_loss: 31.7294\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 53.9188 - val_loss: 30.4726\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 51.7612 - val_loss: 29.2364\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 49.7478 - val_loss: 28.0281\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 46.9280 - val_loss: 26.8391\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 44.5093 - val_loss: 25.6529\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 42.9311 - val_loss: 24.4815\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 40.1469 - val_loss: 23.3521\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 38.3713 - val_loss: 22.2496\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 36.3836 - val_loss: 21.2020\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 34.7827 - val_loss: 20.2278\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 32.9646 - val_loss: 19.2953\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 31.1986 - val_loss: 18.4602\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 29.8252 - val_loss: 17.7139\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 28.3559 - val_loss: 17.0411\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 27.3543 - val_loss: 16.4297\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 26.0894 - val_loss: 15.8848\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 25.3558 - val_loss: 15.3856\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.9572 - val_loss: 14.9132\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.6515 - val_loss: 14.4548\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.4439 - val_loss: 14.0282\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.8913 - val_loss: 13.6226\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.7192 - val_loss: 13.2433\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.3967 - val_loss: 12.8818\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.4943 - val_loss: 12.5414\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.8254 - val_loss: 12.2195\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.6734 - val_loss: 11.9095\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.8651 - val_loss: 11.6103\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.4190 - val_loss: 11.3371\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.0556 - val_loss: 11.0644\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.4581 - val_loss: 10.8154\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.0541 - val_loss: 10.5733\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.4750 - val_loss: 10.3447\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.2470 - val_loss: 10.1290\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.9217 - val_loss: 9.9227\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.6422 - val_loss: 9.7214\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.3765 - val_loss: 9.5229\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.6586 - val_loss: 9.3406\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.6357 - val_loss: 9.1624\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.1978 - val_loss: 8.9903\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.0133 - val_loss: 8.8312\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.8061 - val_loss: 8.6737\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.4643 - val_loss: 8.5265\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.1794 - val_loss: 8.3802\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.0915 - val_loss: 8.2380\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.6379 - val_loss: 8.1084\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.4563 - val_loss: 7.9804\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.1636 - val_loss: 7.8557\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.1834 - val_loss: 7.7350\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.0125 - val_loss: 7.6175\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.5932 - val_loss: 7.5058\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.4794 - val_loss: 7.3991\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.4588 - val_loss: 7.2957\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.2501 - val_loss: 7.1953\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.1736 - val_loss: 7.0987\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.8575 - val_loss: 7.0009\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.7127 - val_loss: 6.9096\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 9.6853 - val_loss: 6.8215\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 9.5218 - val_loss: 6.7391\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.3682 - val_loss: 6.6555\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.3729 - val_loss: 6.5761\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.1364 - val_loss: 6.4990\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 9.0666 - val_loss: 6.4227\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8.8802 - val_loss: 6.3500\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8.8022 - val_loss: 6.2758\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8.5858 - val_loss: 6.2081\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8.5335 - val_loss: 6.1411\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.4019 - val_loss: 6.0751\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8.3835 - val_loss: 6.0138\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.3045 - val_loss: 5.9536\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1369 - val_loss: 5.8958\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0813 - val_loss: 5.8374\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.9188 - val_loss: 5.7787\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.7171 - val_loss: 5.7248\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.8790 - val_loss: 5.6730\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.6502 - val_loss: 5.6217\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.7327 - val_loss: 5.5690\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.6099 - val_loss: 5.5178\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.4938 - val_loss: 5.4683\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7.4249 - val_loss: 5.4197\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.3418 - val_loss: 5.3722\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7.2754 - val_loss: 5.3289\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7.1852 - val_loss: 5.2852\n",
      "\n",
      "Feature shape is (180, 50)\n",
      "\n",
      "Feature test shape is (44, 50)\n",
      "\n",
      "After SMOTE feature shape is (268, 50)\n",
      "Model: \"sequential_271\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2031 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1761 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2032 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1762 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2033 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1763 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2034 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1764 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2035 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1765 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2036 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1766 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2037 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1767 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2038 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1768 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2039 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 249s 2s/step - loss: 176.3018 - val_loss: 54.2994\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 151.8262 - val_loss: 47.6972\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 130.0747 - val_loss: 42.9152\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 114.7300 - val_loss: 39.3323\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 105.0161 - val_loss: 36.5493\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 91.9596 - val_loss: 34.2518\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 87.3590 - val_loss: 32.3993\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 81.2916 - val_loss: 30.7769\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 78.0815 - val_loss: 29.4349\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 73.0289 - val_loss: 28.2653\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 69.1245 - val_loss: 27.1159\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 66.3603 - val_loss: 26.0814\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 63.9623 - val_loss: 25.1455\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 60.8190 - val_loss: 24.2252\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 58.2841 - val_loss: 23.3593\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 55.8223 - val_loss: 22.5291\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 53.9828 - val_loss: 21.7078\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 51.5637 - val_loss: 20.8898\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 48.4866 - val_loss: 20.0399\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 46.6102 - val_loss: 19.2194\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 45.0722 - val_loss: 18.3990\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 43.0168 - val_loss: 17.5795\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 41.2525 - val_loss: 16.7667\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 38.9907 - val_loss: 15.9593\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 37.3553 - val_loss: 15.1640\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 35.5618 - val_loss: 14.3896\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 33.8006 - val_loss: 13.6641\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 31.8140 - val_loss: 12.9553\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 30.6026 - val_loss: 12.2907\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 28.9604 - val_loss: 11.6683\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 27.7701 - val_loss: 11.0895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 26.1002 - val_loss: 10.5753\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 25.0657 - val_loss: 10.1108\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 23.7909 - val_loss: 9.6936\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.1640 - val_loss: 9.3242\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22.1883 - val_loss: 8.9933\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.9888 - val_loss: 8.6922\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.6935 - val_loss: 8.4258\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.2676 - val_loss: 8.1851\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.8676 - val_loss: 7.9555\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.9387 - val_loss: 7.7430\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18.6045 - val_loss: 7.5346\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.7586 - val_loss: 7.3463\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.1857 - val_loss: 7.1675\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.1398 - val_loss: 6.9954\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.6518 - val_loss: 6.8264\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.0662 - val_loss: 6.6724\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.7460 - val_loss: 6.5200\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.1051 - val_loss: 6.3787\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.9220 - val_loss: 6.2449\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.7421 - val_loss: 6.1223\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.3614 - val_loss: 6.0008\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.8959 - val_loss: 5.8904\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.7133 - val_loss: 5.7807\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.5889 - val_loss: 5.6762\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.0892 - val_loss: 5.5763\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.7589 - val_loss: 5.4861\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.6167 - val_loss: 5.3935\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.3642 - val_loss: 5.3084\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.0393 - val_loss: 5.2253\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.9907 - val_loss: 5.1533\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.6191 - val_loss: 5.0770\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.4821 - val_loss: 5.0030\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.3200 - val_loss: 4.9351\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.2390 - val_loss: 4.8648\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.9694 - val_loss: 4.8025\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.6931 - val_loss: 4.7398\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.5516 - val_loss: 4.6824\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.5062 - val_loss: 4.6269\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.2068 - val_loss: 4.5725\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.9792 - val_loss: 4.5181\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.9379 - val_loss: 4.4680\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.9297 - val_loss: 4.4185\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.5791 - val_loss: 4.3702\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.5614 - val_loss: 4.3225\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.4246 - val_loss: 4.2777\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.2652 - val_loss: 4.2353\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.1399 - val_loss: 4.1947\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.1592 - val_loss: 4.1527\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.8836 - val_loss: 4.1130\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.9107 - val_loss: 4.0764\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.6083 - val_loss: 4.0384\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.5941 - val_loss: 4.0015\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.4436 - val_loss: 3.9638\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.5416 - val_loss: 3.9290\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.3253 - val_loss: 3.8937\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2622 - val_loss: 3.8592\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0493 - val_loss: 3.8263\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1631 - val_loss: 3.7939\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0245 - val_loss: 3.7631\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.9356 - val_loss: 3.7302\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1118 - val_loss: 3.6996\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.6316 - val_loss: 3.6696\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.6865 - val_loss: 3.6399\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.6029 - val_loss: 3.6126\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.5095 - val_loss: 3.5840\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.4291 - val_loss: 3.5560\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.2830 - val_loss: 3.5287\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.2382 - val_loss: 3.5023\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.2208 - val_loss: 3.4781\n",
      "Model: \"sequential_272\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2040 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1769 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2041 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1770 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2042 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1771 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2043 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1772 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2044 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1773 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2045 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1774 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2046 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1775 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2047 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1776 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2048 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 233s 2s/step - loss: 209.3689 - val_loss: 69.3425\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 178.4816 - val_loss: 60.3666\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 155.4522 - val_loss: 53.6898\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 136.8560 - val_loss: 48.5942\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 123.6741 - val_loss: 44.5697\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 113.6767 - val_loss: 41.2720\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 105.0410 - val_loss: 38.5603\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 97.1031 - val_loss: 36.3494\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 90.7341 - val_loss: 34.4308\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 85.3807 - val_loss: 32.7673\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 82.2247 - val_loss: 31.2988\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 77.4357 - val_loss: 29.9738\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 73.7782 - val_loss: 28.7873\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 70.3353 - val_loss: 27.6669\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 67.0343 - val_loss: 26.6009\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 63.8983 - val_loss: 25.5725\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 60.7952 - val_loss: 24.5678\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 57.8341 - val_loss: 23.5851\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 55.9773 - val_loss: 22.6069\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 53.4943 - val_loss: 21.6461\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 49.9305 - val_loss: 20.6960\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 48.3257 - val_loss: 19.7644\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 46.4444 - val_loss: 18.8654\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 43.5746 - val_loss: 17.9790\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 41.8010 - val_loss: 17.1287\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 39.9281 - val_loss: 16.3224\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 37.8838 - val_loss: 15.5650\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 36.0159 - val_loss: 14.8628\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 34.2457 - val_loss: 14.2141\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 32.8182 - val_loss: 13.6306\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 31.1436 - val_loss: 13.1113\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 30.3981 - val_loss: 12.6295\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 28.7534 - val_loss: 12.1833\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 27.9065 - val_loss: 11.7675\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 26.7575 - val_loss: 11.3908\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 25.5472 - val_loss: 11.0337\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 25.1964 - val_loss: 10.7085\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 24.1533 - val_loss: 10.4030\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.4322 - val_loss: 10.1107\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.5872 - val_loss: 9.8373\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.2374 - val_loss: 9.5760\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.6252 - val_loss: 9.3348\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.7562 - val_loss: 9.1062\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.3697 - val_loss: 8.8909\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.6875 - val_loss: 8.6899\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.1140 - val_loss: 8.4990\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.6201 - val_loss: 8.3116\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.2967 - val_loss: 8.1360\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.6195 - val_loss: 7.9687\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.3702 - val_loss: 7.8117\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.9321 - val_loss: 7.6628\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.2374 - val_loss: 7.5166\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.2452 - val_loss: 7.3786\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15.6680 - val_loss: 7.2480\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.5131 - val_loss: 7.1192\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.4277 - val_loss: 6.9971\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.7353 - val_loss: 6.8774\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.5407 - val_loss: 6.7631\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.1607 - val_loss: 6.6551\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.8377 - val_loss: 6.5494\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.7843 - val_loss: 6.4501\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.4434 - val_loss: 6.3520\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.2494 - val_loss: 6.2571\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.0417 - val_loss: 6.1688\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.7717 - val_loss: 6.0796\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.4617 - val_loss: 5.9966\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.0955 - val_loss: 5.9155\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.1549 - val_loss: 5.8380\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.8441 - val_loss: 5.7633\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.7605 - val_loss: 5.6902\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.3455 - val_loss: 5.6183\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11.5065 - val_loss: 5.5489\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.2565 - val_loss: 5.4809\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.0462 - val_loss: 5.4139\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.7294 - val_loss: 5.3501\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.8392 - val_loss: 5.2878\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.6902 - val_loss: 5.2278\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.3961 - val_loss: 5.1711\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.4252 - val_loss: 5.1144\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.1307 - val_loss: 5.0594\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.9403 - val_loss: 5.0062\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.8043 - val_loss: 4.9553\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.7010 - val_loss: 4.9047\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.6793 - val_loss: 4.8563\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.6146 - val_loss: 4.8080\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.3528 - val_loss: 4.7610\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.3567 - val_loss: 4.7155\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.1674 - val_loss: 4.6706\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.1032 - val_loss: 4.6265\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.0758 - val_loss: 4.5846\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.9236 - val_loss: 4.5429\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.6927 - val_loss: 4.5026\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.8033 - val_loss: 4.4632\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.5753 - val_loss: 4.4249\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.3600 - val_loss: 4.3865\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.3752 - val_loss: 4.3499\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.4157 - val_loss: 4.3142\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1134 - val_loss: 4.2801\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0354 - val_loss: 4.2461\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1001 - val_loss: 4.2130\n",
      "['../Cli3/UTSW_Cli_224P_OrderFea_40_SMOTE_CV_it_2_10_4.mat', '../PrePost/PET_MOO/HN_MR_4_PPD_SMOTE_CV5_fea50_it_50_4.mat', '../PrePost/CT_MOO/HN_MR_4_PPD_SMOTE_CV5_fea50_val_it_50_4.mat']\n",
      "\n",
      "... Processing ../PrePost/PET_MOO/HN_MR_4_PPD_SMOTE_CV5_fea50_it_50_4 ...\n",
      "PET_feature shape is (178, 50)\n",
      "\n",
      "... Processing ../PrePost/CT_MOO/HN_MR_4_PPD_SMOTE_CV5_fea50_val_it_50_4 ...\n",
      "CT_feature shape is (178, 50)\n",
      "\n",
      "Feature shape is (178, 50)\n",
      "\n",
      "Label shape is (178, 1)\n",
      "\n",
      "Feature test shape is (46, 50)\n",
      "\n",
      "Label test shape is (46, 1)\n",
      "\n",
      "After SMOTE feature shape is (266, 50)\n",
      "Model: \"sequential_273\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2049 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1777 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2050 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1778 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2051 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1779 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2052 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1780 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2053 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1781 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2054 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1782 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2055 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1783 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2056 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1784 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2057 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 234s 2s/step - loss: 206.7478 - val_loss: 76.8636\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 169.3611 - val_loss: 65.9425\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 140.9103 - val_loss: 57.9391\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 125.7611 - val_loss: 51.8123\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 108.2294 - val_loss: 47.1296\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 98.3843 - val_loss: 43.4023\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 87.7261 - val_loss: 40.3874\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 80.3602 - val_loss: 37.8459\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 75.0510 - val_loss: 35.6600\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 70.4707 - val_loss: 33.7332\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 66.1875 - val_loss: 32.0778\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 62.6712 - val_loss: 30.6093\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 59.3912 - val_loss: 29.2872\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 56.1008 - val_loss: 28.0635\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 53.3980 - val_loss: 26.9238\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 51.0148 - val_loss: 25.8341\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 48.7336 - val_loss: 24.7918\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 46.6823 - val_loss: 23.7905\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 44.3329 - val_loss: 22.8043\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 42.5021 - val_loss: 21.8470\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 40.5367 - val_loss: 20.8977\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 38.6527 - val_loss: 19.9652\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 36.6326 - val_loss: 19.0552\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 34.9582 - val_loss: 18.1704\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 32.9825 - val_loss: 17.2971\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 31.2608 - val_loss: 16.4532\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 3ms/step - loss: 29.5559 - val_loss: 15.6419\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 28.0919 - val_loss: 14.8709\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 26.2702 - val_loss: 14.1574\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 25.2673 - val_loss: 13.5055\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 24.2518 - val_loss: 12.9317\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 23.2605 - val_loss: 12.4157\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 21.9646 - val_loss: 11.9730\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 21.7699 - val_loss: 11.5841\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 20.4105 - val_loss: 11.2324\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 19.7859 - val_loss: 10.9122\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 19.4992 - val_loss: 10.6088\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 18.9824 - val_loss: 10.3268\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 18.0558 - val_loss: 10.0624\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 17.7318 - val_loss: 9.8150\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 17.4567 - val_loss: 9.5823\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.8401 - val_loss: 9.3646\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.2622 - val_loss: 9.1620\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.0343 - val_loss: 8.9674\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.7023 - val_loss: 8.7830\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.3092 - val_loss: 8.6051\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.8031 - val_loss: 8.4399\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.5583 - val_loss: 8.2795\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.3051 - val_loss: 8.1257\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.9242 - val_loss: 7.9843\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.7190 - val_loss: 7.8428\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.5692 - val_loss: 7.7106\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.4629 - val_loss: 7.5824\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.0366 - val_loss: 7.4611\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.5640 - val_loss: 7.3451\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.4020 - val_loss: 7.2337\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.3348 - val_loss: 7.1268\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.0020 - val_loss: 7.0197\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.1205 - val_loss: 6.9159\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11.7458 - val_loss: 6.8159\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.5862 - val_loss: 6.7209\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.4918 - val_loss: 6.6294\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.2264 - val_loss: 6.5416\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.1848 - val_loss: 6.4619\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.0439 - val_loss: 6.3784\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 10.5881 - val_loss: 6.2999\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.6681 - val_loss: 6.2223\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.5639 - val_loss: 6.1489\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.4893 - val_loss: 6.0755\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.3546 - val_loss: 6.0055\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.3311 - val_loss: 5.9379\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.1256 - val_loss: 5.8716\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.0145 - val_loss: 5.8073\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.7167 - val_loss: 5.7446\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.7063 - val_loss: 5.6835\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.6830 - val_loss: 5.6233\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.5462 - val_loss: 5.5669\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9.2770 - val_loss: 5.5117\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.2052 - val_loss: 5.4564\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.1682 - val_loss: 5.4047\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9.0160 - val_loss: 5.3531\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.8889 - val_loss: 5.3033\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8.9857 - val_loss: 5.2551\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8.7111 - val_loss: 5.2074\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8.6001 - val_loss: 5.1600\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.6229 - val_loss: 5.1140\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8.2579 - val_loss: 5.0703\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.4969 - val_loss: 5.0273\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.4298 - val_loss: 4.9869\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.3523 - val_loss: 4.9446\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.4108 - val_loss: 4.9039\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.2482 - val_loss: 4.8623\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.9568 - val_loss: 4.8238\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.9659 - val_loss: 4.7873\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.0333 - val_loss: 4.7501\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.8690 - val_loss: 4.7141\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.7911 - val_loss: 4.6781\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.8322 - val_loss: 4.6431\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.6183 - val_loss: 4.6087\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.6997 - val_loss: 4.5748\n",
      "Model: \"sequential_274\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2058 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1785 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2059 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1786 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2060 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1787 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2061 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1788 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2062 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1789 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2063 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1790 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2064 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1791 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2065 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1792 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2066 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 242s 2s/step - loss: 181.4388 - val_loss: 77.8283\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 150.3707 - val_loss: 67.7103\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 132.4022 - val_loss: 60.2773\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 117.0940 - val_loss: 54.4229\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 107.3794 - val_loss: 49.8455\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 98.9955 - val_loss: 46.2217\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 91.5638 - val_loss: 43.3644\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 84.3311 - val_loss: 41.0041\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 79.0116 - val_loss: 39.0002\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 74.7627 - val_loss: 37.2135\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 71.6156 - val_loss: 35.6033\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 68.2834 - val_loss: 34.1638\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 64.5169 - val_loss: 32.8538\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 62.7167 - val_loss: 31.5814\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 59.6165 - val_loss: 30.3573\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 56.8260 - val_loss: 29.2210\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 54.2961 - val_loss: 28.1134\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 52.0544 - val_loss: 27.0399\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 49.9529 - val_loss: 25.9484\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 47.5259 - val_loss: 24.8858\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 45.3998 - val_loss: 23.8504\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 43.1508 - val_loss: 22.8490\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 41.2761 - val_loss: 21.9140\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 38.7278 - val_loss: 21.0344\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 37.2320 - val_loss: 20.1973\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 35.4727 - val_loss: 19.4337\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 33.3946 - val_loss: 18.7253\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 32.6592 - val_loss: 18.0939\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 30.9694 - val_loss: 17.5100\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 29.6515 - val_loss: 16.9660\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 28.4185 - val_loss: 16.4436\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 27.3417 - val_loss: 15.9626\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 26.5052 - val_loss: 15.5224\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 25.3563 - val_loss: 15.1258\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 24.2790 - val_loss: 14.7125\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 23.6477 - val_loss: 14.3464\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 22.8567 - val_loss: 13.9984\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 21.9440 - val_loss: 13.6793\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 21.3820 - val_loss: 13.3748\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 20.7604 - val_loss: 13.1127\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 20.1132 - val_loss: 12.8328\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 19.5770 - val_loss: 12.5811\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 18.9250 - val_loss: 12.3324\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 18.5316 - val_loss: 12.0993\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 18.1371 - val_loss: 11.8706\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 17.5917 - val_loss: 11.6332\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 17.2374 - val_loss: 11.4224\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.9353 - val_loss: 11.2216\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.4783 - val_loss: 11.0439\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.8095 - val_loss: 10.8758\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.3724 - val_loss: 10.7072\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.1082 - val_loss: 10.5473\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.8262 - val_loss: 10.3692\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.3692 - val_loss: 10.2128\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.4305 - val_loss: 10.0610\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.9299 - val_loss: 9.8971\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.8261 - val_loss: 9.7539\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.5852 - val_loss: 9.5989\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.2766 - val_loss: 9.4620\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.0226 - val_loss: 9.3266\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.6131 - val_loss: 9.1951\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.5406 - val_loss: 9.0655\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.4354 - val_loss: 8.9524\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.0691 - val_loss: 8.8382\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.9643 - val_loss: 8.7223\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.6203 - val_loss: 8.6095\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.3283 - val_loss: 8.4912\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.0911 - val_loss: 8.3950\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.9600 - val_loss: 8.2970\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.7672 - val_loss: 8.1929\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.9326 - val_loss: 8.1026\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.4706 - val_loss: 8.0065\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.3004 - val_loss: 7.9147\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.2489 - val_loss: 7.8143\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.0294 - val_loss: 7.7286\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.9845 - val_loss: 7.6614\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.7313 - val_loss: 7.5885\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.7366 - val_loss: 7.5172\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.6135 - val_loss: 7.4550\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.4295 - val_loss: 7.3803\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.3426 - val_loss: 7.3179\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.0900 - val_loss: 7.2449\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.2354 - val_loss: 7.1813\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.0836 - val_loss: 7.1103\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.6900 - val_loss: 7.0400\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.6675 - val_loss: 6.9785\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.8151 - val_loss: 6.9182\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.7738 - val_loss: 6.8523\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.3723 - val_loss: 6.7992\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.2804 - val_loss: 6.7395\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.3654 - val_loss: 6.6816\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.1566 - val_loss: 6.6225\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.1965 - val_loss: 6.5670\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.9422 - val_loss: 6.5124\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.9891 - val_loss: 6.4680\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.9019 - val_loss: 6.4265\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.8882 - val_loss: 6.3744\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.7466 - val_loss: 6.3242\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.6240 - val_loss: 6.2757\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.5082 - val_loss: 6.2312\n",
      "\n",
      "Feature shape is (178, 50)\n",
      "\n",
      "Feature test shape is (46, 50)\n",
      "\n",
      "After SMOTE feature shape is (266, 50)\n",
      "Model: \"sequential_275\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2067 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1793 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2068 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1794 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2069 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1795 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2070 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1796 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2071 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1797 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2072 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1798 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2073 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1799 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2074 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1800 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2075 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 245s 2s/step - loss: 169.7252 - val_loss: 76.0367\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 141.0092 - val_loss: 65.9224\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 120.4551 - val_loss: 58.4075\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 104.6832 - val_loss: 52.5471\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 94.0127 - val_loss: 47.9450\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 87.1460 - val_loss: 44.2078\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 78.4807 - val_loss: 41.1656\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 72.1647 - val_loss: 38.6284\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 68.1342 - val_loss: 36.4194\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 64.3424 - val_loss: 34.4653\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 60.3690 - val_loss: 32.7133\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 56.4656 - val_loss: 31.1167\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 53.8350 - val_loss: 29.6078\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 50.9669 - val_loss: 28.1863\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 48.2914 - val_loss: 26.8282\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 45.1532 - val_loss: 25.5087\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 42.9814 - val_loss: 24.2529\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 40.3179 - val_loss: 23.0183\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 37.9402 - val_loss: 21.8804\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 35.9740 - val_loss: 20.8595\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 33.7467 - val_loss: 19.9219\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 32.2268 - val_loss: 19.0590\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 30.5151 - val_loss: 18.2959\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 29.0947 - val_loss: 17.5915\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 28.0464 - val_loss: 16.9480\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 26.6044 - val_loss: 16.3486\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 25.4363 - val_loss: 15.8139\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 24.2366 - val_loss: 15.3241\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 23.6561 - val_loss: 14.8637\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 22.5910 - val_loss: 14.4223\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 21.5615 - val_loss: 14.0217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 20.7339 - val_loss: 13.6517\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 20.2407 - val_loss: 13.3157\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 19.6122 - val_loss: 12.9722\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 19.1801 - val_loss: 12.6635\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 18.4689 - val_loss: 12.3703\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 17.8121 - val_loss: 12.0984\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 17.2670 - val_loss: 11.8430\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.9538 - val_loss: 11.6009\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.4696 - val_loss: 11.3549\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 15.8841 - val_loss: 11.1287\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.3829 - val_loss: 10.9100\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 15.1740 - val_loss: 10.7128\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 14.6971 - val_loss: 10.5236\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 14.2849 - val_loss: 10.3384\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 14.1196 - val_loss: 10.1675\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 13.9742 - val_loss: 9.9976\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 13.4732 - val_loss: 9.8377\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.3142 - val_loss: 9.6920\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.1986 - val_loss: 9.5466\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.6792 - val_loss: 9.4140\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.5996 - val_loss: 9.2769\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.2304 - val_loss: 9.1495\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11.9659 - val_loss: 9.0335\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11.9460 - val_loss: 8.9183\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.7389 - val_loss: 8.8064\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.3642 - val_loss: 8.6932\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.2540 - val_loss: 8.5881\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.1113 - val_loss: 8.4939\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.8977 - val_loss: 8.3992\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.7827 - val_loss: 8.3043\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.5852 - val_loss: 8.2173\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 10.4020 - val_loss: 8.1340\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.2347 - val_loss: 8.0511\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.1894 - val_loss: 7.9718\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9.9542 - val_loss: 7.8945\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.8560 - val_loss: 7.8222\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9.6920 - val_loss: 7.7495\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.5894 - val_loss: 7.6751\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.5948 - val_loss: 7.6071\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.4243 - val_loss: 7.5449\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.1905 - val_loss: 7.4744\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9.1131 - val_loss: 7.4095\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8.9467 - val_loss: 7.3516\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8.8568 - val_loss: 7.2903\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8.8647 - val_loss: 7.2352\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.7303 - val_loss: 7.1817\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.5051 - val_loss: 7.1268\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.4207 - val_loss: 7.0751\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.3998 - val_loss: 7.0269\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.5190 - val_loss: 6.9785\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.2363 - val_loss: 6.9270\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.1837 - val_loss: 6.8768\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.0273 - val_loss: 6.8302\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.1271 - val_loss: 6.7850\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.9619 - val_loss: 6.7448\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.9951 - val_loss: 6.7005\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.8778 - val_loss: 6.6605\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.6929 - val_loss: 6.6204\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.6901 - val_loss: 6.5780\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.7178 - val_loss: 6.5420\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.6668 - val_loss: 6.5044\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.4447 - val_loss: 6.4665\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.5342 - val_loss: 6.4317\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.4392 - val_loss: 6.3966\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.3452 - val_loss: 6.3639\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.1918 - val_loss: 6.3299\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.1767 - val_loss: 6.2970\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.0982 - val_loss: 6.2638\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.0261 - val_loss: 6.2352\n",
      "Model: \"sequential_276\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2076 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1801 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2077 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1802 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2078 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1803 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2079 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1804 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2080 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1805 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2081 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1806 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2082 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1807 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2083 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1808 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2084 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 244s 2s/step - loss: 160.3421 - val_loss: 48.4113\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 137.2605 - val_loss: 44.4307\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 120.0469 - val_loss: 41.3554\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 111.8160 - val_loss: 38.9220\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 100.8955 - val_loss: 36.9366\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 96.5208 - val_loss: 35.2796\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 87.6731 - val_loss: 33.8410\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 82.0612 - val_loss: 32.6119\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 78.0614 - val_loss: 31.4940\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 74.0418 - val_loss: 30.4816\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 70.7771 - val_loss: 29.5472\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 68.6431 - val_loss: 28.6692\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 65.5336 - val_loss: 27.8033\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 62.8444 - val_loss: 26.9504\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 59.8822 - val_loss: 26.0947\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 58.1015 - val_loss: 25.2366\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 55.0599 - val_loss: 24.3491\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 52.8832 - val_loss: 23.4367\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 50.5311 - val_loss: 22.5215\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 47.8110 - val_loss: 21.5924\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 45.5871 - val_loss: 20.6686\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 43.8155 - val_loss: 19.7609\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 41.4212 - val_loss: 18.8731\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 39.4962 - val_loss: 18.0112\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 37.6324 - val_loss: 17.2125\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 35.7163 - val_loss: 16.4565\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 33.6052 - val_loss: 15.7793\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 32.1948 - val_loss: 15.1577\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 30.8632 - val_loss: 14.5948\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 29.6673 - val_loss: 14.1042\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 28.5460 - val_loss: 13.6414\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 27.5995 - val_loss: 13.2246\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 26.5096 - val_loss: 12.8535\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 25.3472 - val_loss: 12.4858\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 24.7202 - val_loss: 12.1480\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 23.6835 - val_loss: 11.8283\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 22.8748 - val_loss: 11.5182\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 22.6950 - val_loss: 11.2281\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 21.9293 - val_loss: 10.9593\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 21.4253 - val_loss: 10.7081\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 20.7104 - val_loss: 10.4645\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 20.2935 - val_loss: 10.2285\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 19.6657 - val_loss: 10.0103\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 19.1595 - val_loss: 9.7940\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 18.7377 - val_loss: 9.5914\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 18.2278 - val_loss: 9.3916\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 17.7057 - val_loss: 9.2075\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 17.4580 - val_loss: 9.0328\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.8964 - val_loss: 8.8618\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.5672 - val_loss: 8.6977\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.3012 - val_loss: 8.5349\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.0062 - val_loss: 8.3796\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.3448 - val_loss: 8.2299\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.2793 - val_loss: 8.0848\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.7067 - val_loss: 7.9532\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.4510 - val_loss: 7.8194\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.0968 - val_loss: 7.6905\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.9416 - val_loss: 7.5702\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.4827 - val_loss: 7.4518\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.4096 - val_loss: 7.3364\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.2899 - val_loss: 7.2315\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.9705 - val_loss: 7.1275\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.6919 - val_loss: 7.0282\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.4666 - val_loss: 6.9339\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.4743 - val_loss: 6.8385\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.8569 - val_loss: 6.7450\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.0603 - val_loss: 6.6553\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.7067 - val_loss: 6.5670\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.5257 - val_loss: 6.4807\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.4136 - val_loss: 6.3993\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.2706 - val_loss: 6.3204\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.0520 - val_loss: 6.2426\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.8562 - val_loss: 6.1676\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.7505 - val_loss: 6.0973\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.6125 - val_loss: 6.0276\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.4055 - val_loss: 5.9602\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.3865 - val_loss: 5.8931\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.3169 - val_loss: 5.8264\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.9763 - val_loss: 5.7632\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.0650 - val_loss: 5.7032\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.8248 - val_loss: 5.6401\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.6859 - val_loss: 5.5802\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.5181 - val_loss: 5.5242\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.2804 - val_loss: 5.4689\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.2957 - val_loss: 5.4154\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.0778 - val_loss: 5.3636\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.2698 - val_loss: 5.3105\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.8571 - val_loss: 5.2606\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.8238 - val_loss: 5.2098\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.9127 - val_loss: 5.1610\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.5860 - val_loss: 5.1118\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.6851 - val_loss: 5.0668\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.5265 - val_loss: 5.0223\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.4105 - val_loss: 4.9794\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.3763 - val_loss: 4.9355\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.3758 - val_loss: 4.8937\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.2545 - val_loss: 4.8529\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.1291 - val_loss: 4.8143\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.9783 - val_loss: 4.7764\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.9797 - val_loss: 4.7381\n",
      "['../Cli3/UTSW_Cli_224P_OrderFea_40_SMOTE_CV_it_2_10_5.mat', '../PrePost/PET_MOO/HN_MR_4_PPD_SMOTE_CV5_fea50_it_50_5.mat', '../PrePost/CT_MOO/HN_MR_4_PPD_SMOTE_CV5_fea50_val_it_50_5.mat']\n",
      "\n",
      "... Processing ../PrePost/PET_MOO/HN_MR_4_PPD_SMOTE_CV5_fea50_it_50_5 ...\n",
      "PET_feature shape is (180, 50)\n",
      "\n",
      "... Processing ../PrePost/CT_MOO/HN_MR_4_PPD_SMOTE_CV5_fea50_val_it_50_5 ...\n",
      "CT_feature shape is (180, 50)\n",
      "\n",
      "Feature shape is (180, 50)\n",
      "\n",
      "Label shape is (180, 1)\n",
      "\n",
      "Feature test shape is (44, 50)\n",
      "\n",
      "Label test shape is (44, 1)\n",
      "\n",
      "After SMOTE feature shape is (268, 50)\n",
      "Model: \"sequential_277\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2085 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1809 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2086 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1810 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2087 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1811 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2088 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1812 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2089 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1813 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2090 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1814 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2091 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1815 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2092 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1816 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2093 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 240s 2s/step - loss: 180.5425 - val_loss: 56.1320\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 147.0167 - val_loss: 49.5586\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 125.8818 - val_loss: 44.8413\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 108.3588 - val_loss: 41.3168\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 97.3864 - val_loss: 38.5442\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 87.6680 - val_loss: 36.3278\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 80.9361 - val_loss: 34.4964\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 74.4471 - val_loss: 32.9121\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 70.4248 - val_loss: 31.5307\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 66.1350 - val_loss: 30.3157\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 62.7876 - val_loss: 29.2124\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 59.4650 - val_loss: 28.2187\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 56.8966 - val_loss: 27.3042\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 54.7582 - val_loss: 26.3983\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 52.3024 - val_loss: 25.5864\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 50.3027 - val_loss: 24.7848\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 49.0287 - val_loss: 23.9735\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 46.8933 - val_loss: 23.2066\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 44.6610 - val_loss: 22.4474\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 43.2727 - val_loss: 21.7111\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 41.8234 - val_loss: 20.9742\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 39.7307 - val_loss: 20.2626\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 38.1617 - val_loss: 19.5565\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 36.9267 - val_loss: 18.8397\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 35.3382 - val_loss: 18.1331\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 33.6975 - val_loss: 17.4239\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 3ms/step - loss: 32.2113 - val_loss: 16.7258\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 30.5428 - val_loss: 16.0434\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 29.4056 - val_loss: 15.3952\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 27.9030 - val_loss: 14.7730\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 26.6860 - val_loss: 14.1717\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 25.1059 - val_loss: 13.6099\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.8302 - val_loss: 13.0822\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.1040 - val_loss: 12.5937\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.8779 - val_loss: 12.1440\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.6774 - val_loss: 11.7451\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.1880 - val_loss: 11.3823\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.6144 - val_loss: 11.0538\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.8958 - val_loss: 10.7737\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.2233 - val_loss: 10.5020\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.6725 - val_loss: 10.2580\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.1028 - val_loss: 10.0378\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.8529 - val_loss: 9.8246\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16.3652 - val_loss: 9.6255\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.6060 - val_loss: 9.4381\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.3418 - val_loss: 9.2617\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.2703 - val_loss: 9.0869\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.7570 - val_loss: 8.9238\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.4885 - val_loss: 8.7727\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.2370 - val_loss: 8.6244\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.8293 - val_loss: 8.4786\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.6397 - val_loss: 8.3445\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.4868 - val_loss: 8.2101\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.1745 - val_loss: 8.0805\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.8995 - val_loss: 7.9588\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.7129 - val_loss: 7.8424\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.4853 - val_loss: 7.7291\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.2264 - val_loss: 7.6203\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.0264 - val_loss: 7.5151\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.9121 - val_loss: 7.4106\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.7542 - val_loss: 7.3105\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.4483 - val_loss: 7.2134\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.3449 - val_loss: 7.1171\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.1302 - val_loss: 7.0256\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.8074 - val_loss: 6.9397\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.8066 - val_loss: 6.8591\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.7494 - val_loss: 6.7817\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.3122 - val_loss: 6.7014\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.3884 - val_loss: 6.6252\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.2408 - val_loss: 6.5525\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.8430 - val_loss: 6.4828\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.9108 - val_loss: 6.4110\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.8752 - val_loss: 6.3428\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.6406 - val_loss: 6.2770\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.3235 - val_loss: 6.2128\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.3855 - val_loss: 6.1483\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.2293 - val_loss: 6.0848\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.0013 - val_loss: 6.0235\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.9618 - val_loss: 5.9616\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9.0746 - val_loss: 5.9057\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.8169 - val_loss: 5.8512\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.6977 - val_loss: 5.7966\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.6227 - val_loss: 5.7415\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.5269 - val_loss: 5.6890\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.4025 - val_loss: 5.6391\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2695 - val_loss: 5.5907\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1829 - val_loss: 5.5411\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0701 - val_loss: 5.4931\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1313 - val_loss: 5.4504\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.8990 - val_loss: 5.4054\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.8312 - val_loss: 5.3629\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.8951 - val_loss: 5.3195\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.8161 - val_loss: 5.2790\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.6616 - val_loss: 5.2407\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.6267 - val_loss: 5.2027\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.5603 - val_loss: 5.1639\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.5280 - val_loss: 5.1268\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.4674 - val_loss: 5.0911\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7.3418 - val_loss: 5.0535\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.3343 - val_loss: 5.0169\n",
      "Model: \"sequential_278\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2094 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1817 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2095 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1818 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2096 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1819 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2097 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1820 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2098 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1821 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2099 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1822 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2100 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1823 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2101 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1824 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2102 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 245s 2s/step - loss: 177.4431 - val_loss: 97.9173\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 151.0833 - val_loss: 87.0660\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 133.1083 - val_loss: 78.8041\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 120.3188 - val_loss: 72.1558\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 106.6051 - val_loss: 66.9509\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 99.3790 - val_loss: 62.7595\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 90.5733 - val_loss: 59.2805\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 84.4830 - val_loss: 56.3954\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 78.8544 - val_loss: 53.9255\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 72.9178 - val_loss: 51.7114\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 70.7485 - val_loss: 49.6342\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 66.4984 - val_loss: 47.6864\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 63.9769 - val_loss: 45.8325\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 60.9337 - val_loss: 44.0504\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 57.8738 - val_loss: 42.2874\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 54.7518 - val_loss: 40.5325\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 51.9396 - val_loss: 38.8033\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 48.3420 - val_loss: 37.1175\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 46.1946 - val_loss: 35.4943\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 43.4477 - val_loss: 34.0231\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 40.7936 - val_loss: 32.6789\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 38.7095 - val_loss: 31.4756\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 36.7510 - val_loss: 30.3554\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 35.0879 - val_loss: 29.3140\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 33.5158 - val_loss: 28.3546\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 31.2595 - val_loss: 27.4775\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 29.6004 - val_loss: 26.6901\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 28.8234 - val_loss: 25.9480\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 27.5841 - val_loss: 25.2351\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 26.1313 - val_loss: 24.6071\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 25.4059 - val_loss: 24.0258\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 24.4170 - val_loss: 23.4648\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.6712 - val_loss: 22.9651\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.5233 - val_loss: 22.4837\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.9343 - val_loss: 22.0463\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.3659 - val_loss: 21.6305\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.4126 - val_loss: 21.2579\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.0186 - val_loss: 20.8925\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.6049 - val_loss: 20.5478\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.7763 - val_loss: 20.2271\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.2002 - val_loss: 19.9135\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.0366 - val_loss: 19.6137\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.0937 - val_loss: 19.3533\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.8614 - val_loss: 19.0887\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.4951 - val_loss: 18.8429\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.1962 - val_loss: 18.6067\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.6250 - val_loss: 18.3849\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.3475 - val_loss: 18.1626\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.8365 - val_loss: 17.9649\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.5209 - val_loss: 17.7800\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.3613 - val_loss: 17.5904\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.9682 - val_loss: 17.4265\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.6826 - val_loss: 17.2722\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.2675 - val_loss: 17.1128\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.1176 - val_loss: 16.9696\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.9349 - val_loss: 16.8319\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.6358 - val_loss: 16.6995\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.2553 - val_loss: 16.5771\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.1664 - val_loss: 16.4639\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.0579 - val_loss: 16.3435\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.8411 - val_loss: 16.2275\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.5535 - val_loss: 16.1279\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.2897 - val_loss: 16.0236\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.2601 - val_loss: 15.9319\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.0488 - val_loss: 15.8298\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.0287 - val_loss: 15.7326\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.6590 - val_loss: 15.6443\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.4507 - val_loss: 15.5489\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.4333 - val_loss: 15.4688\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.9723 - val_loss: 15.3876\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.9586 - val_loss: 15.3131\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.8377 - val_loss: 15.2427\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.7343 - val_loss: 15.1808\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.6056 - val_loss: 15.1113\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.4604 - val_loss: 15.0417\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.2110 - val_loss: 14.9864\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.3087 - val_loss: 14.9205\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.1315 - val_loss: 14.8557\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.0856 - val_loss: 14.7918\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.1022 - val_loss: 14.7321\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.7331 - val_loss: 14.6779\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.6646 - val_loss: 14.6290\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.6628 - val_loss: 14.5749\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.4768 - val_loss: 14.5276\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.3691 - val_loss: 14.4755\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.3065 - val_loss: 14.4300\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2097 - val_loss: 14.3726\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0620 - val_loss: 14.3241\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0092 - val_loss: 14.2745\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1279 - val_loss: 14.2242\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0607 - val_loss: 14.1818\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.8294 - val_loss: 14.1429\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.6254 - val_loss: 14.0988\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.7054 - val_loss: 14.0554\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.5569 - val_loss: 14.0134\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.5533 - val_loss: 13.9762\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.4187 - val_loss: 13.9372\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.4649 - val_loss: 13.9069\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.2886 - val_loss: 13.8757\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.2244 - val_loss: 13.8398\n",
      "\n",
      "Feature shape is (180, 50)\n",
      "\n",
      "Feature test shape is (44, 50)\n",
      "\n",
      "After SMOTE feature shape is (268, 50)\n",
      "Model: \"sequential_279\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2103 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1825 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2104 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1826 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2105 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1827 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2106 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1828 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2107 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1829 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2108 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1830 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2109 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1831 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2110 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1832 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2111 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 249s 2s/step - loss: 184.5087 - val_loss: 82.3648\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 147.5835 - val_loss: 70.3087\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 128.6177 - val_loss: 62.1300\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 110.1835 - val_loss: 56.3742\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 100.1656 - val_loss: 51.8709\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 90.7162 - val_loss: 48.3659\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 83.2597 - val_loss: 45.4635\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 76.7262 - val_loss: 43.1606\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 72.8695 - val_loss: 41.1831\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 68.0843 - val_loss: 39.4282\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 64.9319 - val_loss: 37.8238\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 63.5927 - val_loss: 36.4363\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 60.6670 - val_loss: 35.0512\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 58.5691 - val_loss: 33.7993\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 56.1275 - val_loss: 32.6342\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 52.5501 - val_loss: 31.5179\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 52.2887 - val_loss: 30.4668\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 49.5601 - val_loss: 29.4317\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 48.4172 - val_loss: 28.4023\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 46.6029 - val_loss: 27.3993\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 43.6747 - val_loss: 26.3930\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 42.0435 - val_loss: 25.4040\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 41.2618 - val_loss: 24.4035\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 39.0075 - val_loss: 23.4152\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 36.9640 - val_loss: 22.4402\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 34.8033 - val_loss: 21.5176\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 33.5355 - val_loss: 20.6468\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 32.8160 - val_loss: 19.8205\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 30.8657 - val_loss: 19.0540\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 29.4896 - val_loss: 18.3183\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 3ms/step - loss: 28.6447 - val_loss: 17.6626\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 27.5527 - val_loss: 17.0356\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 25.6865 - val_loss: 16.4547\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 25.2300 - val_loss: 15.9039\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.9536 - val_loss: 15.4242\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.2434 - val_loss: 14.9695\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.1059 - val_loss: 14.5405\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.8380 - val_loss: 14.1563\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.5135 - val_loss: 13.7780\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.5429 - val_loss: 13.4204\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.0212 - val_loss: 13.0999\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 19.4351 - val_loss: 12.7802\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 18.7768 - val_loss: 12.4747\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.2778 - val_loss: 12.1941\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.0670 - val_loss: 11.9399\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.2155 - val_loss: 11.6899\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 16.7938 - val_loss: 11.4465\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.5136 - val_loss: 11.2178\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.2295 - val_loss: 10.9910\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.8917 - val_loss: 10.7636\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.4216 - val_loss: 10.5600\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.2093 - val_loss: 10.3495\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.6345 - val_loss: 10.1618\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.3316 - val_loss: 9.9780\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.0941 - val_loss: 9.7986\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.5506 - val_loss: 9.6309\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.6265 - val_loss: 9.4741\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.3059 - val_loss: 9.3147\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.8818 - val_loss: 9.1615\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.6150 - val_loss: 9.0186\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.5872 - val_loss: 8.8837\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12.3019 - val_loss: 8.7516\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.0863 - val_loss: 8.6293\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.8268 - val_loss: 8.4955\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.5646 - val_loss: 8.3731\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.5736 - val_loss: 8.2558\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.3334 - val_loss: 8.1421\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.0522 - val_loss: 8.0269\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.9287 - val_loss: 7.9240\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.9306 - val_loss: 7.8216\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.5997 - val_loss: 7.7219\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.3958 - val_loss: 7.6271\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.3861 - val_loss: 7.5320\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.0476 - val_loss: 7.4468\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.2199 - val_loss: 7.3585\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.8747 - val_loss: 7.2715\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.6788 - val_loss: 7.1897\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.6433 - val_loss: 7.1156\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.6172 - val_loss: 7.0376\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.3878 - val_loss: 6.9596\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.3201 - val_loss: 6.8870\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.1461 - val_loss: 6.8218\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.1337 - val_loss: 6.7477\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.0766 - val_loss: 6.6769\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.0011 - val_loss: 6.6142\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.9093 - val_loss: 6.5521\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.8122 - val_loss: 6.4927\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.6145 - val_loss: 6.4361\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.5110 - val_loss: 6.3798\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.4772 - val_loss: 6.3264\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2966 - val_loss: 6.2725\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2956 - val_loss: 6.2179\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0818 - val_loss: 6.1616\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0264 - val_loss: 6.1108\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.8921 - val_loss: 6.0612\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.8901 - val_loss: 6.0121\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.8962 - val_loss: 5.9670\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.5803 - val_loss: 5.9224\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.6954 - val_loss: 5.8790\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.5559 - val_loss: 5.8391\n",
      "Model: \"sequential_280\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2112 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1833 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2113 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1834 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2114 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1835 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2115 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1836 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2116 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1837 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2117 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1838 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2118 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1839 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2119 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1840 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2120 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 253s 2s/step - loss: 193.5336 - val_loss: 74.6187\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 162.9639 - val_loss: 66.8657\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 143.7556 - val_loss: 60.5719\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 126.7880 - val_loss: 55.5470\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 117.3817 - val_loss: 51.3507\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 105.1273 - val_loss: 47.9475\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 96.6799 - val_loss: 45.0663\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 90.4142 - val_loss: 42.6059\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 84.9441 - val_loss: 40.4432\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 79.6867 - val_loss: 38.5443\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 76.2503 - val_loss: 36.7936\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 71.7973 - val_loss: 35.2446\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 68.5216 - val_loss: 33.7702\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 66.0326 - val_loss: 32.3965\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 62.9926 - val_loss: 31.0706\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 59.4759 - val_loss: 29.8269\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 56.8217 - val_loss: 28.6604\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 54.6444 - val_loss: 27.4765\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 52.2263 - val_loss: 26.3131\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 49.4945 - val_loss: 25.1678\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 47.1097 - val_loss: 24.0056\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 44.8780 - val_loss: 22.8651\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 42.4501 - val_loss: 21.7556\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 39.8022 - val_loss: 20.6859\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 37.9060 - val_loss: 19.6712\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 35.6904 - val_loss: 18.7522\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 34.0206 - val_loss: 17.9439\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 32.7911 - val_loss: 17.2425\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 31.1689 - val_loss: 16.6393\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 30.0508 - val_loss: 16.0790\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 28.8521 - val_loss: 15.5529\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 27.7176 - val_loss: 15.0677\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 26.7885 - val_loss: 14.6276\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 25.5185 - val_loss: 14.2001\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 24.8900 - val_loss: 13.7976\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 24.2502 - val_loss: 13.4192\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 23.3289 - val_loss: 13.0668\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 22.6837 - val_loss: 12.7382\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 22.1881 - val_loss: 12.4182\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 21.4308 - val_loss: 12.1139\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 20.9745 - val_loss: 11.8365\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.0791 - val_loss: 11.5566\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.8823 - val_loss: 11.2910\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.9962 - val_loss: 11.0366\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.6948 - val_loss: 10.7908\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.8246 - val_loss: 10.5672\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 17.5433 - val_loss: 10.3489\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.3524 - val_loss: 10.1357\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.7466 - val_loss: 9.9332\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.4341 - val_loss: 9.7325\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.8089 - val_loss: 9.5374\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.4827 - val_loss: 9.3503\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.3261 - val_loss: 9.1722\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.0617 - val_loss: 9.0026\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.5466 - val_loss: 8.8356\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.4463 - val_loss: 8.6764\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.0672 - val_loss: 8.5170\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.8104 - val_loss: 8.3698\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.5660 - val_loss: 8.2287\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.2441 - val_loss: 8.0943\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.8703 - val_loss: 7.9599\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.8164 - val_loss: 7.8308\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.2707 - val_loss: 7.7047\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.1189 - val_loss: 7.5794\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.0485 - val_loss: 7.4588\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.7718 - val_loss: 7.3442\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.6290 - val_loss: 7.2344\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.4030 - val_loss: 7.1287\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.2514 - val_loss: 7.0268\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.0102 - val_loss: 6.9227\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.0524 - val_loss: 6.8243\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.6763 - val_loss: 6.7300\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.5726 - val_loss: 6.6351\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.2265 - val_loss: 6.5446\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.2304 - val_loss: 6.4569\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.0154 - val_loss: 6.3698\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.8604 - val_loss: 6.2889\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.7361 - val_loss: 6.2105\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.5728 - val_loss: 6.1315\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.3074 - val_loss: 6.0543\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.4254 - val_loss: 5.9773\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.3100 - val_loss: 5.9052\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.0962 - val_loss: 5.8403\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.0263 - val_loss: 5.7743\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.8738 - val_loss: 5.7070\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.7825 - val_loss: 5.6456\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.6168 - val_loss: 5.5823\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.5618 - val_loss: 5.5203\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.3140 - val_loss: 5.4580\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.3629 - val_loss: 5.3996\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1236 - val_loss: 5.3430\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0444 - val_loss: 5.2901\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0090 - val_loss: 5.2355\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.9983 - val_loss: 5.1839\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.6101 - val_loss: 5.1317\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.7208 - val_loss: 5.0815\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.5397 - val_loss: 5.0362\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.5714 - val_loss: 4.9896\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.4246 - val_loss: 4.9452\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.4376 - val_loss: 4.9010\n",
      "['../Cli3/UTSW_Cli_224P_OrderFea_50_SMOTE_CV_it_2_10_1.mat', '../PrePost/PET_MOO/HN_MR_5_PPD_SMOTE_CV5_fea50_it_50_1.mat', '../PrePost/CT_MOO/HN_MR_5_PPD_SMOTE_CV5_fea50_val_it_50_1.mat']\n",
      "\n",
      "... Processing ../PrePost/PET_MOO/HN_MR_5_PPD_SMOTE_CV5_fea50_it_50_1 ...\n",
      "PET_feature shape is (180, 50)\n",
      "\n",
      "... Processing ../PrePost/CT_MOO/HN_MR_5_PPD_SMOTE_CV5_fea50_val_it_50_1 ...\n",
      "CT_feature shape is (180, 50)\n",
      "\n",
      "Feature shape is (180, 50)\n",
      "\n",
      "Label shape is (180, 1)\n",
      "\n",
      "Feature test shape is (44, 50)\n",
      "\n",
      "Label test shape is (44, 1)\n",
      "\n",
      "After SMOTE feature shape is (268, 50)\n",
      "Model: \"sequential_281\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2121 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1841 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2122 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1842 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2123 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1843 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2124 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1844 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2125 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1845 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2126 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1846 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2127 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1847 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2128 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1848 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2129 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 245s 2s/step - loss: 197.2767 - val_loss: 57.8711\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 160.6632 - val_loss: 50.8121\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 137.4567 - val_loss: 45.8720\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 122.9901 - val_loss: 42.2140\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 110.8185 - val_loss: 39.4298\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 101.4612 - val_loss: 37.2137\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 92.4160 - val_loss: 35.2776\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 86.7788 - val_loss: 33.6544\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 81.0581 - val_loss: 32.2569\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 75.5761 - val_loss: 31.0566\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 72.3470 - val_loss: 29.9667\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 68.4045 - val_loss: 28.9998\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 65.4400 - val_loss: 28.1041\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 62.7954 - val_loss: 27.2399\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 59.7199 - val_loss: 26.4645\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 57.7024 - val_loss: 25.7070\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 55.4944 - val_loss: 25.0330\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 53.5462 - val_loss: 24.3592\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 51.7353 - val_loss: 23.7470\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 49.7810 - val_loss: 23.1083\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 48.2985 - val_loss: 22.5189\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 46.9178 - val_loss: 21.9287\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 45.3366 - val_loss: 21.3920\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 43.5020 - val_loss: 20.8278\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 42.1164 - val_loss: 20.2690\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 40.5469 - val_loss: 19.6867\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 3ms/step - loss: 39.6747 - val_loss: 19.1488\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 38.1575 - val_loss: 18.6082\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 36.5511 - val_loss: 18.0604\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 35.2662 - val_loss: 17.5219\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 34.2360 - val_loss: 16.9828\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 32.4558 - val_loss: 16.4579\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 31.6291 - val_loss: 15.9369\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 30.5443 - val_loss: 15.4303\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 29.2403 - val_loss: 14.9148\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 28.1326 - val_loss: 14.3926\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 27.1771 - val_loss: 13.8889\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 25.6121 - val_loss: 13.3954\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 25.1246 - val_loss: 12.9294\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.7205 - val_loss: 12.4681\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.7338 - val_loss: 12.0275\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.3559 - val_loss: 11.6006\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.9030 - val_loss: 11.1746\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.5176 - val_loss: 10.8081\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.3339 - val_loss: 10.4589\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.6610 - val_loss: 10.1274\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.7151 - val_loss: 9.8321\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.3466 - val_loss: 9.5469\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.9899 - val_loss: 9.2937\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.5888 - val_loss: 9.0560\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.8498 - val_loss: 8.8344\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.5031 - val_loss: 8.6290\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.1407 - val_loss: 8.4374\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.6744 - val_loss: 8.2584\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.5135 - val_loss: 8.0957\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.0692 - val_loss: 7.9532\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.7618 - val_loss: 7.8227\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.3310 - val_loss: 7.6916\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.0060 - val_loss: 7.5693\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.8429 - val_loss: 7.4549\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.6623 - val_loss: 7.3460\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.5199 - val_loss: 7.2306\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.2975 - val_loss: 7.1172\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.0604 - val_loss: 7.0163\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.7685 - val_loss: 6.9165\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.7510 - val_loss: 6.8303\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.5340 - val_loss: 6.7394\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.2934 - val_loss: 6.6475\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.2082 - val_loss: 6.5622\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.0667 - val_loss: 6.4782\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.9555 - val_loss: 6.3996\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.8348 - val_loss: 6.3246\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.5212 - val_loss: 6.2502\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.3719 - val_loss: 6.1778\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.1497 - val_loss: 6.1080\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.0697 - val_loss: 6.0357\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.9988 - val_loss: 5.9686\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.8713 - val_loss: 5.9028\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.7086 - val_loss: 5.8386\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.7498 - val_loss: 5.7759\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.4275 - val_loss: 5.7220\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.1730 - val_loss: 5.6655\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.4498 - val_loss: 5.6065\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.9948 - val_loss: 5.5485\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.8956 - val_loss: 5.4933\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.9528 - val_loss: 5.4402\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.0357 - val_loss: 5.3902\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.9965 - val_loss: 5.3357\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.7678 - val_loss: 5.2868\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.6642 - val_loss: 5.2381\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.3808 - val_loss: 5.1908\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2289 - val_loss: 5.1476\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.4211 - val_loss: 5.1025\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1525 - val_loss: 5.0592\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.4430 - val_loss: 5.0156\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0662 - val_loss: 4.9711\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0949 - val_loss: 4.9332\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0949 - val_loss: 4.8944\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1255 - val_loss: 4.8534\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.8746 - val_loss: 4.8150\n",
      "Model: \"sequential_282\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2130 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1849 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2131 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1850 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2132 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1851 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2133 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1852 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2134 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1853 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2135 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1854 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2136 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1855 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2137 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1856 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2138 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 247s 2s/step - loss: 199.1671 - val_loss: 93.8726\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 165.6607 - val_loss: 80.6890\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 142.7152 - val_loss: 71.1012\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 123.9885 - val_loss: 63.56409\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 109.5368 - val_loss: 57.8449\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 101.2231 - val_loss: 53.2053\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 92.9805 - val_loss: 49.4742\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 86.2745 - val_loss: 46.4074\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 78.9070 - val_loss: 43.7209\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 77.1981 - val_loss: 41.4156\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 72.7140 - val_loss: 39.3916\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 70.2831 - val_loss: 37.5295\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 65.4531 - val_loss: 35.8359\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 63.0239 - val_loss: 34.3123\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 59.9142 - val_loss: 32.9272\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 58.4644 - val_loss: 31.6250\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 54.8489 - val_loss: 30.3856\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 53.6868 - val_loss: 29.2465\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 51.3838 - val_loss: 28.1179\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 50.2821 - val_loss: 27.0559\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 46.3911 - val_loss: 25.9694\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 45.9699 - val_loss: 24.9254\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 43.1171 - val_loss: 23.9081\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 41.4132 - val_loss: 22.9159\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 39.4294 - val_loss: 21.9460\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 37.4961 - val_loss: 21.0152\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 35.4954 - val_loss: 20.1211\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 34.1293 - val_loss: 19.2925\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 31.9553 - val_loss: 18.5365\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 31.4727 - val_loss: 17.8446\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 29.7982 - val_loss: 17.2345\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 28.8612 - val_loss: 16.6797\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 27.5884 - val_loss: 16.1601\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 27.0609 - val_loss: 15.6835\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 25.8163 - val_loss: 15.2425\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 24.4387 - val_loss: 14.8178\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 24.1995 - val_loss: 14.4283\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.2065 - val_loss: 14.0440\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.0482 - val_loss: 13.6755\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.9307 - val_loss: 13.3487\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.4854 - val_loss: 13.0347\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.4595 - val_loss: 12.7273\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.7212 - val_loss: 12.4524\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.5665 - val_loss: 12.1887\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.1913 - val_loss: 11.9375\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.2491 - val_loss: 11.6877\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.7895 - val_loss: 11.4509\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.5414 - val_loss: 11.2285\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.2909 - val_loss: 11.0183\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.8391 - val_loss: 10.8130\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.3879 - val_loss: 10.6112\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.0663 - val_loss: 10.4202\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.6083 - val_loss: 10.2368\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.3905 - val_loss: 10.0607\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.8767 - val_loss: 9.8946\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.7412 - val_loss: 9.7165\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.2372 - val_loss: 9.5499\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.7854 - val_loss: 9.4012\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.7120 - val_loss: 9.2511\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.5672 - val_loss: 9.1090\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.1600 - val_loss: 8.9763\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.0683 - val_loss: 8.8393\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.9402 - val_loss: 8.7161\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.5030 - val_loss: 8.5898\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.2871 - val_loss: 8.4674\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.9973 - val_loss: 8.3521\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.8841 - val_loss: 8.2358\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.6309 - val_loss: 8.1285\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.5445 - val_loss: 8.0257\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.1967 - val_loss: 7.9257\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.0845 - val_loss: 7.8227\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.9065 - val_loss: 7.7281\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.8494 - val_loss: 7.6388\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.6886 - val_loss: 7.5490\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.3050 - val_loss: 7.4587\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.2939 - val_loss: 7.3719\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.2806 - val_loss: 7.2889\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.1398 - val_loss: 7.2029\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.8439 - val_loss: 7.1223\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.5485 - val_loss: 7.0496\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.6125 - val_loss: 6.9737\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.5520 - val_loss: 6.9041\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.3302 - val_loss: 6.8348\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.4456 - val_loss: 6.7702\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.1007 - val_loss: 6.7012\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.0308 - val_loss: 6.6385\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.9598 - val_loss: 6.5732\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.9172 - val_loss: 6.5114\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.6907 - val_loss: 6.4511\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.7154 - val_loss: 6.3904\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.4748 - val_loss: 6.3329\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8.4076 - val_loss: 6.2791\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.4802 - val_loss: 6.2324\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1576 - val_loss: 6.1740\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1724 - val_loss: 6.1224\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0621 - val_loss: 6.0740\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.8147 - val_loss: 6.0201\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.8642 - val_loss: 5.9747\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.7863 - val_loss: 5.9268\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.6746 - val_loss: 5.8811\n",
      "\n",
      "Feature shape is (180, 50)\n",
      "\n",
      "Feature test shape is (44, 50)\n",
      "\n",
      "After SMOTE feature shape is (268, 50)\n",
      "Model: \"sequential_283\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2139 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1857 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2140 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1858 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2141 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1859 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2142 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1860 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2143 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1861 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2144 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1862 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2145 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1863 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2146 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1864 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2147 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 252s 2s/step - loss: 193.3839 - val_loss: 87.9311\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 153.0161 - val_loss: 76.3334\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 131.4176 - val_loss: 67.6204\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 115.4046 - val_loss: 61.0105\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 101.5253 - val_loss: 56.0694\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 93.9935 - val_loss: 52.1193\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 86.3360 - val_loss: 49.0254\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 80.2082 - val_loss: 46.5215\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 73.3151 - val_loss: 44.4860\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 69.8283 - val_loss: 42.7759\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 65.2896 - val_loss: 41.3043\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 62.6146 - val_loss: 40.0049\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 59.8030 - val_loss: 38.8568\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 56.7380 - val_loss: 37.7835\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 54.0625 - val_loss: 36.7783\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 52.3333 - val_loss: 35.8223\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 49.6541 - val_loss: 34.9173\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 47.8743 - val_loss: 34.0458\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 46.2553 - val_loss: 33.2099\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 44.3676 - val_loss: 32.3612\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 42.6234 - val_loss: 31.5213\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 40.6031 - val_loss: 30.7012\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 38.7331 - val_loss: 29.9072\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 37.0798 - val_loss: 29.1068\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 35.0556 - val_loss: 28.3100\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 33.7833 - val_loss: 27.5020\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 31.4708 - val_loss: 26.7158\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 29.8649 - val_loss: 25.9226\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 28.2430 - val_loss: 25.2002\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 27.0155 - val_loss: 24.5675\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 25.7977 - val_loss: 23.9913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 24.4844 - val_loss: 23.4895\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.1603 - val_loss: 23.0378\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.4785 - val_loss: 22.6226\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.7473 - val_loss: 22.2559\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.0231 - val_loss: 21.9183\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.3774 - val_loss: 21.6087\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.6973 - val_loss: 21.3164\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.2109 - val_loss: 21.0375\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.7299 - val_loss: 20.7668\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.0521 - val_loss: 20.5128\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.4583 - val_loss: 20.2641\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.6814 - val_loss: 20.0258\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.3416 - val_loss: 19.8040\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.2792 - val_loss: 19.5746\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.6146 - val_loss: 19.3791\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.7189 - val_loss: 19.1658\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.9595 - val_loss: 18.9721\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.7138 - val_loss: 18.7820\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.2857 - val_loss: 18.5904\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.8268 - val_loss: 18.4205\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.5382 - val_loss: 18.2651\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 13.2735 - val_loss: 18.1150\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.0458 - val_loss: 17.9719\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.6569 - val_loss: 17.8440\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 12.3844 - val_loss: 17.7183\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.3592 - val_loss: 17.5981\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.2036 - val_loss: 17.4694\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.1627 - val_loss: 17.3493\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.7083 - val_loss: 17.2318\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.4725 - val_loss: 17.1144\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.3187 - val_loss: 16.9988\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.1499 - val_loss: 16.8877\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.8481 - val_loss: 16.7700\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.8727 - val_loss: 16.6774\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.6101 - val_loss: 16.5765\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.4143 - val_loss: 16.4812\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.1081 - val_loss: 16.3785\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.2582 - val_loss: 16.2816\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.9610 - val_loss: 16.1968\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.9472 - val_loss: 16.1042\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.6361 - val_loss: 16.0183\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.6230 - val_loss: 15.9371\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.4984 - val_loss: 15.8642\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.3971 - val_loss: 15.7758\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.2344 - val_loss: 15.7038\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 9.0800 - val_loss: 15.6317\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.9804 - val_loss: 15.5476\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.9330 - val_loss: 15.4572\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.8015 - val_loss: 15.3835\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.8281 - val_loss: 15.3035\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.4854 - val_loss: 15.2366\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.6013 - val_loss: 15.1763\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2536 - val_loss: 15.1090\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2214 - val_loss: 15.0536\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2722 - val_loss: 14.9931\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1013 - val_loss: 14.9258\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.9928 - val_loss: 14.8626\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.9308 - val_loss: 14.7929\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.7713 - val_loss: 14.7324\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.7853 - val_loss: 14.6755\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.7197 - val_loss: 14.6156\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7.6440 - val_loss: 14.5600\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7.5510 - val_loss: 14.4905\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.4095 - val_loss: 14.4434\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.3480 - val_loss: 14.3911\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.3937 - val_loss: 14.3367\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.3690 - val_loss: 14.2825\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.1974 - val_loss: 14.2293\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.0956 - val_loss: 14.1814\n",
      "Model: \"sequential_284\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2148 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1865 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2149 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1866 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2150 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1867 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2151 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1868 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2152 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1869 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2153 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1870 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2154 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1871 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2155 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1872 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2156 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 263s 2s/step - loss: 192.6424 - val_loss: 72.5048\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 160.1537 - val_loss: 64.6622\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 141.0112 - val_loss: 58.7605\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 123.4094 - val_loss: 54.2833\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 113.4292 - val_loss: 50.6965\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 106.5365 - val_loss: 47.7465\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 97.1035 - val_loss: 45.2579\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 91.8232 - val_loss: 43.1681\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 86.5477 - val_loss: 41.3230\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 79.6313 - val_loss: 39.7003\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 77.4411 - val_loss: 38.2336\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 73.9419 - val_loss: 36.9118\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 70.2331 - val_loss: 35.6780\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 67.7644 - val_loss: 34.5185\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 64.8998 - val_loss: 33.4089\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 61.8547 - val_loss: 32.3510\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 59.0784 - val_loss: 31.3051\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 56.6106 - val_loss: 30.2953\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 54.1491 - val_loss: 29.2873\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 52.2752 - val_loss: 28.2969\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 49.8832 - val_loss: 27.3108\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 47.4813 - val_loss: 26.3309\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 44.8280 - val_loss: 25.3519\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 43.3407 - val_loss: 24.3936\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 41.5751 - val_loss: 23.4607\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 39.0572 - val_loss: 22.5468\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 37.0822 - val_loss: 21.6835\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 35.4469 - val_loss: 20.8539\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 33.8388 - val_loss: 20.0845\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 32.2107 - val_loss: 19.3715\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 31.0419 - val_loss: 18.7285\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 29.4410 - val_loss: 18.1314\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 28.2091 - val_loss: 17.6042\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 26.7427 - val_loss: 17.1179\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 26.1304 - val_loss: 16.6780\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 25.5421 - val_loss: 16.2631\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 24.4748 - val_loss: 15.8706\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.7375 - val_loss: 15.5040\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.1588 - val_loss: 15.1535\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.0896 - val_loss: 14.8219\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.7555 - val_loss: 14.5130\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.0882 - val_loss: 14.2097\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.5133 - val_loss: 13.9267\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.0918 - val_loss: 13.6517\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.4362 - val_loss: 13.3943\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.8536 - val_loss: 13.1450\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.6476 - val_loss: 12.9058\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.2046 - val_loss: 12.6715\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.7593 - val_loss: 12.4473\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.1768 - val_loss: 12.2264\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.7993 - val_loss: 12.0193\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.4903 - val_loss: 11.8200\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 16.2616 - val_loss: 11.6290\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.6612 - val_loss: 11.4461\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.4996 - val_loss: 11.2766\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.1271 - val_loss: 11.1039\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.8602 - val_loss: 10.9366\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.8141 - val_loss: 10.7768\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.5613 - val_loss: 10.6174\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.9703 - val_loss: 10.4655\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 13.7314 - val_loss: 10.3184\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 13.3785 - val_loss: 10.1840\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.2791 - val_loss: 10.0478\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.0362 - val_loss: 9.9148\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.8504 - val_loss: 9.7837\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.5113 - val_loss: 9.6629\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 12.3487 - val_loss: 9.5447\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.1664 - val_loss: 9.4244\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.0613 - val_loss: 9.3094\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 11.8762 - val_loss: 9.1936\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.7259 - val_loss: 9.0840\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.3393 - val_loss: 8.9814\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 11.3364 - val_loss: 8.8779\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.0827 - val_loss: 8.7805\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.9222 - val_loss: 8.6855\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.6759 - val_loss: 8.5900\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.5190 - val_loss: 8.4976\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.4859 - val_loss: 8.4127\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.2241 - val_loss: 8.3267\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.1496 - val_loss: 8.2435\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.1725 - val_loss: 8.1628\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.9357 - val_loss: 8.0829\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.8702 - val_loss: 8.0034\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.7199 - val_loss: 7.9250\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.5121 - val_loss: 7.8532\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.5148 - val_loss: 7.7795\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.4891 - val_loss: 7.7055\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.4122 - val_loss: 7.6362\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.2230 - val_loss: 7.5674\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.0449 - val_loss: 7.4988\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.9566 - val_loss: 7.4331\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.0107 - val_loss: 7.3677\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.7349 - val_loss: 7.3010\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.5247 - val_loss: 7.2394\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.7354 - val_loss: 7.1799\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.5167 - val_loss: 7.1224\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.3647 - val_loss: 7.0676\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.4174 - val_loss: 7.0100\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2216 - val_loss: 6.9543\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1117 - val_loss: 6.9007\n",
      "['../Cli3/UTSW_Cli_224P_OrderFea_50_SMOTE_CV_it_2_10_2.mat', '../PrePost/PET_MOO/HN_MR_5_PPD_SMOTE_CV5_fea50_it_50_2.mat', '../PrePost/CT_MOO/HN_MR_5_PPD_SMOTE_CV5_fea50_val_it_50_2.mat']\n",
      "\n",
      "... Processing ../PrePost/PET_MOO/HN_MR_5_PPD_SMOTE_CV5_fea50_it_50_2 ...\n",
      "PET_feature shape is (180, 50)\n",
      "\n",
      "... Processing ../PrePost/CT_MOO/HN_MR_5_PPD_SMOTE_CV5_fea50_val_it_50_2 ...\n",
      "CT_feature shape is (180, 50)\n",
      "\n",
      "Feature shape is (180, 50)\n",
      "\n",
      "Label shape is (180, 1)\n",
      "\n",
      "Feature test shape is (44, 50)\n",
      "\n",
      "Label test shape is (44, 1)\n",
      "\n",
      "After SMOTE feature shape is (268, 50)\n",
      "Model: \"sequential_285\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2157 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1873 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2158 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1874 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2159 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1875 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2160 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1876 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2161 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1877 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2162 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1878 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2163 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1879 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2164 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1880 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2165 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 251s 2s/step - loss: 199.0571 - val_loss: 74.9551\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 156.8484 - val_loss: 64.5059\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 138.2520 - val_loss: 56.6315\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 119.0979 - val_loss: 50.7817\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 107.4627 - val_loss: 46.1186\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 95.2032 - val_loss: 42.4912\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 89.4623 - val_loss: 39.5160\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 81.2650 - val_loss: 37.0350\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 77.3425 - val_loss: 34.9285\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 72.7895 - val_loss: 33.1380\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 69.3179 - val_loss: 31.5415\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 64.7672 - val_loss: 30.0792\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 61.8651 - val_loss: 28.7761\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 59.3730 - val_loss: 27.5268\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 56.5029 - val_loss: 26.3605\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 54.3279 - val_loss: 25.2596\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 51.9246 - val_loss: 24.1969\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 49.3436 - val_loss: 23.1755\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 47.1760 - val_loss: 22.2078\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 45.1556 - val_loss: 21.2512\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 42.7334 - val_loss: 20.2950\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 41.2833 - val_loss: 19.3432\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 39.3786 - val_loss: 18.3948\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 37.4581 - val_loss: 17.4722\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 34.8508 - val_loss: 16.5683\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 33.6653 - val_loss: 15.6875\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 3ms/step - loss: 31.4863 - val_loss: 14.8599\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 29.7338 - val_loss: 14.0883\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 28.6291 - val_loss: 13.3793\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 27.6745 - val_loss: 12.7275\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 25.7743 - val_loss: 12.1603\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 24.8479 - val_loss: 11.6482\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.7589 - val_loss: 11.1908\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.5696 - val_loss: 10.7743\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.8405 - val_loss: 10.4133\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.2787 - val_loss: 10.0739\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.7701 - val_loss: 9.7642\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.8603 - val_loss: 9.4688\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.3388 - val_loss: 9.1999\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.5085 - val_loss: 8.9437\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.9229 - val_loss: 8.7068\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.4381 - val_loss: 8.4865\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.0094 - val_loss: 8.2779\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.9349 - val_loss: 8.0905\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.3625 - val_loss: 7.9095\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.8272 - val_loss: 7.7269\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.7119 - val_loss: 7.5579\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.2206 - val_loss: 7.3994\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.7706 - val_loss: 7.2449\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.2634 - val_loss: 7.1006\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.0404 - val_loss: 6.9560\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.8189 - val_loss: 6.8280\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.7359 - val_loss: 6.6988\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.3040 - val_loss: 6.5859\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.0634 - val_loss: 6.4771\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.7777 - val_loss: 6.3673\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.6534 - val_loss: 6.2651\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.2401 - val_loss: 6.1642\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.1409 - val_loss: 6.0685\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.8030 - val_loss: 5.9823\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.5852 - val_loss: 5.8944\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.4826 - val_loss: 5.8138\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.2277 - val_loss: 5.7302\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.1125 - val_loss: 5.6544\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.1204 - val_loss: 5.5781\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.7070 - val_loss: 5.5069\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.6660 - val_loss: 5.4372\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.6148 - val_loss: 5.3702\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.3534 - val_loss: 5.3069\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.1880 - val_loss: 5.2439\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.9001 - val_loss: 5.1849\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.9804 - val_loss: 5.1262\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.7119 - val_loss: 5.0711\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.6046 - val_loss: 5.0169\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.4669 - val_loss: 4.9645\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.4333 - val_loss: 4.9137\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.1763 - val_loss: 4.8661\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.1836 - val_loss: 4.8201\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.0778 - val_loss: 4.7744\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.0078 - val_loss: 4.7294\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.7927 - val_loss: 4.6862\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.6608 - val_loss: 4.6456\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8.6002 - val_loss: 4.6050\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8.4565 - val_loss: 4.5648\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8.3950 - val_loss: 4.5253\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1724 - val_loss: 4.4894\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8.3407 - val_loss: 4.4548\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8.2350 - val_loss: 4.4205\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.9382 - val_loss: 4.3856\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0072 - val_loss: 4.3512\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.8894 - val_loss: 4.3186\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.8559 - val_loss: 4.2860\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7.8149 - val_loss: 4.2556\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.7544 - val_loss: 4.2255\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7.8159 - val_loss: 4.1965\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7.4888 - val_loss: 4.1681\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7.4159 - val_loss: 4.1394\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7.4270 - val_loss: 4.1123\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7.3296 - val_loss: 4.0854\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7.4014 - val_loss: 4.0596\n",
      "Model: \"sequential_286\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2166 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1881 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2167 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1882 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2168 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1883 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2169 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1884 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2170 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1885 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2171 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1886 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2172 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1887 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2173 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1888 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2174 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 255s 2s/step - loss: 219.1548 - val_loss: 75.0122\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 181.8182 - val_loss: 66.5065\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 155.1439 - val_loss: 60.2982\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 137.3080 - val_loss: 55.6204\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 123.1364 - val_loss: 51.9514\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 111.5839 - val_loss: 48.9372\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 105.0698 - val_loss: 46.3273\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 98.0407 - val_loss: 44.1523\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 92.5162 - val_loss: 42.2261\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 88.7312 - val_loss: 40.4988\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 82.2261 - val_loss: 38.9892\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 78.6856 - val_loss: 37.5837\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 74.8238 - val_loss: 36.3248\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 72.3931 - val_loss: 35.1301\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 68.7313 - val_loss: 33.9873\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 66.7843 - val_loss: 32.9154\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 63.7725 - val_loss: 31.8642\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 60.8368 - val_loss: 30.8145\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 58.6684 - val_loss: 29.8081\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 56.4008 - val_loss: 28.8265\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 54.0056 - val_loss: 27.8494\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 51.9037 - val_loss: 26.8641\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 49.1544 - val_loss: 25.8564\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 47.0046 - val_loss: 24.8353\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 44.9289 - val_loss: 23.8074\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 43.2234 - val_loss: 22.8252\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 41.0246 - val_loss: 21.8781\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 38.8405 - val_loss: 20.9787\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 37.1006 - val_loss: 20.1219\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 35.1261 - val_loss: 19.3288\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 33.5046 - val_loss: 18.6134\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 32.2576 - val_loss: 17.9679\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 30.8905 - val_loss: 17.3684\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 29.4722 - val_loss: 16.8259\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 28.5482 - val_loss: 16.3308\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 27.6766 - val_loss: 15.8602\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 26.5400 - val_loss: 15.4274\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 25.8135 - val_loss: 15.0129\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 25.2671 - val_loss: 14.6097\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.8580 - val_loss: 14.2354\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.2594 - val_loss: 13.8692\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.8877 - val_loss: 13.5149\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.8701 - val_loss: 13.1954\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.3197 - val_loss: 12.8858\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.6048 - val_loss: 12.5970\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.3200 - val_loss: 12.3123\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.5092 - val_loss: 12.0510\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.1741 - val_loss: 11.8003\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.5193 - val_loss: 11.5449\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.0089 - val_loss: 11.3188\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.6493 - val_loss: 11.0928\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.2753 - val_loss: 10.8717\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.8307 - val_loss: 10.6550\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.3721 - val_loss: 10.4595\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.2005 - val_loss: 10.2571\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.7771 - val_loss: 10.0507\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.4369 - val_loss: 9.8670\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.2507 - val_loss: 9.6864\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.8220 - val_loss: 9.5128\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.4509 - val_loss: 9.3447\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.0904 - val_loss: 9.1890\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.9674 - val_loss: 9.0352\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.9726 - val_loss: 8.8913\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.4518 - val_loss: 8.7463\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.3174 - val_loss: 8.5950\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.1189 - val_loss: 8.4532\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.7733 - val_loss: 8.3169\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.5472 - val_loss: 8.1856\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.4543 - val_loss: 8.0596\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.2346 - val_loss: 7.9342\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.8991 - val_loss: 7.8206\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.7289 - val_loss: 7.7073\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.4389 - val_loss: 7.5941\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.4933 - val_loss: 7.4781\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.1410 - val_loss: 7.3703\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.8467 - val_loss: 7.2600\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.8537 - val_loss: 7.1577\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.5526 - val_loss: 7.0577\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.4905 - val_loss: 6.9633\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.4492 - val_loss: 6.8742\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.1611 - val_loss: 6.7839\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.1771 - val_loss: 6.6967\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.9105 - val_loss: 6.6090\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.9644 - val_loss: 6.5252\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.6847 - val_loss: 6.4465\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.7115 - val_loss: 6.3691\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.3609 - val_loss: 6.2940\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.3597 - val_loss: 6.2212\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.2997 - val_loss: 6.1459\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.1535 - val_loss: 6.0698\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.0048 - val_loss: 6.0039\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.8795 - val_loss: 5.9423\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.7648 - val_loss: 5.8734\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.6298 - val_loss: 5.8128\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.5706 - val_loss: 5.7492\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.5390 - val_loss: 5.6879\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.4245 - val_loss: 5.6283\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.3397 - val_loss: 5.5663\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2661 - val_loss: 5.5100\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2716 - val_loss: 5.4534\n",
      "\n",
      "Feature shape is (180, 50)\n",
      "\n",
      "Feature test shape is (44, 50)\n",
      "\n",
      "After SMOTE feature shape is (268, 50)\n",
      "Model: \"sequential_287\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2175 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1889 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2176 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1890 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2177 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1891 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2178 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1892 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2179 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1893 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2180 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1894 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2181 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1895 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2182 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1896 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2183 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 262s 2s/step - loss: 192.1418 - val_loss: 86.6339\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 160.5219 - val_loss: 74.5029\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 130.4705 - val_loss: 66.1549\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 113.6488 - val_loss: 59.7383\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 100.8984 - val_loss: 54.8204\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 87.7668 - val_loss: 51.2232\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 82.6166 - val_loss: 48.1850\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 75.8804 - val_loss: 45.6268\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 70.1139 - val_loss: 43.5563\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 66.1071 - val_loss: 41.8218\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 63.2890 - val_loss: 40.2820\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 60.6239 - val_loss: 38.9090\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 58.2756 - val_loss: 37.6476\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 55.4847 - val_loss: 36.4940\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 53.4990 - val_loss: 35.3739\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 51.7985 - val_loss: 34.3587\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 49.4422 - val_loss: 33.4271\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 47.6806 - val_loss: 32.5366\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 46.4491 - val_loss: 31.6229\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 44.8315 - val_loss: 30.7449\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 43.0688 - val_loss: 29.8758\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 41.5810 - val_loss: 28.9624\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 39.8372 - val_loss: 28.0709\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 38.0777 - val_loss: 27.1561\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 36.8429 - val_loss: 26.2836\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 34.9882 - val_loss: 25.4107\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 33.3960 - val_loss: 24.5557\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 31.7502 - val_loss: 23.6970\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 29.9757 - val_loss: 22.8991\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 28.7963 - val_loss: 22.1165\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 27.1684 - val_loss: 21.4012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 26.0052 - val_loss: 20.7448\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 24.9437 - val_loss: 20.1550\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.8586 - val_loss: 19.6406\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.9038 - val_loss: 19.1641\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22.1573 - val_loss: 18.7220\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21.7773 - val_loss: 18.3232\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.9480 - val_loss: 17.9718\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.3652 - val_loss: 17.6284\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.7815 - val_loss: 17.2903\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.1739 - val_loss: 16.9764\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.6483 - val_loss: 16.6757\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.0166 - val_loss: 16.3865\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.6408 - val_loss: 16.1175\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.0571 - val_loss: 15.8565\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.7917 - val_loss: 15.6151\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.3052 - val_loss: 15.3902\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.0794 - val_loss: 15.1679\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.5106 - val_loss: 14.9660\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.3906 - val_loss: 14.7640\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.8997 - val_loss: 14.5850\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.3896 - val_loss: 14.4020\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.3095 - val_loss: 14.2177\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.9417 - val_loss: 14.0315\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.5092 - val_loss: 13.8651\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.4032 - val_loss: 13.7041\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.2220 - val_loss: 13.5545\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.9307 - val_loss: 13.4021\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.8849 - val_loss: 13.2440\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.5567 - val_loss: 13.1101\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.3711 - val_loss: 12.9673\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.9870 - val_loss: 12.8433\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.9504 - val_loss: 12.7099\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.6320 - val_loss: 12.5834\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.4793 - val_loss: 12.4496\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 11.3729 - val_loss: 12.3352\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 10.9582 - val_loss: 12.2108\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 10.9957 - val_loss: 12.0879\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.8367 - val_loss: 11.9782\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 10.8927 - val_loss: 11.8713\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 10.3610 - val_loss: 11.7672\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 10.3580 - val_loss: 11.6702\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 10.3327 - val_loss: 11.5693\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 10.0122 - val_loss: 11.4676\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 9.9244 - val_loss: 11.3643\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 9.6375 - val_loss: 11.2634\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.6623 - val_loss: 11.1690\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.5655 - val_loss: 11.0657\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.2968 - val_loss: 10.9725\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.4357 - val_loss: 10.8784\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.0435 - val_loss: 10.7877\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.8672 - val_loss: 10.7081\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.0163 - val_loss: 10.6231\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.8715 - val_loss: 10.5417\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.7154 - val_loss: 10.4635\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.5626 - val_loss: 10.3766\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.4311 - val_loss: 10.3019\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.5384 - val_loss: 10.2294\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2615 - val_loss: 10.1569\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1229 - val_loss: 10.0860\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1722 - val_loss: 10.0108\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0224 - val_loss: 9.9403\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0230 - val_loss: 9.8692\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7.7611 - val_loss: 9.8012\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.7835 - val_loss: 9.7346\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.7095 - val_loss: 9.6751\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.4460 - val_loss: 9.6176\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.5203 - val_loss: 9.5559\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.4690 - val_loss: 9.4978\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.3054 - val_loss: 9.4413\n",
      "Model: \"sequential_288\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2184 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1897 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2185 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1898 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2186 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1899 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2187 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1900 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2188 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1901 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2189 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1902 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2190 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1903 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2191 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1904 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2192 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 277s 2s/step - loss: 188.8454 - val_loss: 54.9364\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 158.6464 - val_loss: 50.2399\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 138.8902 - val_loss: 46.5745\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 125.4138 - val_loss: 43.6871\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 113.6563 - val_loss: 41.3314\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 104.5693 - val_loss: 39.4056\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 98.7077 - val_loss: 37.7512\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 91.5115 - val_loss: 36.3047\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 86.3918 - val_loss: 35.0620\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 82.1013 - val_loss: 33.9308\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 78.2767 - val_loss: 32.8524\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 75.2744 - val_loss: 31.8677\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 72.1393 - val_loss: 30.9341\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 69.2082 - val_loss: 30.0128\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 65.6328 - val_loss: 29.0708\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 62.9765 - val_loss: 28.1045\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 59.7575 - val_loss: 27.1463\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 57.8327 - val_loss: 26.1547\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 55.5092 - val_loss: 25.1622\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 52.9746 - val_loss: 24.1509\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 49.8209 - val_loss: 23.1303\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 47.9017 - val_loss: 22.1012\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 45.1326 - val_loss: 21.1034\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 43.3171 - val_loss: 20.1446\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 41.2328 - val_loss: 19.2684\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 38.9239 - val_loss: 18.4697\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 36.9431 - val_loss: 17.7456\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 35.4294 - val_loss: 17.0749\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 33.9803 - val_loss: 16.4782\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 32.4885 - val_loss: 15.9412\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 30.8858 - val_loss: 15.4489\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 29.9304 - val_loss: 14.9903\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 28.6016 - val_loss: 14.5663\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 27.4368 - val_loss: 14.1695\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 26.9691 - val_loss: 13.7838\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 25.5663 - val_loss: 13.4230\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 24.7970 - val_loss: 13.0827\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 24.1773 - val_loss: 12.7694\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.9375 - val_loss: 12.4703\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.2720 - val_loss: 12.1919\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.8638 - val_loss: 11.9121\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.2820 - val_loss: 11.6553\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.1607 - val_loss: 11.4048\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.6853 - val_loss: 11.1743\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.0871 - val_loss: 10.9537\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.4967 - val_loss: 10.7391\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.3221 - val_loss: 10.5382\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.0303 - val_loss: 10.3455\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.1882 - val_loss: 10.1631\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.0018 - val_loss: 9.9767\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.5781 - val_loss: 9.8069\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.0626 - val_loss: 9.6385\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.7943 - val_loss: 9.4773\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.3447 - val_loss: 9.3195\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.9631 - val_loss: 9.1610\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.6451 - val_loss: 9.0173\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.3720 - val_loss: 8.8807\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.0004 - val_loss: 8.7393\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.6874 - val_loss: 8.6084\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.3441 - val_loss: 8.4897\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.1452 - val_loss: 8.3650\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.8339 - val_loss: 8.2464\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.5917 - val_loss: 8.1351\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.3583 - val_loss: 8.0230\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.1617 - val_loss: 7.9186\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.0580 - val_loss: 7.8166\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.6679 - val_loss: 7.7146\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.3686 - val_loss: 7.6186\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.3286 - val_loss: 7.5236\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.0533 - val_loss: 7.4299\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.9904 - val_loss: 7.3388\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.6394 - val_loss: 7.2559\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.6467 - val_loss: 7.1693\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.3303 - val_loss: 7.0915\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.1781 - val_loss: 7.0119\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.0079 - val_loss: 6.9375\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.9608 - val_loss: 6.8628\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.9402 - val_loss: 6.7818\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.5642 - val_loss: 6.7093\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.5957 - val_loss: 6.6366\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.2988 - val_loss: 6.5664\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.1670 - val_loss: 6.5013\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.0080 - val_loss: 6.4372\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.0877 - val_loss: 6.3758\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.8877 - val_loss: 6.3127\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.7336 - val_loss: 6.2517\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.6745 - val_loss: 6.1918\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.6274 - val_loss: 6.1308\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.4779 - val_loss: 6.0809\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.3398 - val_loss: 6.0244\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2330 - val_loss: 5.9679\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2254 - val_loss: 5.9188\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.1381 - val_loss: 5.8685\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0843 - val_loss: 5.8195\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.8372 - val_loss: 5.7675\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.8989 - val_loss: 5.7186\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.7113 - val_loss: 5.6721\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.6110 - val_loss: 5.6210\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.6355 - val_loss: 5.5784\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.5010 - val_loss: 5.5363\n",
      "['../Cli3/UTSW_Cli_224P_OrderFea_50_SMOTE_CV_it_2_10_3.mat', '../PrePost/PET_MOO/HN_MR_5_PPD_SMOTE_CV5_fea50_it_50_3.mat', '../PrePost/CT_MOO/HN_MR_5_PPD_SMOTE_CV5_fea50_val_it_50_3.mat']\n",
      "\n",
      "... Processing ../PrePost/PET_MOO/HN_MR_5_PPD_SMOTE_CV5_fea50_it_50_3 ...\n",
      "PET_feature shape is (179, 50)\n",
      "\n",
      "... Processing ../PrePost/CT_MOO/HN_MR_5_PPD_SMOTE_CV5_fea50_val_it_50_3 ...\n",
      "CT_feature shape is (179, 50)\n",
      "\n",
      "Feature shape is (179, 50)\n",
      "\n",
      "Label shape is (179, 1)\n",
      "\n",
      "Feature test shape is (45, 50)\n",
      "\n",
      "Label test shape is (45, 1)\n",
      "\n",
      "After SMOTE feature shape is (266, 50)\n",
      "Model: \"sequential_289\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2193 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1905 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2194 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1906 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2195 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1907 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2196 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1908 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2197 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1909 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2198 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1910 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2199 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1911 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2200 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1912 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2201 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 270s 2s/step - loss: 172.7018 - val_loss: 67.8218\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 145.0091 - val_loss: 59.2531\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 128.1590 - val_loss: 52.8426\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 109.9376 - val_loss: 47.8286\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 98.1290 - val_loss: 43.9867\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 91.9968 - val_loss: 40.8752\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 84.5155 - val_loss: 38.2802\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 78.1951 - val_loss: 36.0961\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 73.2926 - val_loss: 34.2355\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 68.6607 - val_loss: 32.6633\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 65.3657 - val_loss: 31.2734\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 61.7692 - val_loss: 30.0569\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 58.8593 - val_loss: 28.9719\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 56.1200 - val_loss: 27.9080\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 53.9578 - val_loss: 26.8993\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 51.5537 - val_loss: 25.9866\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 49.5288 - val_loss: 25.0562\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 47.5012 - val_loss: 24.1643\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 45.8335 - val_loss: 23.2969\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 43.4874 - val_loss: 22.4193\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 41.8675 - val_loss: 21.4912\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 39.8473 - val_loss: 20.5923\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 38.2386 - val_loss: 19.7248\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 36.0895 - val_loss: 18.8610\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 34.7307 - val_loss: 18.0249\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 32.7616 - val_loss: 17.1758\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 3ms/step - loss: 30.8585 - val_loss: 16.3596\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 29.2093 - val_loss: 15.5635\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 27.6838 - val_loss: 14.7775\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 26.8434 - val_loss: 14.1081\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 25.6567 - val_loss: 13.4876\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 24.6669 - val_loss: 12.9479\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 23.1983 - val_loss: 12.4247\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 22.6112 - val_loss: 11.9753\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 21.3999 - val_loss: 11.5794\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 21.0180 - val_loss: 11.1991\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 20.4211 - val_loss: 10.8104\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 19.5292 - val_loss: 10.4874\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 18.7109 - val_loss: 10.1580\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 18.2542 - val_loss: 9.8530\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 17.8229 - val_loss: 9.5648\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 17.2120 - val_loss: 9.2926\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.7173 - val_loss: 9.0371\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.3171 - val_loss: 8.7826\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.9665 - val_loss: 8.5551\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.5128 - val_loss: 8.3503\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.1209 - val_loss: 8.1358\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.8056 - val_loss: 7.9421\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.1187 - val_loss: 7.7659\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.9326 - val_loss: 7.5999\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.7569 - val_loss: 7.4315\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 13.3727 - val_loss: 7.2870\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 13.0979 - val_loss: 7.1349\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.7015 - val_loss: 6.9937\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.6636 - val_loss: 6.8572\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 12.3980 - val_loss: 6.7184\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.0125 - val_loss: 6.5928\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11.7161 - val_loss: 6.4662\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.6545 - val_loss: 6.3606\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.4728 - val_loss: 6.2554\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.2762 - val_loss: 6.1495\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.0227 - val_loss: 6.0560\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.7882 - val_loss: 5.9544\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.6254 - val_loss: 5.8681\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.4596 - val_loss: 5.7753\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.3098 - val_loss: 5.6895\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.2875 - val_loss: 5.6103\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.1922 - val_loss: 5.5337\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.9834 - val_loss: 5.4664\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.8559 - val_loss: 5.3948\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.6287 - val_loss: 5.3216\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.4341 - val_loss: 5.2534\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.4924 - val_loss: 5.1922\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.2824 - val_loss: 5.1291\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.0857 - val_loss: 5.0729\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.1607 - val_loss: 5.0101\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.8604 - val_loss: 4.9567\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.9741 - val_loss: 4.9016\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.8166 - val_loss: 4.8509\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.7060 - val_loss: 4.7969\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.6699 - val_loss: 4.7462\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.2789 - val_loss: 4.6982\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.4097 - val_loss: 4.6519\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.2611 - val_loss: 4.6061\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.1030 - val_loss: 4.5611\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.0566 - val_loss: 4.5152\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.0405 - val_loss: 4.4728\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.1100 - val_loss: 4.4285\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.8663 - val_loss: 4.3849\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.8387 - val_loss: 4.3459\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.6979 - val_loss: 4.3061\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.6560 - val_loss: 4.2700\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.6132 - val_loss: 4.2344\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.4571 - val_loss: 4.1987\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.4111 - val_loss: 4.1681\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.3188 - val_loss: 4.1317\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.3209 - val_loss: 4.0986\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.0716 - val_loss: 4.0655\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.1719 - val_loss: 4.0370\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.0648 - val_loss: 4.0080\n",
      "Model: \"sequential_290\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2202 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1913 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2203 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1914 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2204 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1915 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2205 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1916 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2206 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1917 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2207 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1918 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2208 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1919 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2209 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1920 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2210 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 274s 2s/step - loss: 172.5142 - val_loss: 61.3823\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 149.2749 - val_loss: 55.3323\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 134.6456 - val_loss: 50.5638\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 116.9517 - val_loss: 46.9162\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 105.6806 - val_loss: 43.8561\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 96.4938 - val_loss: 41.2310\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 91.9449 - val_loss: 38.9759\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 88.1533 - val_loss: 37.0007\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 79.4896 - val_loss: 35.2382\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 76.2476 - val_loss: 33.6255\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 72.3772 - val_loss: 32.1510\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 69.7729 - val_loss: 30.7652\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 65.0315 - val_loss: 29.4703\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 60.8579 - val_loss: 28.2148\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 58.6938 - val_loss: 27.0101\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 57.0725 - val_loss: 25.8158\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 54.4201 - val_loss: 24.6148\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 51.4815 - val_loss: 23.4449\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 48.6422 - val_loss: 22.2975\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 46.6258 - val_loss: 21.1733\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 43.8386 - val_loss: 20.0736\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 41.4161 - val_loss: 19.0231\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 38.5704 - val_loss: 18.0483\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 37.2069 - val_loss: 17.1446\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 35.1053 - val_loss: 16.3354\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 33.7876 - val_loss: 15.6107\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 32.0323 - val_loss: 14.9568\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 30.9039 - val_loss: 14.3587\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 29.3192 - val_loss: 13.8030\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 28.6761 - val_loss: 13.3024\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 26.7963 - val_loss: 12.8246\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 26.8138 - val_loss: 12.3818\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 25.6988 - val_loss: 11.9694\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 24.1949 - val_loss: 11.5951\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 23.7005 - val_loss: 11.2436\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 22.6282 - val_loss: 10.9080\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 22.0836 - val_loss: 10.5936\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 21.5708 - val_loss: 10.2950\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 20.7640 - val_loss: 10.0153\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 20.4272 - val_loss: 9.7484\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 19.2352 - val_loss: 9.4895\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 18.9537 - val_loss: 9.2501\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 18.5566 - val_loss: 9.0291\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 17.9155 - val_loss: 8.8141\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 17.5960 - val_loss: 8.6048\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.9801 - val_loss: 8.4042\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.6903 - val_loss: 8.2126\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.3990 - val_loss: 8.0370\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.8521 - val_loss: 7.8624\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.3166 - val_loss: 7.6989\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.0182 - val_loss: 7.5490\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.7803 - val_loss: 7.3981\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.3591 - val_loss: 7.2623\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.7265 - val_loss: 7.1202\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.5880 - val_loss: 6.9911\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.5539 - val_loss: 6.8660\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.9639 - val_loss: 6.7480\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.6624 - val_loss: 6.6347\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.7470 - val_loss: 6.5249\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.1966 - val_loss: 6.4247\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.0203 - val_loss: 6.3262\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.8219 - val_loss: 6.2276\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.5936 - val_loss: 6.1328\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.4211 - val_loss: 6.0376\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.3590 - val_loss: 5.9458\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.9399 - val_loss: 5.8602\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.9928 - val_loss: 5.7748\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.5065 - val_loss: 5.6955\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.5045 - val_loss: 5.6171\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.3994 - val_loss: 5.5424\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.0757 - val_loss: 5.4702\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.9483 - val_loss: 5.3990\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.9296 - val_loss: 5.3348\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.8878 - val_loss: 5.2688\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.5966 - val_loss: 5.2062\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.4069 - val_loss: 5.1412\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.1924 - val_loss: 5.0820\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.1586 - val_loss: 5.0231\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.1264 - val_loss: 4.9666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.9745 - val_loss: 4.9102\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.9134 - val_loss: 4.8588\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.8108 - val_loss: 4.8027\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.6317 - val_loss: 4.7554\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.5459 - val_loss: 4.7067\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.4111 - val_loss: 4.6589\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.4129 - val_loss: 4.6121\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.0550 - val_loss: 4.5672\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.2376 - val_loss: 4.5240\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.9831 - val_loss: 4.4814\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.0422 - val_loss: 4.4398\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.8775 - val_loss: 4.3994\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.7503 - val_loss: 4.3591\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.6715 - val_loss: 4.3219\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.6867 - val_loss: 4.2853\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.6212 - val_loss: 4.2490\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.4593 - val_loss: 4.2135\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.4730 - val_loss: 4.1780\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.3448 - val_loss: 4.1429\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.2105 - val_loss: 4.1104\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.0865 - val_loss: 4.0792\n",
      "\n",
      "Feature shape is (179, 50)\n",
      "\n",
      "Feature test shape is (45, 50)\n",
      "\n",
      "After SMOTE feature shape is (266, 50)\n",
      "Model: \"sequential_291\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2211 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1921 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2212 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1922 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2213 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1923 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2214 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1924 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2215 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1925 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2216 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1926 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2217 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1927 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2218 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1928 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2219 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 273s 2s/step - loss: 228.8110 - val_loss: 80.4736\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 182.2246 - val_loss: 69.5794\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 165.8871 - val_loss: 61.2482\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 145.6252 - val_loss: 54.9737\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 127.6542 - val_loss: 50.0207\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 115.0860 - val_loss: 46.1374\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 102.9079 - val_loss: 42.9640\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 98.2092 - val_loss: 40.2340\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 92.6334 - val_loss: 37.9147\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 84.1831 - val_loss: 35.9398\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 83.2761 - val_loss: 34.1475\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 77.6456 - val_loss: 32.5303\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 71.8375 - val_loss: 31.0826\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 68.6189 - val_loss: 29.7072\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 63.5019 - val_loss: 28.3965\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 62.1175 - val_loss: 27.1297\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 57.5556 - val_loss: 25.8866\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 56.5695 - val_loss: 24.6498\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 51.4704 - val_loss: 23.4330\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 50.7549 - val_loss: 22.2143\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 46.1097 - val_loss: 21.0458\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 44.9266 - val_loss: 19.9530\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 42.7047 - val_loss: 18.9215\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 40.6309 - val_loss: 17.9992\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 36.7597 - val_loss: 17.1733\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 36.9539 - val_loss: 16.4121\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 34.8937 - val_loss: 15.7277\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 33.4826 - val_loss: 15.0978\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 31.7686 - val_loss: 14.5202\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 30.5624 - val_loss: 13.9841\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 29.2168 - val_loss: 13.4805\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 27.2490 - val_loss: 13.0125\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 26.7022 - val_loss: 12.5770\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 26.1390 - val_loss: 12.1654\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 24.7776 - val_loss: 11.7801\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 24.0163 - val_loss: 11.4179\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 23.6070 - val_loss: 11.0776\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 22.0178 - val_loss: 10.7681\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 21.5511 - val_loss: 10.4643\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 20.9627 - val_loss: 10.1853\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 20.4562 - val_loss: 9.9179\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 19.8051 - val_loss: 9.6711\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 19.2309 - val_loss: 9.4264\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 18.7298 - val_loss: 9.1983\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 17.9551 - val_loss: 8.9843\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 17.7876 - val_loss: 8.7851\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 17.2413 - val_loss: 8.5956\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 16.4455 - val_loss: 8.4092\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 16.2170 - val_loss: 8.2332\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.0177 - val_loss: 8.0677\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.3456 - val_loss: 7.9087\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 15.3691 - val_loss: 7.7512\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.5752 - val_loss: 7.6038\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 14.3992 - val_loss: 7.4656\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 14.2537 - val_loss: 7.3348\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 14.0597 - val_loss: 7.1995\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 13.6653 - val_loss: 7.0747\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 13.3034 - val_loss: 6.9562\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.1708 - val_loss: 6.8408\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.6542 - val_loss: 6.7279\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 12.6894 - val_loss: 6.6225\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 12.2480 - val_loss: 6.5195\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 12.1046 - val_loss: 6.4204\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11.9066 - val_loss: 6.3263\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.5068 - val_loss: 6.2366\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.7159 - val_loss: 6.1494\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.3877 - val_loss: 6.0616\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.9880 - val_loss: 5.9779\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 10.7418 - val_loss: 5.8998\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.8164 - val_loss: 5.8235\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.4451 - val_loss: 5.7507\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.4463 - val_loss: 5.6778\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.2649 - val_loss: 5.6087\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.2934 - val_loss: 5.5406\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.9386 - val_loss: 5.4748\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.7011 - val_loss: 5.4093\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.6343 - val_loss: 5.3476\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.5943 - val_loss: 5.2871\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.2962 - val_loss: 5.2279\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.2088 - val_loss: 5.1714\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.3072 - val_loss: 5.1143\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.7973 - val_loss: 5.0594\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.1000 - val_loss: 5.0065\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.9034 - val_loss: 4.9545\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.8239 - val_loss: 4.9033\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.6783 - val_loss: 4.8532\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.5274 - val_loss: 4.8041\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.4734 - val_loss: 4.7577\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.3004 - val_loss: 4.7114\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.1854 - val_loss: 4.6655\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.0662 - val_loss: 4.6207\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.0886 - val_loss: 4.5772\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.7836 - val_loss: 4.5347\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.9176 - val_loss: 4.4933\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.8015 - val_loss: 4.4532\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.7191 - val_loss: 4.4152\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.5612 - val_loss: 4.3776\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.6161 - val_loss: 4.3405\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.4952 - val_loss: 4.3031\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.2887 - val_loss: 4.2689\n",
      "Model: \"sequential_292\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2220 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1929 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2221 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1930 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2222 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1931 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2223 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1932 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2224 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1933 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2225 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1934 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2226 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1935 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2227 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1936 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2228 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 300s 3s/step - loss: 218.0352 - val_loss: 86.7699\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 185.3322 - val_loss: 75.0128\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 160.5045 - val_loss: 66.4069\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 142.4067 - val_loss: 59.6983\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 126.4082 - val_loss: 54.4210\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 116.0868 - val_loss: 50.1095\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 103.6861 - val_loss: 46.5667\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 97.5015 - val_loss: 43.5150\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 91.8450 - val_loss: 40.9153\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 84.0112 - val_loss: 38.6472\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 79.8951 - val_loss: 36.6306\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 76.0042 - val_loss: 34.7709\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 71.9881 - val_loss: 33.0929\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 69.3706 - val_loss: 31.5015\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 65.5011 - val_loss: 30.0375\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 62.3407 - val_loss: 28.6638\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 59.9462 - val_loss: 27.3653\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 56.2059 - val_loss: 26.1487\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 54.2139 - val_loss: 24.9434\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 51.5471 - val_loss: 23.8036\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 48.8615 - val_loss: 22.7017\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 47.0612 - val_loss: 21.6146\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 44.8231 - val_loss: 20.5778\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 42.2641 - val_loss: 19.5809\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 39.6030 - val_loss: 18.6325\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 38.3500 - val_loss: 17.7247\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 36.1124 - val_loss: 16.8503\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 34.2452 - val_loss: 16.0478\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 32.4267 - val_loss: 15.3008\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 30.9352 - val_loss: 14.6050\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 29.8267 - val_loss: 13.9739\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 28.2965 - val_loss: 13.4017\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 27.0503 - val_loss: 12.8882\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 26.0347 - val_loss: 12.4154\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 25.0125 - val_loss: 11.9901\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 24.1877 - val_loss: 11.5975\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 23.3887 - val_loss: 11.2295\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 22.8909 - val_loss: 10.8837\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 21.7080 - val_loss: 10.5627\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 21.1324 - val_loss: 10.2511\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 20.4724 - val_loss: 9.9637\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 19.9523 - val_loss: 9.6920\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 19.4128 - val_loss: 9.4379\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 18.7294 - val_loss: 9.1975\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 17.9793 - val_loss: 8.9690\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 17.5798 - val_loss: 8.7527\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 17.0259 - val_loss: 8.5433\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.7963 - val_loss: 8.3348\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 16.0627 - val_loss: 8.1430\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 15.8317 - val_loss: 7.9547\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 15.4807 - val_loss: 7.7798\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 15.0024 - val_loss: 7.6121\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 14.6887 - val_loss: 7.4488\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 14.1045 - val_loss: 7.2943\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 13.8976 - val_loss: 7.1475\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 13.6339 - val_loss: 7.0095\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 13.3665 - val_loss: 6.8754\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 13.0787 - val_loss: 6.7473\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 13.1203 - val_loss: 6.6276\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 12.6357 - val_loss: 6.5116\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 12.1387 - val_loss: 6.4020\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 12.0613 - val_loss: 6.2949\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11.9494 - val_loss: 6.1941\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11.5525 - val_loss: 6.0961\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11.5263 - val_loss: 6.0003\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11.1197 - val_loss: 5.9096\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 10.9109 - val_loss: 5.8226\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 10.9053 - val_loss: 5.7391\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 10.6819 - val_loss: 5.6562\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 10.4318 - val_loss: 5.5782\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 10.2664 - val_loss: 5.5030\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9.8746 - val_loss: 5.4300\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.9495 - val_loss: 5.3602\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9.8400 - val_loss: 5.2923\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.6667 - val_loss: 5.2285\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9.4536 - val_loss: 5.1653\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9.2882 - val_loss: 5.1044\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9.2254 - val_loss: 5.0461\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9.1340 - val_loss: 4.9907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.0952 - val_loss: 4.9358\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.8404 - val_loss: 4.8823\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8.6438 - val_loss: 4.8321\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8.6135 - val_loss: 4.7823\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.4421 - val_loss: 4.7357\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.3973 - val_loss: 4.6890\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.3146 - val_loss: 4.6440\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.2534 - val_loss: 4.5996\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.9687 - val_loss: 4.5581\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.1033 - val_loss: 4.5162\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.8219 - val_loss: 4.4752\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.8380 - val_loss: 4.4370\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.7343 - val_loss: 4.3995\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.6516 - val_loss: 4.3616\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.5514 - val_loss: 4.3259\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.4451 - val_loss: 4.2914\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.4300 - val_loss: 4.2579\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.3991 - val_loss: 4.2243\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.3564 - val_loss: 4.1917\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.2448 - val_loss: 4.1602\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.1999 - val_loss: 4.1298\n",
      "['../Cli3/UTSW_Cli_224P_OrderFea_50_SMOTE_CV_it_2_10_4.mat', '../PrePost/PET_MOO/HN_MR_5_PPD_SMOTE_CV5_fea50_it_50_4.mat', '../PrePost/CT_MOO/HN_MR_5_PPD_SMOTE_CV5_fea50_val_it_50_4.mat']\n",
      "\n",
      "... Processing ../PrePost/PET_MOO/HN_MR_5_PPD_SMOTE_CV5_fea50_it_50_4 ...\n",
      "PET_feature shape is (178, 50)\n",
      "\n",
      "... Processing ../PrePost/CT_MOO/HN_MR_5_PPD_SMOTE_CV5_fea50_val_it_50_4 ...\n",
      "CT_feature shape is (178, 50)\n",
      "\n",
      "Feature shape is (178, 50)\n",
      "\n",
      "Label shape is (178, 1)\n",
      "\n",
      "Feature test shape is (46, 50)\n",
      "\n",
      "Label test shape is (46, 1)\n",
      "\n",
      "After SMOTE feature shape is (266, 50)\n",
      "Model: \"sequential_293\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2229 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1937 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2230 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1938 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2231 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1939 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2232 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1940 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2233 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1941 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2234 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1942 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2235 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1943 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2236 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1944 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2237 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 296s 2s/step - loss: 156.3710 - val_loss: 54.5235\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 131.4917 - val_loss: 46.8770\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 113.1525 - val_loss: 41.4196\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 98.6175 - val_loss: 37.4076\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 86.3442 - val_loss: 34.4223\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 78.2808 - val_loss: 32.0380\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 73.1906 - val_loss: 30.1959\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 68.4242 - val_loss: 28.6275\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 64.4255 - val_loss: 27.2670\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 60.4150 - val_loss: 26.1276\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 57.3891 - val_loss: 25.0880\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 54.5091 - val_loss: 24.1496\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 52.3183 - val_loss: 23.2695\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 50.7040 - val_loss: 22.4726\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 48.0063 - val_loss: 21.6774\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 46.1229 - val_loss: 20.9275\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 43.9360 - val_loss: 20.1795\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 42.2612 - val_loss: 19.4423\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 40.7387 - val_loss: 18.7126\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 38.7683 - val_loss: 17.9936\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 37.0989 - val_loss: 17.2842\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 35.6891 - val_loss: 16.5842\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 33.7045 - val_loss: 15.9078\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 32.2826 - val_loss: 15.2237\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 30.8241 - val_loss: 14.5742\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 29.4394 - val_loss: 13.9439\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 27.7694 - val_loss: 13.3388\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 26.6652 - val_loss: 12.7761\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 25.3731 - val_loss: 12.2662\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 24.5753 - val_loss: 11.7891\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 23.6499 - val_loss: 11.3562\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 22.6096 - val_loss: 10.9748\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 21.6930 - val_loss: 10.6233\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 20.9660 - val_loss: 10.3074\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 20.3091 - val_loss: 10.0111\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 19.5027 - val_loss: 9.7379\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 19.3600 - val_loss: 9.4876\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 18.8386 - val_loss: 9.2633\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 18.0251 - val_loss: 9.0510\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 17.9847 - val_loss: 8.8481\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 17.2830 - val_loss: 8.6678\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 16.8845 - val_loss: 8.4876\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 16.5373 - val_loss: 8.3115\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 16.1563 - val_loss: 8.1411\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 15.9814 - val_loss: 7.9911\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 15.4392 - val_loss: 7.8350\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 15.0736 - val_loss: 7.6891\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.8272 - val_loss: 7.5475\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14.2734 - val_loss: 7.4207\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 14.1196 - val_loss: 7.2929\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 14.1919 - val_loss: 7.1709\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 13.6625 - val_loss: 7.0498\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 13.5010 - val_loss: 6.9377\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.4024 - val_loss: 6.8286\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 12.9715 - val_loss: 6.7240\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 12.3634 - val_loss: 6.6128\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 12.5637 - val_loss: 6.5078\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12.3000 - val_loss: 6.4073\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 12.0237 - val_loss: 6.3088\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11.7237 - val_loss: 6.2114\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11.5986 - val_loss: 6.1222\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11.3199 - val_loss: 6.0372\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11.2296 - val_loss: 5.9530\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11.2146 - val_loss: 5.8688\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 10.7802 - val_loss: 5.7910\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 10.5323 - val_loss: 5.7096\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 10.6098 - val_loss: 5.6281\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 10.3187 - val_loss: 5.5480\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.2272 - val_loss: 5.4779\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9.9963 - val_loss: 5.4066\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9.9966 - val_loss: 5.3360\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.6891 - val_loss: 5.2725\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9.7938 - val_loss: 5.2068\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9.3821 - val_loss: 5.1443\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - ETA: 0s - loss: 9.868 - 0s 4ms/step - loss: 9.3710 - val_loss: 5.0845\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9.2160 - val_loss: 5.0283\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.2050 - val_loss: 4.9719\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.9643 - val_loss: 4.9149\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8.7573 - val_loss: 4.8591\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8.8196 - val_loss: 4.8083\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.4845 - val_loss: 4.7592\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8.7253 - val_loss: 4.7058\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.3920 - val_loss: 4.6559\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.3482 - val_loss: 4.6121\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8.2897 - val_loss: 4.5644\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8.1378 - val_loss: 4.5223\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.9350 - val_loss: 4.4827\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.8601 - val_loss: 4.4427\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.8209 - val_loss: 4.4036\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.8301 - val_loss: 4.3635\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.6644 - val_loss: 4.3258\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.7446 - val_loss: 4.2853\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.6204 - val_loss: 4.2497\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.4853 - val_loss: 4.2122\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.4295 - val_loss: 4.1792\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.3672 - val_loss: 4.1447\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.3485 - val_loss: 4.1094\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.3122 - val_loss: 4.0785\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.1062 - val_loss: 4.0451\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.1956 - val_loss: 4.0153\n",
      "Model: \"sequential_294\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2238 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1945 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2239 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1946 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2240 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1947 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2241 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1948 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2242 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1949 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2243 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1950 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2244 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1951 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2245 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1952 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2246 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 305s 3s/step - loss: 175.0912 - val_loss: 77.3105\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 150.5344 - val_loss: 69.8751\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 130.1251 - val_loss: 64.1527\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 114.6163 - val_loss: 59.7074\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 104.9633 - val_loss: 55.9659\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 96.8582 - val_loss: 52.8581\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 91.1598 - val_loss: 50.2518\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 83.7726 - val_loss: 48.0466\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 80.0295 - val_loss: 46.1108\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 76.2009 - val_loss: 44.4087\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 70.0861 - val_loss: 42.8397\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 66.3411 - val_loss: 41.4364\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 64.7387 - val_loss: 40.0989\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 61.9390 - val_loss: 38.8092\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 58.3751 - val_loss: 37.5499\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 55.9242 - val_loss: 36.3924\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 54.2214 - val_loss: 35.2400\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 50.4722 - val_loss: 34.1362\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 49.5741 - val_loss: 32.9951\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 47.6832 - val_loss: 31.9133\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 45.2317 - val_loss: 30.8672\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 42.6898 - val_loss: 29.8620\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 40.7893 - val_loss: 28.8591\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 39.1769 - val_loss: 27.8778\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 37.7653 - val_loss: 26.9428\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 36.3770 - val_loss: 26.1096\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 34.0109 - val_loss: 25.3079\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 33.3562 - val_loss: 24.5301\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 31.5045 - val_loss: 23.8336\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 30.4976 - val_loss: 23.1699\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 29.1070 - val_loss: 22.5605\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 28.4104 - val_loss: 21.9933\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 26.7890 - val_loss: 21.4658\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 25.7717 - val_loss: 20.9605\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 24.6659 - val_loss: 20.5131\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 24.0536 - val_loss: 20.0837\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 22.9146 - val_loss: 19.6676\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 22.8077 - val_loss: 19.2632\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 22.0845 - val_loss: 18.8796\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 21.0668 - val_loss: 18.5344\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 20.4599 - val_loss: 18.1736\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 20.1935 - val_loss: 17.8328\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 19.0429 - val_loss: 17.5403\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 19.3242 - val_loss: 17.2251\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 18.5500 - val_loss: 16.9261\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 18.0440 - val_loss: 16.6444\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 17.6130 - val_loss: 16.3920\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 17.4211 - val_loss: 16.1362\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 16.2835 - val_loss: 15.9100\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.5613 - val_loss: 15.6797\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 15.8119 - val_loss: 15.4333\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 15.6506 - val_loss: 15.2099\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 15.3010 - val_loss: 14.9821\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15.1606 - val_loss: 14.7689\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 14.6101 - val_loss: 14.5713\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 14.2487 - val_loss: 14.3895\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 13.7450 - val_loss: 14.2096\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.7961 - val_loss: 14.0251\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 13.3864 - val_loss: 13.8471\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13.1535 - val_loss: 13.6712\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 12.8095 - val_loss: 13.4964\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 12.7064 - val_loss: 13.3322\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 12.2576 - val_loss: 13.1650\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 12.1747 - val_loss: 13.0189\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 12.1568 - val_loss: 12.8663\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11.8290 - val_loss: 12.7241\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11.4611 - val_loss: 12.5934\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11.3271 - val_loss: 12.4571\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11.1863 - val_loss: 12.3241\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11.2643 - val_loss: 12.1959\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.7539 - val_loss: 12.0764\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 10.6455 - val_loss: 11.9464\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 10.5666 - val_loss: 11.8253\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.3136 - val_loss: 11.7184\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.1726 - val_loss: 11.6105\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10.2095 - val_loss: 11.5020\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.9202 - val_loss: 11.4039\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.5966 - val_loss: 11.3186\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.5543 - val_loss: 11.2303\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9.6397 - val_loss: 11.1382\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9.2212 - val_loss: 11.0432\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9.1854 - val_loss: 10.9528\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9.1349 - val_loss: 10.8666\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8.9486 - val_loss: 10.7806\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8.8892 - val_loss: 10.6947\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8.7650 - val_loss: 10.6157\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8.6712 - val_loss: 10.5347\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8.5845 - val_loss: 10.4523\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8.5092 - val_loss: 10.3829\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8.4815 - val_loss: 10.3090\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8.4912 - val_loss: 10.2332\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8.2676 - val_loss: 10.1642\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8.1609 - val_loss: 10.1081\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.9549 - val_loss: 10.0427\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.1267 - val_loss: 9.9799\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.9353 - val_loss: 9.9193\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.7913 - val_loss: 9.8683\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.8507 - val_loss: 9.8105\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.6782 - val_loss: 9.7626\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.7330 - val_loss: 9.7054\n",
      "\n",
      "Feature shape is (178, 50)\n",
      "\n",
      "Feature test shape is (46, 50)\n",
      "\n",
      "After SMOTE feature shape is (266, 50)\n",
      "Model: \"sequential_295\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2247 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1953 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2248 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1954 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2249 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1955 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2250 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1956 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2251 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1957 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2252 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1958 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2253 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1959 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2254 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1960 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2255 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 294s 2s/step - loss: 183.9707 - val_loss: 63.8901\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 150.1395 - val_loss: 55.0938\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 128.5487 - val_loss: 48.9834\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 108.6325 - val_loss: 44.4495\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 95.1780 - val_loss: 41.0783\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 87.2625 - val_loss: 38.3926\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 80.7965 - val_loss: 36.2737\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 74.9372 - val_loss: 34.4102\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 70.7153 - val_loss: 32.7864\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 66.7273 - val_loss: 31.3773\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 63.5732 - val_loss: 30.1296\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 60.6348 - val_loss: 29.0248\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 58.0393 - val_loss: 27.9796\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 55.4273 - val_loss: 27.0459\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 53.9550 - val_loss: 26.1634\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 51.7732 - val_loss: 25.3069\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 49.8614 - val_loss: 24.4695\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 48.0992 - val_loss: 23.6697\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 46.3529 - val_loss: 22.9004\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 44.9069 - val_loss: 22.0853\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 43.2472 - val_loss: 21.2917\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 41.5983 - val_loss: 20.5162\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 40.1096 - val_loss: 19.7259\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 38.4873 - val_loss: 18.9526\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 36.7716 - val_loss: 18.1934\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 35.2990 - val_loss: 17.4202\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 33.5062 - val_loss: 16.6661\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 31.9988 - val_loss: 15.9194\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 30.8191 - val_loss: 15.1965\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 29.3067 - val_loss: 14.4814\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 4ms/step - loss: 27.6281 - val_loss: 13.7822\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 26.1683 - val_loss: 13.1196\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 25.1121 - val_loss: 12.5233\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 23.7036 - val_loss: 11.9751\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 22.9777 - val_loss: 11.5009\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 22.3101 - val_loss: 11.0733\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 21.2290 - val_loss: 10.7097\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 20.7590 - val_loss: 10.3741\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 20.1742 - val_loss: 10.0714\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 19.1899 - val_loss: 9.7932\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 18.9384 - val_loss: 9.5195\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 18.5128 - val_loss: 9.2693\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 17.6687 - val_loss: 9.0343\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 17.1292 - val_loss: 8.8185\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 17.1690 - val_loss: 8.5950\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 16.8484 - val_loss: 8.3905\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 16.2569 - val_loss: 8.1963\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 15.5352 - val_loss: 8.0167\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 15.3332 - val_loss: 7.8362\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 14.7624 - val_loss: 7.6732\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 14.5679 - val_loss: 7.5224\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 14.4656 - val_loss: 7.3657\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 14.0229 - val_loss: 7.2199\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 13.6464 - val_loss: 7.0797\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 13.4305 - val_loss: 6.9453\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 13.1228 - val_loss: 6.8213\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 12.9591 - val_loss: 6.6999\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 12.6975 - val_loss: 6.5855\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 12.3664 - val_loss: 6.4667\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 12.3396 - val_loss: 6.3544\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11.9523 - val_loss: 6.2487\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11.8598 - val_loss: 6.1443\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11.6468 - val_loss: 6.0502\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11.4165 - val_loss: 5.9566\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11.2942 - val_loss: 5.8639\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11.0418 - val_loss: 5.7749\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 10.9140 - val_loss: 5.6889\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 10.7592 - val_loss: 5.6082\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 10.4871 - val_loss: 5.5282\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 10.4478 - val_loss: 5.4505\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 10.2825 - val_loss: 5.3762\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 10.1448 - val_loss: 5.2999\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9.8783 - val_loss: 5.2291\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9.7002 - val_loss: 5.1636\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9.5868 - val_loss: 5.0978\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9.6571 - val_loss: 5.0323\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9.5352 - val_loss: 4.9708\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9.1443 - val_loss: 4.9104\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9.1468 - val_loss: 4.8493\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9.0594 - val_loss: 4.7920\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8.9170 - val_loss: 4.7366\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8.8603 - val_loss: 4.6814\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.7426 - val_loss: 4.6281\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8.4737 - val_loss: 4.5776\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8.4606 - val_loss: 4.5276\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8.4642 - val_loss: 4.4794\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8.2227 - val_loss: 4.4342\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.2057 - val_loss: 4.3891\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8.2416 - val_loss: 4.3442\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.9930 - val_loss: 4.3028\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.7877 - val_loss: 4.2624\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.7556 - val_loss: 4.2227\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.7322 - val_loss: 4.1845\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.7994 - val_loss: 4.1466\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.7337 - val_loss: 4.1085\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.6606 - val_loss: 4.0711\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.3960 - val_loss: 4.0357\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.3574 - val_loss: 4.0013\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.2631 - val_loss: 3.9677\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.0544 - val_loss: 3.9352\n",
      "Model: \"sequential_296\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2256 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1961 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2257 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1962 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2258 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1963 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2259 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1964 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2260 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1965 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2261 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1966 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2262 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1967 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2263 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1968 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2264 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 295s 2s/step - loss: 209.2883 - val_loss: 71.2495\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 173.7582 - val_loss: 61.9339\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 151.2504 - val_loss: 55.0710\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 133.2264 - val_loss: 49.9383\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 115.3051 - val_loss: 46.0170\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 106.5617 - val_loss: 42.8884\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 100.2371 - val_loss: 40.3527\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 90.4802 - val_loss: 38.2295\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 86.1673 - val_loss: 36.3941\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 80.4832 - val_loss: 34.7710\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 77.2978 - val_loss: 33.3253\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 73.9257 - val_loss: 32.0213\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 69.8262 - val_loss: 30.8096\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 66.9042 - val_loss: 29.6530\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 64.0565 - val_loss: 28.5534\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 59.8258 - val_loss: 27.5010\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 58.0698 - val_loss: 26.4359\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 55.2497 - val_loss: 25.3747\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 52.3919 - val_loss: 24.3187\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 50.3804 - val_loss: 23.2571\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 48.0238 - val_loss: 22.2110\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 46.0629 - val_loss: 21.1646\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 42.7696 - val_loss: 20.1341\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 41.0780 - val_loss: 19.1592\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 38.9764 - val_loss: 18.2573\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 37.2850 - val_loss: 17.4567\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 34.8294 - val_loss: 16.7569\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 33.5772 - val_loss: 16.1233\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 31.5832 - val_loss: 15.5371\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 31.0486 - val_loss: 15.0037\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 29.1446 - val_loss: 14.5183\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 28.4696 - val_loss: 14.0600\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 27.0283 - val_loss: 13.6359\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 26.4439 - val_loss: 13.2454\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 25.1444 - val_loss: 12.8827\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 24.3669 - val_loss: 12.5367\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 23.8039 - val_loss: 12.2092\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 23.1340 - val_loss: 11.8988\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 22.2614 - val_loss: 11.6043\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 21.2930 - val_loss: 11.3344\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 21.0870 - val_loss: 11.0802\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 20.1632 - val_loss: 10.8259\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 19.8804 - val_loss: 10.5907\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 19.0540 - val_loss: 10.3635\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 18.6272 - val_loss: 10.1474\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 18.1528 - val_loss: 9.9448\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 17.9114 - val_loss: 9.7632\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 17.1364 - val_loss: 9.5833\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.8229 - val_loss: 9.4096\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.3613 - val_loss: 9.2407\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16.1244 - val_loss: 9.0737\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 15.7899 - val_loss: 8.9180\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 15.3826 - val_loss: 8.7707\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 14.9377 - val_loss: 8.6329\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 14.7777 - val_loss: 8.5018\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 14.2849 - val_loss: 8.3700\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 13.7727 - val_loss: 8.2515\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 13.7995 - val_loss: 8.1329\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 13.5081 - val_loss: 8.0226\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 13.2699 - val_loss: 7.9121\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 12.9978 - val_loss: 7.8135\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 12.7335 - val_loss: 7.7060\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 12.4217 - val_loss: 7.6050\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 12.3658 - val_loss: 7.5055\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11.8633 - val_loss: 7.4054\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11.8542 - val_loss: 7.3088\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11.6568 - val_loss: 7.2223\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11.4747 - val_loss: 7.1359\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11.2651 - val_loss: 7.0464\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 10.8625 - val_loss: 6.9620\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 10.9270 - val_loss: 6.8858\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 10.7307 - val_loss: 6.8060\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 10.6202 - val_loss: 6.7295\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 10.3608 - val_loss: 6.6552\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 10.1532 - val_loss: 6.5858\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 10.1375 - val_loss: 6.5074\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 10.0766 - val_loss: 6.4366\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9.6546 - val_loss: 6.3669\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9.5254 - val_loss: 6.2981\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9.5379 - val_loss: 6.2338\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.3173 - val_loss: 6.1759\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.1707 - val_loss: 6.1172\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9.0195 - val_loss: 6.0591\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8.8969 - val_loss: 6.0039\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8.7860 - val_loss: 5.9447\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8.8179 - val_loss: 5.8935\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.6468 - val_loss: 5.8403\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.5241 - val_loss: 5.7855\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.5022 - val_loss: 5.7340\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.2896 - val_loss: 5.6867\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.3205 - val_loss: 5.6406\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.0783 - val_loss: 5.5898\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8.1649 - val_loss: 5.5470\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.9798 - val_loss: 5.5037\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.8514 - val_loss: 5.4570\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.8208 - val_loss: 5.4154\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.7676 - val_loss: 5.3765\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7.5680 - val_loss: 5.3302\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.4971 - val_loss: 5.2910\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7.4345 - val_loss: 5.2526\n",
      "['../Cli3/UTSW_Cli_224P_OrderFea_50_SMOTE_CV_it_2_10_5.mat', '../PrePost/PET_MOO/HN_MR_5_PPD_SMOTE_CV5_fea50_it_50_5.mat', '../PrePost/CT_MOO/HN_MR_5_PPD_SMOTE_CV5_fea50_val_it_50_5.mat']\n",
      "\n",
      "... Processing ../PrePost/PET_MOO/HN_MR_5_PPD_SMOTE_CV5_fea50_it_50_5 ...\n",
      "PET_feature shape is (179, 50)\n",
      "\n",
      "... Processing ../PrePost/CT_MOO/HN_MR_5_PPD_SMOTE_CV5_fea50_val_it_50_5 ...\n",
      "CT_feature shape is (179, 50)\n",
      "\n",
      "Feature shape is (179, 50)\n",
      "\n",
      "Label shape is (179, 1)\n",
      "\n",
      "Feature test shape is (45, 50)\n",
      "\n",
      "Label test shape is (45, 1)\n",
      "\n",
      "After SMOTE feature shape is (268, 50)\n",
      "Model: \"sequential_297\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2265 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1969 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2266 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1970 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2267 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1971 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2268 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1972 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2269 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1973 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2270 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1974 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2271 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1975 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2272 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1976 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2273 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 298s 2s/step - loss: 184.0043 - val_loss: 74.2499\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 161.0296 - val_loss: 64.6027\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 140.7923 - val_loss: 56.9589\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 118.8039 - val_loss: 51.1505\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 107.3634 - val_loss: 46.4407\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 97.3294 - val_loss: 42.6311\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 89.5662 - val_loss: 39.3406\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 81.4686 - val_loss: 36.7970\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 76.1233 - val_loss: 34.5656\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 71.0019 - val_loss: 32.6313\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 67.7437 - val_loss: 30.9052\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 64.6071 - val_loss: 29.3337\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 61.3033 - val_loss: 27.8868\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 57.6849 - val_loss: 26.5850\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 54.6758 - val_loss: 25.3683\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 52.3206 - val_loss: 24.2268\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 50.1963 - val_loss: 23.1072\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 47.7297 - val_loss: 22.0539\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 45.3700 - val_loss: 21.0070\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 43.4819 - val_loss: 19.9890\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 41.6602 - val_loss: 18.9739\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 39.2303 - val_loss: 18.0042\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 37.0542 - val_loss: 17.0735\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 35.0836 - val_loss: 16.1830\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 33.4758 - val_loss: 15.3508\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 31.8932 - val_loss: 14.5421\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 4ms/step - loss: 30.0437 - val_loss: 13.8173\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 28.4610 - val_loss: 13.1481\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 27.3631 - val_loss: 12.5347\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 25.9368 - val_loss: 12.0038\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 24.6498 - val_loss: 11.5166\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 24.2397 - val_loss: 11.1016\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 23.0941 - val_loss: 10.7186\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 22.4145 - val_loss: 10.3699\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 21.5311 - val_loss: 10.0347\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.6735 - val_loss: 9.7256\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.3980 - val_loss: 9.4328\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.7082 - val_loss: 9.1611\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.0713 - val_loss: 8.9036\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.3843 - val_loss: 8.6572\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.0607 - val_loss: 8.4408\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.7586 - val_loss: 8.2306\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17.1527 - val_loss: 8.0280\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.2631 - val_loss: 7.8394\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16.1965 - val_loss: 7.6595\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.9523 - val_loss: 7.4881\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.4750 - val_loss: 7.3328\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.0606 - val_loss: 7.1791\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.6573 - val_loss: 7.0388\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.6669 - val_loss: 6.9005\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 14.2129 - val_loss: 6.7691\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.9705 - val_loss: 6.6425\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.4184 - val_loss: 6.5271\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 13.4256 - val_loss: 6.4072\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.1172 - val_loss: 6.3010\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.9320 - val_loss: 6.2002\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 12.6059 - val_loss: 6.1035\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.2609 - val_loss: 6.0070\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12.3166 - val_loss: 5.9175\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.8146 - val_loss: 5.8297\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.6668 - val_loss: 5.7470\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.7431 - val_loss: 5.6663\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 11.3519 - val_loss: 5.5893\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.1957 - val_loss: 5.5156\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.2102 - val_loss: 5.4474\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.0803 - val_loss: 5.3770\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 10.9974 - val_loss: 5.3138\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 10.6612 - val_loss: 5.2512\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 10.3738 - val_loss: 5.1888\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.3549 - val_loss: 5.1317\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 10.3180 - val_loss: 5.0743\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 10.0609 - val_loss: 5.0192\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 9.9118 - val_loss: 4.9666\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 9.9277 - val_loss: 4.9164\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 9.5811 - val_loss: 4.8646\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 9.5301 - val_loss: 4.8143\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 9.4135 - val_loss: 4.7657\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 9.3728 - val_loss: 4.7208\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 9.3094 - val_loss: 4.6788\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 9.2228 - val_loss: 4.6346\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.9935 - val_loss: 4.5919\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 9.0083 - val_loss: 4.5505\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.8400 - val_loss: 4.5084\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8.6466 - val_loss: 4.4687\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8.7078 - val_loss: 4.4311\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8.3521 - val_loss: 4.3930\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8.4915 - val_loss: 4.3581\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.4656 - val_loss: 4.3215\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8.3934 - val_loss: 4.2876\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8.1876 - val_loss: 4.2536\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8.1816 - val_loss: 4.2205\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0151 - val_loss: 4.1882\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7.9364 - val_loss: 4.1568\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7.8898 - val_loss: 4.1278\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7.7558 - val_loss: 4.0974\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7.5963 - val_loss: 4.0678\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7.6738 - val_loss: 4.0392\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7.6603 - val_loss: 4.0107\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7.4909 - val_loss: 3.9827\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7.4397 - val_loss: 3.9566\n",
      "Model: \"sequential_298\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2274 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1977 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2275 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1978 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2276 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1979 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2277 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1980 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2278 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1981 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2279 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1982 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2280 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1983 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2281 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1984 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2282 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 304s 3s/step - loss: 208.3883 - val_loss: 76.8543\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 180.4363 - val_loss: 67.0955\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 148.9291 - val_loss: 60.0527\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 130.0621 - val_loss: 54.5877\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 118.1137 - val_loss: 50.4621\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 109.6684 - val_loss: 47.0135\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 100.1181 - val_loss: 44.3046\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 92.1743 - val_loss: 41.9887\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 85.8550 - val_loss: 40.0054\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 80.3692 - val_loss: 38.2724\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 76.1850 - val_loss: 36.7368\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 73.9447 - val_loss: 35.3058\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 70.4232 - val_loss: 33.9992\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 67.1082 - val_loss: 32.7801\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 65.2176 - val_loss: 31.6343\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 62.1721 - val_loss: 30.5286\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 60.6431 - val_loss: 29.4711\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 57.4795 - val_loss: 28.4530\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 56.0725 - val_loss: 27.4953\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 53.2486 - val_loss: 26.5259\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 51.6360 - val_loss: 25.5772\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 49.7390 - val_loss: 24.6640\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 47.6775 - val_loss: 23.7272\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 46.0263 - val_loss: 22.8434\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 44.1471 - val_loss: 21.9507\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 41.7249 - val_loss: 21.0789\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 39.7330 - val_loss: 20.2249\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 39.1981 - val_loss: 19.3904\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 36.9577 - val_loss: 18.5678\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 34.7925 - val_loss: 17.7821\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 33.1032 - val_loss: 17.0312\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 32.0032 - val_loss: 16.3193\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 31.0438 - val_loss: 15.6664\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 28.9492 - val_loss: 15.0490\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 27.6451 - val_loss: 14.4857\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 26.3997 - val_loss: 13.9701\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 25.6859 - val_loss: 13.4967\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 24.8276 - val_loss: 13.0629\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.7897 - val_loss: 12.6804\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.2444 - val_loss: 12.3265\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.2123 - val_loss: 11.9679\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.5040 - val_loss: 11.6502\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 20.8822 - val_loss: 11.3505\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.6206 - val_loss: 11.0689\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 20.0964 - val_loss: 10.8075\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19.3130 - val_loss: 10.5608\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.8032 - val_loss: 10.3204\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 18.4710 - val_loss: 10.0941\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 17.7259 - val_loss: 9.8669\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 17.4903 - val_loss: 9.6557\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 16.6062 - val_loss: 9.4624\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 16.7631 - val_loss: 9.2811\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 16.1460 - val_loss: 9.1056\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 15.6627 - val_loss: 8.9300\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 15.2174 - val_loss: 8.7694\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 14.9789 - val_loss: 8.6149\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 14.3856 - val_loss: 8.4654\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 14.4564 - val_loss: 8.3174\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 13.8379 - val_loss: 8.1744\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 13.7323 - val_loss: 8.0428\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 13.5292 - val_loss: 7.9149\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 13.2332 - val_loss: 7.7910\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 12.8414 - val_loss: 7.6717\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 12.8118 - val_loss: 7.5476\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 12.3621 - val_loss: 7.4299\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 12.2828 - val_loss: 7.3244\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 12.0958 - val_loss: 7.2192\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 11.7144 - val_loss: 7.1164\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 11.6241 - val_loss: 7.0163\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 11.1221 - val_loss: 6.9163\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 11.1992 - val_loss: 6.8289\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 11.0144 - val_loss: 6.7397\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 10.8913 - val_loss: 6.6517\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 10.7237 - val_loss: 6.5709\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 10.5279 - val_loss: 6.4848\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.4697 - val_loss: 6.4026\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 10.2445 - val_loss: 6.3243\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.2766 - val_loss: 6.2459\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.8070 - val_loss: 6.1691\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.6963 - val_loss: 6.0963\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 9.5629 - val_loss: 6.0321\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.5246 - val_loss: 5.9664\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.3696 - val_loss: 5.8999\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.3695 - val_loss: 5.8365\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.2316 - val_loss: 5.7723\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8.9697 - val_loss: 5.7103\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 9.1950 - val_loss: 5.6525\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8.8420 - val_loss: 5.5931\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8.8116 - val_loss: 5.5381\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8.6192 - val_loss: 5.4807\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8.5173 - val_loss: 5.4248\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8.3515 - val_loss: 5.3710\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8.3140 - val_loss: 5.3159\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8.2240 - val_loss: 5.2664\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8.1235 - val_loss: 5.2175\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8.0061 - val_loss: 5.1680\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7.8703 - val_loss: 5.1224\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7.9235 - val_loss: 5.0803\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7.8451 - val_loss: 5.0371\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7.8019 - val_loss: 4.9936\n",
      "\n",
      "Feature shape is (179, 50)\n",
      "\n",
      "Feature test shape is (45, 50)\n",
      "\n",
      "After SMOTE feature shape is (268, 50)\n",
      "Model: \"sequential_299\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2283 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1985 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2284 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1986 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2285 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1987 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2286 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1988 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2287 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1989 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2288 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1990 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2289 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1991 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2290 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1992 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2291 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 309s 3s/step - loss: 224.5427 - val_loss: 74.6724\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 162.0025 - val_loss: 60.0909\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 133.3524 - val_loss: 50.5557\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 112.0287 - val_loss: 44.2069\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 99.3737 - val_loss: 39.6977\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 88.1465 - val_loss: 36.4240\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 79.7790 - val_loss: 33.9076\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 73.3466 - val_loss: 31.9492\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 69.0760 - val_loss: 30.4094\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 65.2050 - val_loss: 29.1811\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 62.1033 - val_loss: 28.1657\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 60.5681 - val_loss: 27.2779\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 57.1423 - val_loss: 26.4695\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 55.6698 - val_loss: 25.7223\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 54.1384 - val_loss: 24.9814\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 52.0989 - val_loss: 24.2655\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 50.5340 - val_loss: 23.5847\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 48.3208 - val_loss: 22.8908\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 47.0929 - val_loss: 22.1895\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 45.0563 - val_loss: 21.4773\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 44.0806 - val_loss: 20.7644\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 42.2763 - val_loss: 20.0483\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 40.5991 - val_loss: 19.3285\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 38.8320 - val_loss: 18.6098\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 37.1047 - val_loss: 17.9011\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 35.9595 - val_loss: 17.2038\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 34.3615 - val_loss: 16.5194\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 32.8300 - val_loss: 15.8546\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 31.5572 - val_loss: 15.2178\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 29.9651 - val_loss: 14.6196\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 29.1244 - val_loss: 14.0568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 27.3837 - val_loss: 13.5370\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 26.4340 - val_loss: 13.0601\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 25.5894 - val_loss: 12.6186\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 24.7867 - val_loss: 12.2133\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 23.9573 - val_loss: 11.8412\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.7870 - val_loss: 11.4911\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.2118 - val_loss: 11.1660\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.9445 - val_loss: 10.8648\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 21.0757 - val_loss: 10.5883\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 20.2953 - val_loss: 10.3263\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 19.5523 - val_loss: 10.0806\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 18.9152 - val_loss: 9.8419\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 18.5227 - val_loss: 9.6198\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 17.9088 - val_loss: 9.4052\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 17.6930 - val_loss: 9.2054\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 17.2375 - val_loss: 9.0048\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 17.0558 - val_loss: 8.8127\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 16.2372 - val_loss: 8.6359\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 15.7317 - val_loss: 8.4664\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.7115 - val_loss: 8.3037\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15.2222 - val_loss: 8.1494\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.7616 - val_loss: 8.0001\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.5520 - val_loss: 7.8559\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.4503 - val_loss: 7.7157\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14.1520 - val_loss: 7.5802\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.6647 - val_loss: 7.4508\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13.4765 - val_loss: 7.3273\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 13.1836 - val_loss: 7.2095\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 12.8575 - val_loss: 7.0939\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 12.5808 - val_loss: 6.9841\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 12.4112 - val_loss: 6.8783\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 12.0213 - val_loss: 6.7772\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.9126 - val_loss: 6.6811\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 11.8137 - val_loss: 6.5870\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.5066 - val_loss: 6.4968\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.1824 - val_loss: 6.4088\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 11.1404 - val_loss: 6.3255\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11.1581 - val_loss: 6.2398\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.9447 - val_loss: 6.1584\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.6433 - val_loss: 6.0831\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.5514 - val_loss: 6.0088\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.5488 - val_loss: 5.9347\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 10.2066 - val_loss: 5.8639\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 10.0202 - val_loss: 5.7945\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 9.7133 - val_loss: 5.7259\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 9.7223 - val_loss: 5.6628\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 9.6771 - val_loss: 5.6011\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.5440 - val_loss: 5.5421\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.2908 - val_loss: 5.4830\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.2048 - val_loss: 5.4258\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.1329 - val_loss: 5.3701\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.9206 - val_loss: 5.3170\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8.9204 - val_loss: 5.2635\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8.8484 - val_loss: 5.2107\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.7540 - val_loss: 5.1602\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.7536 - val_loss: 5.1114\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.5855 - val_loss: 5.0640\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.4411 - val_loss: 5.0170\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.4207 - val_loss: 4.9709\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2841 - val_loss: 4.9273\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0715 - val_loss: 4.8824\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.0888 - val_loss: 4.8388\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.9486 - val_loss: 4.7992\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.9331 - val_loss: 4.7604\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.7120 - val_loss: 4.7223\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.6150 - val_loss: 4.6832\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.6249 - val_loss: 4.6463\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.7735 - val_loss: 4.6099\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7.5560 - val_loss: 4.5723\n",
      "Model: \"sequential_300\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2292 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1993 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2293 (Dense)           (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1994 (Dropout)       (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2294 (Dense)           (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_1995 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2295 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1996 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2296 (Dense)           (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_1997 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2297 (Dense)           (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dropout_1998 (Dropout)       (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2298 (Dense)           (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_1999 (Dropout)       (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2299 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_2000 (Dropout)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2300 (Dense)           (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 9,622\n",
      "Trainable params: 9,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 307s 3s/step - loss: 171.8049 - val_loss: 65.0204\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 146.3059 - val_loss: 58.4570\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 130.8627 - val_loss: 53.3348\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 115.6729 - val_loss: 49.2498\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 107.0547 - val_loss: 45.9965\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 98.5655 - val_loss: 43.2715\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 91.7803 - val_loss: 41.0375\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 84.8411 - val_loss: 39.1870\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 79.7629 - val_loss: 37.6027\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 75.8563 - val_loss: 36.2078\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 71.5796 - val_loss: 34.9177\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 68.5342 - val_loss: 33.7230\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 66.3305 - val_loss: 32.5937\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 63.0415 - val_loss: 31.5098\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 60.0619 - val_loss: 30.4706\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 57.4586 - val_loss: 29.4238\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 55.2841 - val_loss: 28.3723\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 52.8020 - val_loss: 27.3605\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 50.0240 - val_loss: 26.3263\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 47.8774 - val_loss: 25.3079\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 45.9633 - val_loss: 24.2858\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 43.5855 - val_loss: 23.2939\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 41.0622 - val_loss: 22.3270\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 39.1235 - val_loss: 21.4372\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 37.2279 - val_loss: 20.5920\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 35.4438 - val_loss: 19.8174\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 33.8391 - val_loss: 19.1087\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 32.3004 - val_loss: 18.4616\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 31.1667 - val_loss: 17.8671\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 30.0528 - val_loss: 17.2929\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 28.2641 - val_loss: 16.7756\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 27.6005 - val_loss: 16.2836\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 26.9125 - val_loss: 15.8238\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 25.5142 - val_loss: 15.3997\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 24.5913 - val_loss: 14.9939\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.7124 - val_loss: 14.6322\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23.0937 - val_loss: 14.2818\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22.0468 - val_loss: 13.9480\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21.4336 - val_loss: 13.6158\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20.6573 - val_loss: 13.3116\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 20.1894 - val_loss: 13.0296\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 19.6120 - val_loss: 12.7500\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 19.2610 - val_loss: 12.4754\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18.5396 - val_loss: 12.2235\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 18.1504 - val_loss: 12.0019\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 17.6665 - val_loss: 11.7693\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 17.1373 - val_loss: 11.5466\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 16.7151 - val_loss: 11.3349\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 16.4520 - val_loss: 11.1323\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 15.9237 - val_loss: 10.9308\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 15.7098 - val_loss: 10.7366\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 15.4240 - val_loss: 10.5557\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 14.9358 - val_loss: 10.3877\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 14.7645 - val_loss: 10.2145\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 14.2709 - val_loss: 10.0545\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 14.2423 - val_loss: 9.8908\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 13.7552 - val_loss: 9.7411\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 13.3652 - val_loss: 9.5903\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 13.3441 - val_loss: 9.4476\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 13.0207 - val_loss: 9.3125\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 12.8494 - val_loss: 9.1771\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 12.6453 - val_loss: 9.0518\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 12.3771 - val_loss: 8.9295\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 12.2200 - val_loss: 8.8111\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 11.8876 - val_loss: 8.6942\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 11.7513 - val_loss: 8.5755\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 11.6832 - val_loss: 8.4686\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 11.4934 - val_loss: 8.3698\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 11.3681 - val_loss: 8.2614\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 11.1228 - val_loss: 8.1604\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 10.7835 - val_loss: 8.0559\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.6618 - val_loss: 7.9510\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 10.5567 - val_loss: 7.8492\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 10.3888 - val_loss: 7.7550\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 10.1911 - val_loss: 7.6680\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10.0797 - val_loss: 7.5843\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 10.0580 - val_loss: 7.4952\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.7179 - val_loss: 7.4049\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9.7294 - val_loss: 7.3210\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 9.5751 - val_loss: 7.2377\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 9.3866 - val_loss: 7.1607\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 9.2286 - val_loss: 7.0865\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 9.0957 - val_loss: 7.0155\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 9.1211 - val_loss: 6.9412\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8.8536 - val_loss: 6.8745\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8.9278 - val_loss: 6.8066\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.8437 - val_loss: 6.7405\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8.7083 - val_loss: 6.6765\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8.5931 - val_loss: 6.6080\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8.4620 - val_loss: 6.5445\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8.3519 - val_loss: 6.4828\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8.3090 - val_loss: 6.4193\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8.2605 - val_loss: 6.3574\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8.1134 - val_loss: 6.2994\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8.1542 - val_loss: 6.2460\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7.9426 - val_loss: 6.1946\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7.8795 - val_loss: 6.1399\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7.8390 - val_loss: 6.0894\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7.7265 - val_loss: 6.0358\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7.6685 - val_loss: 5.9813\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE \n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "# load files\n",
    "for repeat in range(1,6):\n",
    "    for CV in range(1,6):\n",
    "        mat_file_list = [\n",
    "        '../../../data/Models/Cli/Cli3/Cli_Model_CV_'+str(repeat)+'_Fold_'+str(CV)+'.mat',\n",
    "        '../../../data/Models/PET/PET_Model_CV_'+str(repeat)+'_Fold_'+str(CV)+'.mat',\n",
    "        '../../../data/Models/CT/CT_Model_CV_'+str(repeat)+'_Fold_'+str(CV)+'.mat']\n",
    "        print(mat_file_list)\n",
    "        \n",
    "        mat_file = mat_file_list[1]\n",
    "        mat_file_name = mat_file.replace('.mat', '')\n",
    "        print(\"\\n... Processing\", mat_file_name, '...')\n",
    "        mat = sp.io.loadmat(mat_file)\n",
    "        PET1 = mat['PET_sam_train_data0']\n",
    "        PET2 = mat['PET_sam_val_data']\n",
    "        PET = np.concatenate((PET1, PET2))\n",
    "        print('PET_feature shape is', PET.shape)\n",
    "        PET_test = mat['PET_sam_test_data']\n",
    "\n",
    "        mat_file = mat_file_list[2]\n",
    "        mat_file_name = mat_file.replace('.mat', '')\n",
    "        print(\"\\n... Processing\", mat_file_name, '...')\n",
    "        mat = sp.io.loadmat(mat_file)\n",
    "        CT1 = mat['CT_sam_train_data0']\n",
    "        CT2 = mat['CT_sam_val_data']\n",
    "        CT = np.concatenate((CT1, CT2))\n",
    "        print('CT_feature shape is', CT.shape)\n",
    "        CT_test = mat['CT_sam_test_data']\n",
    "        \n",
    "        # load label\n",
    "        Ind1 = mat['CT_ind_train_data0']\n",
    "        Ind2 = mat['CT_ind_val_data']-1\n",
    "        Ind0 = np.concatenate((Ind1, Ind2))\n",
    "        Ind_test = mat['CT_ind_test_data']-1\n",
    "        \n",
    "        # combine feature\n",
    "        Feature_train = PET\n",
    "        print('\\nFeature shape is', Feature_train.shape)\n",
    "        print('\\nLabel shape is', Ind0.shape)\n",
    "\n",
    "        Feature_test = PET_test\n",
    "        print('\\nFeature test shape is', Feature_test.shape)\n",
    "        print('\\nLabel test shape is', Ind_test.shape)\n",
    "        \n",
    "        # SMOTE\n",
    "        sm = SVMSMOTE(random_state=123)\n",
    "\n",
    "        Feature, Ind = sm.fit_resample(Feature_train, Ind0)\n",
    "        print('\\nAfter SMOTE feature shape is', Feature.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # positive model\n",
    "        Feature_pos = Feature[Ind==1,:]\n",
    "#         Ind_pos = \n",
    "        \n",
    "        # model training\n",
    "        clf = AutoEncoder(hidden_neurons = [32, 16, 4, 4, 16, 32],epochs=100)\n",
    "        clf.fit(Feature_pos)\n",
    "        \n",
    "        \n",
    "        # model testing\n",
    "        y_pred = clf.predict_proba(Feature_test)  # predict scores\n",
    "        \n",
    "        y_pred_train = clf.predict_proba(PET[Ind0[:,0]==1,:])  # predict scores\n",
    "        \n",
    "        \n",
    "        with open('AnomalyScore/AutoEncoder_P_PET_Repeat_'+str(repeat)+'CV_'+str(CV)+'.npy', 'wb') as f:\n",
    "            np.save(f,y_pred)\n",
    "        \n",
    "        with open('AnomalyScore/AutoEncoder_P_PET_Train_Repeat_'+str(repeat)+'CV_'+str(CV)+'.npy', 'wb') as f:\n",
    "            np.save(f,y_pred_train)\n",
    "            \n",
    "        \n",
    "        # negative model\n",
    "        Feature_neg = Feature[Ind==0,:]\n",
    "#         Ind_neg = \n",
    "        \n",
    "        # model training\n",
    "        clf = AutoEncoder(hidden_neurons = [32, 16, 4, 4, 16, 32],epochs=100)\n",
    "        clf.fit(Feature_neg)\n",
    "        \n",
    "        \n",
    "        # model testing\n",
    "        y_pred = clf.predict_proba(Feature_test)  # predict scores\n",
    "        \n",
    "        y_pred_train = clf.predict_proba(PET[Ind0[:,0]==0,:])  # predict scores\n",
    "        \n",
    "        \n",
    "        with open('AnomalyScore/AutoEncoder_N_PET_Repeat_'+str(repeat)+'CV_'+str(CV)+'.npy', 'wb') as f:\n",
    "            np.save(f,y_pred)\n",
    "        \n",
    "        with open('AnomalyScore/AutoEncoder_N_PET_Train_Repeat_'+str(repeat)+'CV_'+str(CV)+'.npy', 'wb') as f:\n",
    "            np.save(f,y_pred_train)\n",
    "            \n",
    "            \n",
    "        # combine feature\n",
    "        Feature_train = CT\n",
    "        print('\\nFeature shape is', Feature_train.shape)\n",
    "\n",
    "        Feature_test = CT_test\n",
    "        print('\\nFeature test shape is', Feature_test.shape)\n",
    "        \n",
    "        # SMOTE\n",
    "#         sm = SVMSMOTE(random_state=112)\n",
    "        sm = SVMSMOTE(random_state=123)\n",
    "#         sm = SVMSMOTE(random_state=111)\n",
    "\n",
    "        Feature, Ind = sm.fit_resample(Feature_train, Ind0)\n",
    "        print('\\nAfter SMOTE feature shape is', Feature.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # positive model\n",
    "        Feature_pos = Feature[Ind==1,:]\n",
    "#         Ind_pos = \n",
    "        \n",
    "        # model training\n",
    "        clf = AutoEncoder(hidden_neurons = [32, 16, 4, 4, 16, 32],epochs=100)\n",
    "        clf.fit(Feature_pos)\n",
    "        \n",
    "        \n",
    "        # model testing\n",
    "        y_pred = clf.predict_proba(Feature_test)  # predict scores\n",
    "        \n",
    "        y_pred_train = clf.predict_proba(CT[Ind0[:,0]==1,:])  # predict scores\n",
    "        \n",
    "        \n",
    "        with open('AnomalyScore/AutoEncoder_P_CT_Repeat_'+str(repeat)+'CV_'+str(CV)+'.npy', 'wb') as f:\n",
    "            np.save(f,y_pred)\n",
    "        \n",
    "        with open('AnomalyScore/AutoEncoder_P_CT_Train_Repeat_'+str(repeat)+'CV_'+str(CV)+'.npy', 'wb') as f:\n",
    "            np.save(f,y_pred_train)\n",
    "            \n",
    "        \n",
    "        # negative model\n",
    "        Feature_neg = Feature[Ind==0,:]\n",
    "#         Ind_neg = \n",
    "        \n",
    "        # model training\n",
    "        clf = AutoEncoder(hidden_neurons = [32, 16, 4, 4, 16, 32],epochs=100)\n",
    "        clf.fit(Feature_neg)\n",
    "        \n",
    "        \n",
    "        # model testing\n",
    "        y_pred = clf.predict_proba(Feature_test)  # predict scores\n",
    "        \n",
    "        y_pred_train = clf.predict_proba(CT[Ind0[:,0]==0,:])  # predict scores\n",
    "        \n",
    "        \n",
    "        with open('AnomalyScore/AutoEncoder_N_CT_Repeat_'+str(repeat)+'CV_'+str(CV)+'.npy', 'wb') as f:\n",
    "            np.save(f,y_pred)\n",
    "        \n",
    "        with open('AnomalyScore/AutoEncoder_N_CT_Train_Repeat_'+str(repeat)+'CV_'+str(CV)+'.npy', 'wb') as f:\n",
    "            np.save(f,y_pred_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
